{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DESAFIO 1 G2** \n",
    "# **Dataset Properati - Analisis exploratorio y acondicionamiento de datos.**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_toc\"></a> \n",
    "## Tabla de Contenidos\n",
    "\n",
    "[Intro](#section_intro)\n",
    "\n",
    "Dataset\n",
    "\n",
    "$\\hspace{.5cm}$[Observaciones generales](#section_og)\n",
    "  \n",
    "$\\hspace{.5cm}$[Procesos generales](#section_pg)\n",
    "\n",
    "Imputaciones\n",
    "\n",
    "$\\hspace{.5cm}$[Expresiones regulares](#section_re)\n",
    "\n",
    "$\\hspace{.9cm}$[Principios generales](#section_re_pg)\n",
    "\n",
    "$\\hspace{.9cm}$[Precios](#section_regexp_pre)\n",
    "\n",
    "$\\hspace{.9cm}$[Ambientes](#section_regexp_amb)\n",
    "\n",
    "$\\hspace{.9cm}$[Amenities](#section_regexp_ame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_intro\"></a> \n",
    "## Intro\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de DataFrame y exploracion inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = '../properati.zip'\n",
    "data = pd.read_csv(data_location, compression='zip', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1500)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_og\"></a> \n",
    "### Observaciones Generales\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datosCol(serie) - Funcion que retorna diccionario con los datos de una Serie / Columna del DataFrame a analizar:\n",
    "\n",
    "Campos:\n",
    " - nombre columna.\n",
    " - tipo de dato Pandas serie.\n",
    " - cantidad de registros en la serie.\n",
    " - cantidad de nulos en la serie.\n",
    " - cantidad de NO nulos en la serie.\n",
    " - porcentaje de No nulos en la serie.\n",
    " - cantidad de valores unicos en la serie.\n",
    " - valor mas repetido en la serie.\n",
    " - valor maximo en la serie.\n",
    " - valor minimos en la serie.\n",
    " - media, mediana y desvio estandar en la serie.\n",
    " - distribucion de cuantiles.\n",
    " - tipos de datos sobre los valores incluidos en la serie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datosCol(col=None):\n",
    "    try:\n",
    "        if col.dtype != object:\n",
    "            return {\n",
    "                    'nombre': col.name,\n",
    "                    'series_dt': col.dtype,\n",
    "                    'registros': int(len(col)), \n",
    "                    'nulos': int(len(col) - col.describe()[0]), \n",
    "                    'nulos_porcentaje': round(col.isnull().sum() / col.size*100, 2),\n",
    "                    'nonulos': int(col.describe()[0]),\n",
    "                    'nonulos_porcentraje': round(col.describe()[0] / col.shape[0], 2),\n",
    "                    'unicos': int(len(col.value_counts())),\n",
    "                    'mas_repetido': col.value_counts().index[0],\n",
    "                    'minimo': round(col.min(), 2),\n",
    "                    'maximo': round(col.max(), 2),\n",
    "                    'media': round(col.describe()[1], 2),\n",
    "                    'mediana': col.median(),\n",
    "                    'desvio': round(col.describe()[2], 2),\n",
    "                    'q25': col.describe()[4],\n",
    "                    'q50': col.describe()[5],\n",
    "                    'q75': col.describe()[6],\n",
    "                    'values_dt': [x for x in col.apply(lambda x: type(x)).value_counts().index]\n",
    "                   }\n",
    "        else:\n",
    "            return {\n",
    "                    'nombre': col.name,\n",
    "                    'series_dt': col.dtype,\n",
    "                    'registros': int(col.describe()[0]),\n",
    "                    'nulos': col.isnull().sum(),\n",
    "                    'nulos_porcentaje': round(col.isnull().sum() / col.size*100, 2),\n",
    "                    'nonulos': int(col.notnull().sum()),\n",
    "                    'nonulos_porcentraje': round(col.notnull().sum() / col.size*100, 2),\n",
    "                    'unicos': int(col.describe()[1]), \n",
    "                    'mas_repetido': col.describe()[2],\n",
    "                    'nulos': col.isnull().sum(),\n",
    "                    'frecuencia': int(col.describe()[3]),\n",
    "                    'values_dt': [x for x in col.apply(lambda x: type(x)).value_counts().index]\n",
    "                   }\n",
    "    except:\n",
    "        return 'use a valid pandas Series'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = pd.DataFrame([datosCol(data[x]) for x in data.columns ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>series_dt</th>\n",
       "      <th>registros</th>\n",
       "      <th>nulos</th>\n",
       "      <th>nulos_porcentaje</th>\n",
       "      <th>nonulos</th>\n",
       "      <th>nonulos_porcentraje</th>\n",
       "      <th>unicos</th>\n",
       "      <th>mas_repetido</th>\n",
       "      <th>minimo</th>\n",
       "      <th>maximo</th>\n",
       "      <th>media</th>\n",
       "      <th>mediana</th>\n",
       "      <th>desvio</th>\n",
       "      <th>q25</th>\n",
       "      <th>q50</th>\n",
       "      <th>q75</th>\n",
       "      <th>values_dt</th>\n",
       "      <th>frecuencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>int64</td>\n",
       "      <td>121220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>121220</td>\n",
       "      <td>1.00</td>\n",
       "      <td>121220</td>\n",
       "      <td>2047</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.212190e+05</td>\n",
       "      <td>60609.50</td>\n",
       "      <td>6.060950e+04</td>\n",
       "      <td>34993.34</td>\n",
       "      <td>3.030475e+04</td>\n",
       "      <td>6.060950e+04</td>\n",
       "      <td>9.091425e+04</td>\n",
       "      <td>[&lt;class 'int'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>operation</td>\n",
       "      <td>object</td>\n",
       "      <td>121220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>121220</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "      <td>sell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;class 'str'&gt;]</td>\n",
       "      <td>121220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>property_type</td>\n",
       "      <td>object</td>\n",
       "      <td>121220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>121220</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4</td>\n",
       "      <td>apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;class 'str'&gt;]</td>\n",
       "      <td>71065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>place_name</td>\n",
       "      <td>object</td>\n",
       "      <td>121197</td>\n",
       "      <td>23</td>\n",
       "      <td>0.02</td>\n",
       "      <td>121197</td>\n",
       "      <td>99.98</td>\n",
       "      <td>1060</td>\n",
       "      <td>CÃ³rdoba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;class 'str'&gt;, &lt;class 'float'&gt;]</td>\n",
       "      <td>9254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>place_with_parent_names</td>\n",
       "      <td>object</td>\n",
       "      <td>121220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>121220</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1164</td>\n",
       "      <td>|Argentina|Santa Fe|Rosario|</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;class 'str'&gt;]</td>\n",
       "      <td>8504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>country_name</td>\n",
       "      <td>object</td>\n",
       "      <td>121220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>121220</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;class 'str'&gt;]</td>\n",
       "      <td>121220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>state_name</td>\n",
       "      <td>object</td>\n",
       "      <td>121220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>121220</td>\n",
       "      <td>100.00</td>\n",
       "      <td>28</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;class 'str'&gt;]</td>\n",
       "      <td>32316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>geonames_id</td>\n",
       "      <td>float64</td>\n",
       "      <td>121220</td>\n",
       "      <td>18717</td>\n",
       "      <td>15.44</td>\n",
       "      <td>102503</td>\n",
       "      <td>0.85</td>\n",
       "      <td>646</td>\n",
       "      <td>3.83857e+06</td>\n",
       "      <td>3427208.00</td>\n",
       "      <td>6.948895e+06</td>\n",
       "      <td>3574442.32</td>\n",
       "      <td>3.433910e+06</td>\n",
       "      <td>354130.62</td>\n",
       "      <td>3.430234e+06</td>\n",
       "      <td>3.433910e+06</td>\n",
       "      <td>3.836668e+06</td>\n",
       "      <td>[&lt;class 'float'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lat-lon</td>\n",
       "      <td>object</td>\n",
       "      <td>69670</td>\n",
       "      <td>51550</td>\n",
       "      <td>42.53</td>\n",
       "      <td>69670</td>\n",
       "      <td>57.47</td>\n",
       "      <td>47203</td>\n",
       "      <td>-34.4026444,-58.6684776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;class 'str'&gt;, &lt;class 'float'&gt;]</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lat</td>\n",
       "      <td>float64</td>\n",
       "      <td>121220</td>\n",
       "      <td>51550</td>\n",
       "      <td>42.53</td>\n",
       "      <td>69670</td>\n",
       "      <td>0.57</td>\n",
       "      <td>46495</td>\n",
       "      <td>-34.4026</td>\n",
       "      <td>-54.82</td>\n",
       "      <td>4.550000e+00</td>\n",
       "      <td>-34.63</td>\n",
       "      <td>-3.459799e+01</td>\n",
       "      <td>1.98</td>\n",
       "      <td>-3.466907e+01</td>\n",
       "      <td>-3.459799e+01</td>\n",
       "      <td>-3.444130e+01</td>\n",
       "      <td>[&lt;class 'float'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lon</td>\n",
       "      <td>float64</td>\n",
       "      <td>121220</td>\n",
       "      <td>51550</td>\n",
       "      <td>42.53</td>\n",
       "      <td>69670</td>\n",
       "      <td>0.57</td>\n",
       "      <td>46522</td>\n",
       "      <td>-58.6685</td>\n",
       "      <td>-75.68</td>\n",
       "      <td>-5.373000e+01</td>\n",
       "      <td>-59.27</td>\n",
       "      <td>-5.848013e+01</td>\n",
       "      <td>2.30</td>\n",
       "      <td>-5.872704e+01</td>\n",
       "      <td>-5.848013e+01</td>\n",
       "      <td>-5.839591e+01</td>\n",
       "      <td>[&lt;class 'float'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>price</td>\n",
       "      <td>float64</td>\n",
       "      <td>121220</td>\n",
       "      <td>20410</td>\n",
       "      <td>16.84</td>\n",
       "      <td>100810</td>\n",
       "      <td>0.83</td>\n",
       "      <td>9746</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.500000e+08</td>\n",
       "      <td>468525.93</td>\n",
       "      <td>1.850000e+05</td>\n",
       "      <td>2260100.59</td>\n",
       "      <td>1.100000e+05</td>\n",
       "      <td>1.850000e+05</td>\n",
       "      <td>4.200000e+05</td>\n",
       "      <td>[&lt;class 'float'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>currency</td>\n",
       "      <td>object</td>\n",
       "      <td>100809</td>\n",
       "      <td>20411</td>\n",
       "      <td>16.84</td>\n",
       "      <td>100809</td>\n",
       "      <td>83.16</td>\n",
       "      <td>4</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;class 'str'&gt;, &lt;class 'float'&gt;]</td>\n",
       "      <td>87587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>price_aprox_local_currency</td>\n",
       "      <td>float64</td>\n",
       "      <td>121220</td>\n",
       "      <td>20410</td>\n",
       "      <td>16.84</td>\n",
       "      <td>100810</td>\n",
       "      <td>0.83</td>\n",
       "      <td>10364</td>\n",
       "      <td>2.11734e+06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.212711e+08</td>\n",
       "      <td>4229396.83</td>\n",
       "      <td>2.558452e+06</td>\n",
       "      <td>6904714.13</td>\n",
       "      <td>1.583309e+06</td>\n",
       "      <td>2.558452e+06</td>\n",
       "      <td>4.675792e+06</td>\n",
       "      <td>[&lt;class 'float'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>price_aprox_usd</td>\n",
       "      <td>float64</td>\n",
       "      <td>121220</td>\n",
       "      <td>20410</td>\n",
       "      <td>16.84</td>\n",
       "      <td>100810</td>\n",
       "      <td>0.83</td>\n",
       "      <td>10364</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.654544e+07</td>\n",
       "      <td>239700.58</td>\n",
       "      <td>1.450000e+05</td>\n",
       "      <td>391323.88</td>\n",
       "      <td>8.973388e+04</td>\n",
       "      <td>1.450000e+05</td>\n",
       "      <td>2.650000e+05</td>\n",
       "      <td>[&lt;class 'float'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>surface_total_in_m2</td>\n",
       "      <td>float64</td>\n",
       "      <td>121220</td>\n",
       "      <td>39328</td>\n",
       "      <td>32.44</td>\n",
       "      <td>81892</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1687</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>233.80</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>1782.22</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>[&lt;class 'float'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>surface_covered_in_m2</td>\n",
       "      <td>float64</td>\n",
       "      <td>121220</td>\n",
       "      <td>19907</td>\n",
       "      <td>16.42</td>\n",
       "      <td>101313</td>\n",
       "      <td>0.84</td>\n",
       "      <td>995</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.870000e+05</td>\n",
       "      <td>133.05</td>\n",
       "      <td>7.500000e+01</td>\n",
       "      <td>724.35</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>7.500000e+01</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>[&lt;class 'float'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>price_usd_per_m2</td>\n",
       "      <td>float64</td>\n",
       "      <td>121220</td>\n",
       "      <td>52603</td>\n",
       "      <td>43.39</td>\n",
       "      <td>68617</td>\n",
       "      <td>0.57</td>\n",
       "      <td>25567</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.063333e+05</td>\n",
       "      <td>2160.09</td>\n",
       "      <td>1.800000e+03</td>\n",
       "      <td>2759.29</td>\n",
       "      <td>1.218182e+03</td>\n",
       "      <td>1.800000e+03</td>\n",
       "      <td>2.486412e+03</td>\n",
       "      <td>[&lt;class 'float'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>price_per_m2</td>\n",
       "      <td>float64</td>\n",
       "      <td>121220</td>\n",
       "      <td>33562</td>\n",
       "      <td>27.69</td>\n",
       "      <td>87658</td>\n",
       "      <td>0.72</td>\n",
       "      <td>25185</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.51</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>6912.22</td>\n",
       "      <td>2.213115e+03</td>\n",
       "      <td>28378.64</td>\n",
       "      <td>1.550000e+03</td>\n",
       "      <td>2.213115e+03</td>\n",
       "      <td>3.355549e+03</td>\n",
       "      <td>[&lt;class 'float'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>floor</td>\n",
       "      <td>float64</td>\n",
       "      <td>121220</td>\n",
       "      <td>113321</td>\n",
       "      <td>93.48</td>\n",
       "      <td>7899</td>\n",
       "      <td>0.07</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.150000e+03</td>\n",
       "      <td>17.45</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>120.24</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>[&lt;class 'float'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rooms</td>\n",
       "      <td>float64</td>\n",
       "      <td>121220</td>\n",
       "      <td>73830</td>\n",
       "      <td>60.91</td>\n",
       "      <td>47390</td>\n",
       "      <td>0.39</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.200000e+01</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>[&lt;class 'float'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>expenses</td>\n",
       "      <td>float64</td>\n",
       "      <td>121220</td>\n",
       "      <td>106958</td>\n",
       "      <td>88.23</td>\n",
       "      <td>14262</td>\n",
       "      <td>0.12</td>\n",
       "      <td>982</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000150e+07</td>\n",
       "      <td>5009.23</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>120440.26</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>4.000000e+03</td>\n",
       "      <td>[&lt;class 'float'&gt;]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>properati_url</td>\n",
       "      <td>object</td>\n",
       "      <td>121220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>121220</td>\n",
       "      <td>100.00</td>\n",
       "      <td>121220</td>\n",
       "      <td>http://www.properati.com.ar/1bc2u_venta_casa_m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;class 'str'&gt;]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>description</td>\n",
       "      <td>object</td>\n",
       "      <td>121218</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>121218</td>\n",
       "      <td>100.00</td>\n",
       "      <td>104055</td>\n",
       "      <td>AVISO LEGAL: Las descripciones arquitectÃ³nicas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;class 'str'&gt;, &lt;class 'float'&gt;]</td>\n",
       "      <td>358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>title</td>\n",
       "      <td>object</td>\n",
       "      <td>121220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>121220</td>\n",
       "      <td>100.00</td>\n",
       "      <td>72705</td>\n",
       "      <td>DEPARTAMENTO EN VENTA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;class 'str'&gt;]</td>\n",
       "      <td>4855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>image_thumbnail</td>\n",
       "      <td>object</td>\n",
       "      <td>118108</td>\n",
       "      <td>3112</td>\n",
       "      <td>2.57</td>\n",
       "      <td>118108</td>\n",
       "      <td>97.43</td>\n",
       "      <td>114389</td>\n",
       "      <td>https://thumbs4.properati.com/5/yyMiu8BHQI9KXC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;class 'str'&gt;, &lt;class 'float'&gt;]</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        nombre series_dt  registros   nulos  nulos_porcentaje  \\\n",
       "0                   Unnamed: 0     int64     121220       0              0.00   \n",
       "1                    operation    object     121220       0              0.00   \n",
       "2                property_type    object     121220       0              0.00   \n",
       "3                   place_name    object     121197      23              0.02   \n",
       "4      place_with_parent_names    object     121220       0              0.00   \n",
       "5                 country_name    object     121220       0              0.00   \n",
       "6                   state_name    object     121220       0              0.00   \n",
       "7                  geonames_id   float64     121220   18717             15.44   \n",
       "8                      lat-lon    object      69670   51550             42.53   \n",
       "9                          lat   float64     121220   51550             42.53   \n",
       "10                         lon   float64     121220   51550             42.53   \n",
       "11                       price   float64     121220   20410             16.84   \n",
       "12                    currency    object     100809   20411             16.84   \n",
       "13  price_aprox_local_currency   float64     121220   20410             16.84   \n",
       "14             price_aprox_usd   float64     121220   20410             16.84   \n",
       "15         surface_total_in_m2   float64     121220   39328             32.44   \n",
       "16       surface_covered_in_m2   float64     121220   19907             16.42   \n",
       "17            price_usd_per_m2   float64     121220   52603             43.39   \n",
       "18                price_per_m2   float64     121220   33562             27.69   \n",
       "19                       floor   float64     121220  113321             93.48   \n",
       "20                       rooms   float64     121220   73830             60.91   \n",
       "21                    expenses   float64     121220  106958             88.23   \n",
       "22               properati_url    object     121220       0              0.00   \n",
       "23                 description    object     121218       2              0.00   \n",
       "24                       title    object     121220       0              0.00   \n",
       "25             image_thumbnail    object     118108    3112              2.57   \n",
       "\n",
       "    nonulos  nonulos_porcentraje  unicos  \\\n",
       "0    121220                 1.00  121220   \n",
       "1    121220               100.00       1   \n",
       "2    121220               100.00       4   \n",
       "3    121197                99.98    1060   \n",
       "4    121220               100.00    1164   \n",
       "5    121220               100.00       1   \n",
       "6    121220               100.00      28   \n",
       "7    102503                 0.85     646   \n",
       "8     69670                57.47   47203   \n",
       "9     69670                 0.57   46495   \n",
       "10    69670                 0.57   46522   \n",
       "11   100810                 0.83    9746   \n",
       "12   100809                83.16       4   \n",
       "13   100810                 0.83   10364   \n",
       "14   100810                 0.83   10364   \n",
       "15    81892                 0.68    1687   \n",
       "16   101313                 0.84     995   \n",
       "17    68617                 0.57   25567   \n",
       "18    87658                 0.72   25185   \n",
       "19     7899                 0.07     182   \n",
       "20    47390                 0.39      31   \n",
       "21    14262                 0.12     982   \n",
       "22   121220               100.00  121220   \n",
       "23   121218               100.00  104055   \n",
       "24   121220               100.00   72705   \n",
       "25   118108                97.43  114389   \n",
       "\n",
       "                                         mas_repetido      minimo  \\\n",
       "0                                                2047        0.00   \n",
       "1                                                sell         NaN   \n",
       "2                                           apartment         NaN   \n",
       "3                                             CÃ³rdoba         NaN   \n",
       "4                        |Argentina|Santa Fe|Rosario|         NaN   \n",
       "5                                           Argentina         NaN   \n",
       "6                                     Capital Federal         NaN   \n",
       "7                                         3.83857e+06  3427208.00   \n",
       "8                             -34.4026444,-58.6684776         NaN   \n",
       "9                                            -34.4026      -54.82   \n",
       "10                                           -58.6685      -75.68   \n",
       "11                                             120000        0.00   \n",
       "12                                                USD         NaN   \n",
       "13                                        2.11734e+06        0.00   \n",
       "14                                             120000        0.00   \n",
       "15                                                 50        0.00   \n",
       "16                                                 40        0.00   \n",
       "17                                               2000        0.60   \n",
       "18                                               2000        1.51   \n",
       "19                                                  1        1.00   \n",
       "20                                                  3        1.00   \n",
       "21                                                  1        1.00   \n",
       "22  http://www.properati.com.ar/1bc2u_venta_casa_m...         NaN   \n",
       "23  AVISO LEGAL: Las descripciones arquitectÃ³nicas...         NaN   \n",
       "24                              DEPARTAMENTO EN VENTA         NaN   \n",
       "25  https://thumbs4.properati.com/5/yyMiu8BHQI9KXC...         NaN   \n",
       "\n",
       "          maximo       media       mediana      desvio           q25  \\\n",
       "0   1.212190e+05    60609.50  6.060950e+04    34993.34  3.030475e+04   \n",
       "1            NaN         NaN           NaN         NaN           NaN   \n",
       "2            NaN         NaN           NaN         NaN           NaN   \n",
       "3            NaN         NaN           NaN         NaN           NaN   \n",
       "4            NaN         NaN           NaN         NaN           NaN   \n",
       "5            NaN         NaN           NaN         NaN           NaN   \n",
       "6            NaN         NaN           NaN         NaN           NaN   \n",
       "7   6.948895e+06  3574442.32  3.433910e+06   354130.62  3.430234e+06   \n",
       "8            NaN         NaN           NaN         NaN           NaN   \n",
       "9   4.550000e+00      -34.63 -3.459799e+01        1.98 -3.466907e+01   \n",
       "10 -5.373000e+01      -59.27 -5.848013e+01        2.30 -5.872704e+01   \n",
       "11  6.500000e+08   468525.93  1.850000e+05  2260100.59  1.100000e+05   \n",
       "12           NaN         NaN           NaN         NaN           NaN   \n",
       "13  8.212711e+08  4229396.83  2.558452e+06  6904714.13  1.583309e+06   \n",
       "14  4.654544e+07   239700.58  1.450000e+05   391323.88  8.973388e+04   \n",
       "15  2.000000e+05      233.80  8.400000e+01     1782.22  5.000000e+01   \n",
       "16  1.870000e+05      133.05  7.500000e+01      724.35  4.500000e+01   \n",
       "17  2.063333e+05     2160.09  1.800000e+03     2759.29  1.218182e+03   \n",
       "18  4.000000e+06     6912.22  2.213115e+03    28378.64  1.550000e+03   \n",
       "19  3.150000e+03       17.45  3.000000e+00      120.24  1.000000e+00   \n",
       "20  3.200000e+01        3.08  3.000000e+00        1.86  2.000000e+00   \n",
       "21  1.000150e+07     5009.23  2.000000e+03   120440.26  1.000000e+03   \n",
       "22           NaN         NaN           NaN         NaN           NaN   \n",
       "23           NaN         NaN           NaN         NaN           NaN   \n",
       "24           NaN         NaN           NaN         NaN           NaN   \n",
       "25           NaN         NaN           NaN         NaN           NaN   \n",
       "\n",
       "             q50           q75                         values_dt  frecuencia  \n",
       "0   6.060950e+04  9.091425e+04                   [<class 'int'>]         NaN  \n",
       "1            NaN           NaN                   [<class 'str'>]    121220.0  \n",
       "2            NaN           NaN                   [<class 'str'>]     71065.0  \n",
       "3            NaN           NaN  [<class 'str'>, <class 'float'>]      9254.0  \n",
       "4            NaN           NaN                   [<class 'str'>]      8504.0  \n",
       "5            NaN           NaN                   [<class 'str'>]    121220.0  \n",
       "6            NaN           NaN                   [<class 'str'>]     32316.0  \n",
       "7   3.433910e+06  3.836668e+06                 [<class 'float'>]         NaN  \n",
       "8            NaN           NaN  [<class 'str'>, <class 'float'>]       312.0  \n",
       "9  -3.459799e+01 -3.444130e+01                 [<class 'float'>]         NaN  \n",
       "10 -5.848013e+01 -5.839591e+01                 [<class 'float'>]         NaN  \n",
       "11  1.850000e+05  4.200000e+05                 [<class 'float'>]         NaN  \n",
       "12           NaN           NaN  [<class 'str'>, <class 'float'>]     87587.0  \n",
       "13  2.558452e+06  4.675792e+06                 [<class 'float'>]         NaN  \n",
       "14  1.450000e+05  2.650000e+05                 [<class 'float'>]         NaN  \n",
       "15  8.400000e+01  2.000000e+02                 [<class 'float'>]         NaN  \n",
       "16  7.500000e+01  1.500000e+02                 [<class 'float'>]         NaN  \n",
       "17  1.800000e+03  2.486412e+03                 [<class 'float'>]         NaN  \n",
       "18  2.213115e+03  3.355549e+03                 [<class 'float'>]         NaN  \n",
       "19  3.000000e+00  6.000000e+00                 [<class 'float'>]         NaN  \n",
       "20  3.000000e+00  4.000000e+00                 [<class 'float'>]         NaN  \n",
       "21  2.000000e+03  4.000000e+03                 [<class 'float'>]         NaN  \n",
       "22           NaN           NaN                   [<class 'str'>]         1.0  \n",
       "23           NaN           NaN  [<class 'str'>, <class 'float'>]       358.0  \n",
       "24           NaN           NaN                   [<class 'str'>]      4855.0  \n",
       "25           NaN           NaN  [<class 'str'>, <class 'float'>]       255.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploracion general\n",
    "<a id=\"section_pg\"></a> \n",
    "### Procesos Generales\n",
    "\n",
    "[volver a TOC](#section_pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renombro la columna que no tiene nombre\n",
    "data = data.rename({           \n",
    "    'Unnamed: 0': 'Id_caso'\n",
    "}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apartment    71065\n",
      "house        40268\n",
      "PH            5751\n",
      "store         4136\n",
      "Name: property_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# valores \n",
    "medida_property_type = data.property_type.value_counts()\n",
    "print(medida_property_type) \n",
    "# ...........terminar los otros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploracion sobre ubicacion de propiedades\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis campos ubicacion:** `place_name` `place_with_parent_names` `lat-lon` `geonames_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Campo `geonames_id`:\n",
    " - Comprobacion: validacion de asignacion de mismo geonames_id a distintos valores place_name_new\n",
    " - Normalizacion de valores nulos\n",
    "\n",
    "Campo `lat-lon`:\n",
    " \n",
    "Campo `tipo_de_cambio`:\n",
    " \n",
    "Campo `precio_m2`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validacion y comparacion de consistencia entre:\n",
    " - `place_with_parent_names`\n",
    " - `place_name`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a determinadar si la variable `place_name` tiene un dato 'confiable' o 'completo', para eso separamos la variable `place_with_parent_names` en secciones, por el simbolo | (pipe) separo la variable place_with_parent_names, sumando campos nuevos y ya trabajando sobre el nuevo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trabajo = data.join(data[\"place_with_parent_names\"].str.split('|', expand=True).rename(columns={\n",
    "                                                                                                1:'Pais', \n",
    "                                                                                                2:'Zona', \n",
    "                                                                                                3:'Partido_barrio', \n",
    "                                                                                                4:'Localidad', \n",
    "                                                                                                5:'Obs_localidad', \n",
    "                                                                                                6:'Descarte'}))\n",
    "data_trabajo.drop(['Descarte'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validamos que la variable `place_name` sea igual a el ultimo valor informado sobre `place_with_parent_names` ya separado por el proceso anterior.\n",
    "Se desde la ultima variable hasta encontrar un NO nulo y se graba el valor:\n",
    "\n",
    " 1. Obs_localidad\n",
    " 2. Localidad\n",
    " 3. Partido_barrio\n",
    " 4. Zona\n",
    " \n",
    "Creacion de una nueva serie `place_name_new` que se completara a medida que valide que cada variable tenga valor empezando desde la ultima seccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trabajo[\"place_name_new\"] = 'validar'\n",
    "\n",
    "#para cada variable nuevo valido null o ''\n",
    "# creo mascara de los casos donde la varible 'x' tenga null o ''\n",
    "mask_data_Obs_localidad_null =  (data_trabajo.Obs_localidad.isnull()) | (data_trabajo.Obs_localidad == '')\n",
    "\n",
    "# creo otra mascara con origen en la mascara enterior para quedarme con los \n",
    "# que tienen valor en la variable 'x'\n",
    "mask_data_Obs_localidad_notnull = mask_data_Obs_localidad_null == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ActualizaciÃ³n de `place_name_new`\n",
    "\n",
    "1. Obs_localidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de casos con Obs_localidad informada: 548\n",
      "Cantidad de casos con place_name_new original :0\n",
      "Cantidad de casos con place_name_new posterior para analizar: 0\n"
     ]
    }
   ],
   "source": [
    "print ('Cantidad de casos con Obs_localidad informada: ' + str(mask_data_Obs_localidad_notnull.sum()))\n",
    "\n",
    "# creo una mascara sobre la variable que voy a ir completando con el valor obtenido\n",
    "mask_data_place_name_new_validar = data_trabajo.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new original :' + str(mask_data_place_name_new_validar.sum()))\n",
    "\n",
    "# actualizo los valores sobre mi nueva variable con los que encontrÃ© en la variable 'x'\n",
    "data_trabajo.loc[mask_data_Obs_localidad_notnull&mask_data_place_name_new_validar, \"place_name_new\"] = data_trabajo.Obs_localidad\n",
    "\n",
    "# actualizo la mascara sobre mi nueva variable para contar y ver si todo resultÃ³ ok!\n",
    "mask_data_place_name_new_validar = data_trabajo.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new posterior para analizar: ' + str(mask_data_place_name_new_validar.sum()))\n",
    "\n",
    "# la cantidad de casos sobre la variable nueva con valor 'validar' era de 121197\n",
    "# La cantidad de casos sobre la misma variable con valor 'validar' despues de actualizar fue de 120649\n",
    "# El delta corresponde a los valores con origen en el primer campo Obs_localidad ... 548"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Localidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de casos con Localidad informada: 40440\n",
      "Cantidad de casos con place_name_new original: 0\n",
      "Cantidad de casos con place_name_new posterior para analizar: 0\n"
     ]
    }
   ],
   "source": [
    "mask_data_Localidad_null =  (data_trabajo.Localidad.isnull()) | (data_trabajo.Localidad == '')\n",
    "mask_data_Localidad_notnull = mask_data_Localidad_null == False\n",
    "print ('Cantidad de casos con Localidad informada: ' + str(mask_data_Localidad_notnull.sum()))\n",
    "\n",
    "mask_data_place_name_new_validar = data_trabajo.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new original: ' +  str(mask_data_place_name_new_validar.sum()))\n",
    "\n",
    "data_trabajo.loc[mask_data_Localidad_notnull&mask_data_place_name_new_validar, \"place_name_new\"] = data_trabajo.Localidad\n",
    "mask_data_place_name_new_validar = data_trabajo.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new posterior para analizar: ' + str(mask_data_place_name_new_validar.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Partido_barrio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de casos con Partido_barrio informada: 116440\n",
      "Cantidad de casos con place_name_new original: 0\n",
      "Cantidad de casos con place_name_new posterior para analizar: 0\n"
     ]
    }
   ],
   "source": [
    "mask_data_Partido_barrio_null =  (data_trabajo.Partido_barrio.isnull()) | (data_trabajo.Partido_barrio == '')\n",
    "mask_data_Partido_barrio_notnull = mask_data_Partido_barrio_null == False\n",
    "print ('Cantidad de casos con Partido_barrio informada: ' + str(mask_data_Partido_barrio_notnull.sum()))\n",
    "\n",
    "mask_data_place_name_new_validar = data_trabajo.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new original: ' + str(mask_data_place_name_new_validar.sum()))\n",
    "\n",
    "data_trabajo.loc[mask_data_Partido_barrio_notnull&mask_data_place_name_new_validar, \"place_name_new\"] = data_trabajo.Partido_barrio\n",
    "mask_data_place_name_new_validar = data_trabajo.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new posterior para analizar: ' + str(mask_data_place_name_new_validar.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Zona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de casos con Zona informada: 121220\n",
      "Cantidad de casos con place_name_new original: 0\n",
      "Cantidad de casos con place_name_new posterior para analizar: 0\n"
     ]
    }
   ],
   "source": [
    "mask_data_Zona_null =  (data_trabajo.Zona.isnull()) | (data_trabajo.Zona == '')\n",
    "mask_data_Zona_notnull = mask_data_Zona_null == False\n",
    "print ('Cantidad de casos con Zona informada: ' + str(mask_data_Zona_notnull.sum()))\n",
    "\n",
    "mask_data_place_name_new_validar = data_trabajo.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new original: ' + str(mask_data_place_name_new_validar.sum()))\n",
    "\n",
    "data_trabajo.loc[mask_data_Zona_notnull&mask_data_place_name_new_validar, \"place_name_new\"] = data_trabajo.Zona\n",
    "mask_data_place_name_new_validar = data_trabajo.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new posterior para analizar: ' + str(mask_data_place_name_new_validar.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad casos que coinciden entre place_name_new y place_name\n",
    "\n",
    "La coincidencia de registros es un indicador de coincidencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     121197\n",
      "False        23\n",
      "dtype: int64 \n",
      "\n",
      "Vemos que casuiticas encontramos sobre los casos que no encontramos: \n",
      "\n",
      "place_with_parent_names\n",
      "|Argentina|Bs.As. G.B.A. Zona Norte|Tigre||    23\n",
      "Name: Id_caso, dtype: int64\n",
      "Vemos que son todos del mismo place_with_parent_names de Tigre \n",
      "\n",
      "Los normalizamos sobre la variable place_name_new \n",
      "\n",
      "Validamos la actualizaciÃ³n: \n",
      "\n",
      "place_name_new\n",
      "Tigre    23\n",
      "Name: Id_caso, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# valido si place_name_new da igual que place_name, si contamos lo mismo es que da igual\n",
    "mask_place_name_validacion =  data_trabajo.place_name_new == data_trabajo.place_name\n",
    "print(mask_place_name_validacion.value_counts(), '\\n')  \n",
    "\n",
    "mask_place_name_validacion_falso = mask_place_name_validacion == False\n",
    "print ('Vemos que casuiticas encontramos sobre los casos que no encontramos:', '\\n')\n",
    "print(data_trabajo.loc[mask_place_name_validacion_falso, [\"Id_caso\",\"place_with_parent_names\",\"place_name\", \"place_name_new\"]].\\\n",
    "     groupby([\"place_with_parent_names\"])[\"Id_caso\"].count())\n",
    "print('Vemos que son todos del mismo place_with_parent_names de Tigre', '\\n')\n",
    "\n",
    "print ('Los normalizamos sobre la variable place_name_new', '\\n')\n",
    "data_trabajo.loc[mask_place_name_validacion_falso, \"place_name_new\"] = 'Tigre'\n",
    "data_trabajo.loc[mask_place_name_validacion_falso, \"Localidad\"] = 'Tigre'\n",
    "print ('Validamos la actualizaciÃ³n:', '\\n')\n",
    "print(data_trabajo.loc[mask_place_name_validacion_falso, [\"Id_caso\", \"place_name_new\"]]\\\n",
    "     .groupby([\"place_name_new\"])[\"Id_caso\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`calidad_dato` nueva Serie para validar la calidad del dato `place_with_parent_names` luego de separarlo \n",
    "\n",
    "Dependiendo de la zona que estamos analizando entendemos que la cantidad de info que necesitamos para:\n",
    "\n",
    " - `['Bs.As. G.B.A. Zona Norte','Bs.As. G.B.A. Zona Oeste','Bs.As. G.B.A. Zona Sur']` el mÃ­nimo tendria que ser _Localidad_.\n",
    " - `['Buenos Aires Costa AtlÃ¡ntica']` y en especial MDQ el mÃ­nimo tendria que ser _Localidad_.\n",
    " - el resto de las zonas _Partido_barrio_.\n",
    "\n",
    "Se actualizarÃ¡ la Serie creada (`calidad_dato`) a True que identificarÃ¡ los casos sobre los que necesitamos mayor informaciÃ³n:\n",
    "\n",
    "Para `['Bs.As. G.B.A. Zona Norte','Bs.As. G.B.A. Zona Oeste','Bs.As. G.B.A. Zona Sur']` se creara una lista de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de casos a los que le falta informaciÃ³n de localizaciÃ³n:\n",
      "-----------------------------------------------------------------\n",
      "False    107421\n",
      "True      13799\n",
      "Name: calidad_dato, dtype: int64 \n",
      "\n",
      "AgrupaciÃ³n de los casos a los que le falta informaciÃ³n de localizaciÃ³n:\n",
      "-----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pais       Zona                          Partido_barrio     \n",
       "Argentina  Bs.As. G.B.A. Zona Norte      Tigre                  2359\n",
       "                                         Pilar                  1857\n",
       "           Capital Federal                                      1297\n",
       "           Bs.As. G.B.A. Zona Norte      Escobar                1037\n",
       "           Bs.As. G.B.A. Zona Sur        La Plata                767\n",
       "           Bs.As. G.B.A. Zona Norte      San Isidro              641\n",
       "           Bs.As. G.B.A. Zona Oeste      MorÃ³n                   582\n",
       "                                         ItuzaingÃ³               474\n",
       "           Bs.As. G.B.A. Zona Norte      San Fernando            437\n",
       "           Bs.As. G.B.A. Zona Oeste      Moreno                  434\n",
       "           Bs.As. G.B.A. Zona Norte      San Miguel              417\n",
       "                                         General San MartÃ­n      382\n",
       "           Bs.As. G.B.A. Zona Sur        Lomas de Zamora         276\n",
       "           Bs.As. G.B.A. Zona Oeste      Merlo                   271\n",
       "           Bs.As. G.B.A. Zona Sur        Avellaneda              238\n",
       "           Bs.As. G.B.A. Zona Norte      Vicente LÃ³pez           232\n",
       "                                                                 222\n",
       "           Bs.As. G.B.A. Zona Sur        Quilmes                 216\n",
       "                                         Ezeiza                  211\n",
       "                                         Esteban EcheverrÃ­a      209\n",
       "           Bs.As. G.B.A. Zona Oeste      La Matanza              149\n",
       "           Bs.As. G.B.A. Zona Sur        Berazategui             115\n",
       "           Buenos Aires Interior                                 106\n",
       "           Bs.As. G.B.A. Zona Norte      Malvinas Argentinas     106\n",
       "                                         JosÃ© C Paz              101\n",
       "           Bs.As. G.B.A. Zona Oeste      Hurlingham              100\n",
       "                                         Tres de Febrero          96\n",
       "           Bs.As. G.B.A. Zona Sur        San Vicente              95\n",
       "           Bs.As. G.B.A. Zona Oeste      General RodrÃ­guez        83\n",
       "           Bs.As. G.B.A. Zona Sur        LanÃºs                    77\n",
       "           Bs.As. G.B.A. Zona Oeste                               65\n",
       "           Bs.As. G.B.A. Zona Sur        Almirante Brown          42\n",
       "           Buenos Aires Costa AtlÃ¡ntica                           27\n",
       "           Bs.As. G.B.A. Zona Sur                                 24\n",
       "                                         Presidente PerÃ³n         19\n",
       "                                         Florencio Varela         16\n",
       "           Bs.As. G.B.A. Zona Oeste      Marcos Paz               10\n",
       "           Bs.As. G.B.A. Zona Sur        CaÃ±uelas                  9\n",
       "Name: Id_caso, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_trabajo[\"calidad_dato\"] = False\n",
    "\n",
    "# zonas a traves de una lista de valores\n",
    "valores_zona = ['Bs.As. G.B.A. Zona Norte','Bs.As. G.B.A. Zona Oeste','Bs.As. G.B.A. Zona Sur']\n",
    "\n",
    "# mascara sobre la lista de valores y que localidad este nulo o ''\n",
    "mask_Localidad = ([x in valores_zona for x in data_trabajo.Zona]) & ((data_trabajo.Localidad.isnull())|(data_trabajo.Localidad == ''))\n",
    "\n",
    "# actualizo la variable creada sobre los True por la mascara\n",
    "data_trabajo.loc[mask_Localidad, \"calidad_dato\"] = True\n",
    "\n",
    "# caso especial de MDQ\n",
    "valores_zona_mdq = ['Buenos Aires Costa AtlÃ¡ntica']\n",
    "mask_Localidad_mdq = ([x in valores_zona_mdq for x in data_trabajo.Zona])\\\n",
    "& (data_trabajo.Partido_barrio == 'Mar del Plata') & ((data_trabajo.Localidad.isnull()) | (data_trabajo.Localidad == ''))\n",
    "data_trabajo.loc[mask_Localidad, \"calidad_dato\"] = True\n",
    "\n",
    "#resto_zonas\n",
    "valores_zona_resto = ['Buenos Aires Costa AtlÃ¡ntica','Buenos Aires Interior','Capital Federal','Resto de provincias']\n",
    "mask_Partido_barrio = ([x in valores_zona_resto for x in data_trabajo.Zona]) & ((data_trabajo.Partido_barrio.isnull())|\\\n",
    "                                                                                (data_trabajo.Partido_barrio == ''))\n",
    "mask_calidad_dato_false = data_trabajo.calidad_dato == False\n",
    "data_trabajo.loc[mask_Partido_barrio & mask_calidad_dato_false, \"calidad_dato\"] = True\n",
    "# ----------------------------------------------------------------------\n",
    "# todos los casos con True corresponden a los registros sobre los que nos falta informacion referida a \n",
    "# la geolocalizaciÃ³n de la propiedad\n",
    "print ('Cantidad de casos a los que le falta informaciÃ³n de localizaciÃ³n:')\n",
    "print ('-----------------------------------------------------------------')\n",
    "print(data_trabajo.calidad_dato.value_counts(), '\\n')\n",
    "# mascara sobre casos que nos faltaria info\n",
    "mask_faltante = (data_trabajo.calidad_dato == True)\n",
    "data_faltante = data_trabajo.loc[mask_faltante]\n",
    "#print (data_faltante)\n",
    "# agrupo por Pais, Zona, Partido_barrio los casos que no tenemos otra info\n",
    "groupby_df_faltante = data_faltante.groupby(['Pais',  'Zona', 'Partido_barrio'])[\"Id_caso\"].count().\\\n",
    "sort_values(ascending=False)\n",
    "print ('AgrupaciÃ³n de los casos a los que le falta informaciÃ³n de localizaciÃ³n:')\n",
    "print ('-----------------------------------------------------------------------')\n",
    "groupby_df_faltante\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Serie*** `geonames_id`\n",
    "\n",
    "Id asignado a cada `place_name`\n",
    "\n",
    "Primero: vamos a validar que NO se asigne un mismo `geonames_id` a distintos valores de `place_name_new`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casos que un mismo geonames_id tiene asignado mÃ¡s de un place_name\n",
      "------------------------------------------------------------------\n",
      "                                          size\n",
      "geonames_id place_name_new                    \n",
      "3428927.0   San Jose                         5\n",
      "            San JosÃ©                        11\n",
      "3430234.0   Palermo                       2885\n",
      "            Palermo Soho                   394\n",
      "3433359.0   ItuzaingÃ³                      832\n",
      "            Villa Udaondo                   25\n",
      "3435548.0   Centro                         231\n",
      "            Centro / Microcentro           223\n",
      "3435907.0   Bs.As. G.B.A. Zona Norte       222\n",
      "            Bs.As. G.B.A. Zona Oeste        65\n",
      "            Bs.As. G.B.A. Zona Sur          24\n",
      "            Buenos Aires Costa AtlÃ¡ntica    27\n",
      "            Buenos Aires Interior          106\n"
     ]
    }
   ],
   "source": [
    "mask_geonames_id_nonull = data_trabajo.geonames_id.notnull()\n",
    "df_geonames_id_place_name_ag = data_trabajo.loc[mask_geonames_id_nonull]\n",
    "\n",
    "grouped = df_geonames_id_place_name_ag.groupby(['geonames_id',  'place_name_new'])\n",
    "grouped1 = grouped['Id_caso'].agg([np.size])\n",
    "\n",
    "df_agrupado2 = grouped1.groupby(['geonames_id']).filter(lambda grp: grp[\"size\"].count() > 1)\n",
    "print ('Casos que un mismo geonames_id tiene asignado mÃ¡s de un place_name')\n",
    "print ('------------------------------------------------------------------')\n",
    "print (df_agrupado2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen 5 valores de `geonames_id` que tiene mas de un valor de `place_name` por lo que nos vemos en la necesidad de analizar un poco mas, para ver si corresponden a la misma zona y ver que trabajo hacemos sobre ellos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzamos con el proceso de anÃ¡lisis y actualizaciÃ³n de los los casos:\n",
      "-----------------------------------------------------------------------\n",
      "geonames_id = 3428927\n",
      "----------------------\n",
      "|Argentina|Bs.As. G.B.A. Zona Sur|Lomas de Zamora|San JosÃ©|    11\n",
      "|Argentina|Bs.As. G.B.A. Zona Sur|Almirante Brown|San Jose|     5\n",
      "Name: place_with_parent_names, dtype: int64\n",
      "Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
      "3428927.0    16\n",
      "Name: geonames_id, dtype: int64\n",
      "Resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id\n",
      "Validamos en google que la localidad de \"San Jose\" corresponde al partido de \"Almirante Brown\"\n",
      "Para esos registros mask_place_with_parent_names = |Argentina|Bs.As. G.B.A. Zona Sur|Lomas de Zamora|San JosÃ©|\n",
      "Actualizamos la variable Partido_barrio = \"Almirante Brown\"\n",
      "Actualizamos la variable Localidad = \"San Jose\"\n",
      "Actualizamos la variable place_name_new = \"San Jose\"\n",
      "Cantidad de casos para actualizar:\n",
      "Lomas de Zamora    11\n",
      "Name: Partido_barrio, dtype: int64\n",
      "Cantidad de casos actualizados:\n",
      "Almirante Brown    11\n",
      "Name: Partido_barrio, dtype: int64\n",
      "Cantidad de casos para actualizar:\n",
      "San JosÃ©    11\n",
      "Name: Localidad, dtype: int64\n",
      "Cantidad de casos actualizados:\n",
      "San Jose    11\n",
      "Name: Localidad, dtype: int64\n",
      "Cantidad de casos para actualizar:\n",
      "San JosÃ©    11\n",
      "Name: place_name_new, dtype: int64\n",
      "Cantidad de casos actualizados:\n",
      "San Jose    11\n",
      "Name: place_name_new, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print ('Comenzamos con el proceso de anÃ¡lisis y actualizaciÃ³n de los los casos:')\n",
    "print ('-----------------------------------------------------------------------')\n",
    "print ('geonames_id = 3428927')\n",
    "print ('----------------------')\n",
    "# geonames_id = 3428927\n",
    "    # mascara de id\n",
    "mask_geonames_id  = data_trabajo.geonames_id == 3428927\n",
    "    # traemos la informacion de esos casos \n",
    "ver = data_trabajo.loc[mask_geonames_id,['place_with_parent_names']]\n",
    "print (ver.place_with_parent_names.value_counts())\n",
    "print ('Validamos que para esos place_with_parent_names no existan otros geonames_id')\n",
    "    # Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
    "valores = ['|Argentina|Bs.As. G.B.A. Zona Sur|Lomas de Zamora|San JosÃ©|','|Argentina|Bs.As. G.B.A. Zona Sur|\\\n",
    "Almirante Brown|San Jose|']\n",
    "mask_place_with_parent_names  =  ([x in valores for x in data_trabajo.place_with_parent_names]) \n",
    "ver1 = data_trabajo.loc[mask_place_with_parent_names,['geonames_id'] ]\n",
    "print (ver1.geonames_id.value_counts())\n",
    "print ('Resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id')\n",
    "print ('Validamos en google que la localidad de \"San Jose\" corresponde al partido de \"Almirante Brown\"')\n",
    "print ('Para esos registros mask_place_with_parent_names = |Argentina|Bs.As. G.B.A. Zona Sur|Lomas de Zamora|San JosÃ©|')\n",
    "print ('Actualizamos la variable Partido_barrio = \"Almirante Brown\"')\n",
    "print ('Actualizamos la variable Localidad = \"San Jose\"')\n",
    "print ('Actualizamos la variable place_name_new = \"San Jose\"')\n",
    "    \n",
    "    # resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id\n",
    "    # validamos en google que la localidad de 'San Jose' corresponde al partido de 'Almirante Brown'\n",
    "    # para esos registros mask_place_with_parent_names = |Argentina|Bs.As. G.B.A. Zona Sur|Lomas de Zamora|San JosÃ©|\n",
    "    # actualizamos la variable Partido_barrio = 'Almirante Brown'\n",
    "    # actualizamos la variable Localidad = 'San Jose'\n",
    "    # actualizamos la variable place_name_new = 'San Jose'\n",
    "\n",
    "# creamos una veriable igual a geonames_id sobre le df para trabajar sobre esa\n",
    "data_trabajo['geonames_id_new'] = data_trabajo.geonames_id\n",
    "# mascara de geonames_id \n",
    "mask_geonames_id  = data_trabajo.geonames_id == 3428927\n",
    "mask_place_with_parent_names = data_trabajo.place_with_parent_names == '|Argentina|Bs.As. G.B.A. Zona Sur|\\\n",
    "Lomas de Zamora|San JosÃ©|'\n",
    "# actualizamos el valor de Partido_barrio para los casos de la mascara\n",
    "print ('Cantidad de casos para actualizar:')\n",
    "data_antes = data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names,['Partido_barrio']]\n",
    "print (data_antes.Partido_barrio.value_counts())\n",
    "data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names,['Partido_barrio']] = 'Almirante Brown'\n",
    "print ('Cantidad de casos actualizados:')\n",
    "data_despues = data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names,['Partido_barrio']]\n",
    "print (data_despues.Partido_barrio.value_counts())\n",
    "# actualizamos el valor de Localidad para los casos de la mascara\n",
    "print ('Cantidad de casos para actualizar:')\n",
    "data_antes = data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names,['Localidad']]\n",
    "print (data_antes.Localidad.value_counts())\n",
    "data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names,['Localidad']] = 'San Jose'\n",
    "print ('Cantidad de casos actualizados:')\n",
    "data_despues = data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names,['Localidad']]\n",
    "print (data_despues.Localidad.value_counts())\n",
    "# actualizamos el valor de place_name_new para los casos de la mascara\n",
    "print ('Cantidad de casos para actualizar:')\n",
    "data_antes =  data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names,['place_name_new']]\n",
    "print (data_antes.place_name_new.value_counts())\n",
    "data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names,['place_name_new']] = 'San Jose'\n",
    "print ('Cantidad de casos actualizados:')\n",
    "data_despues = data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names,['place_name_new']]\n",
    "print (data_despues.place_name_new.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geonames_id = 3430234\n",
      "----------------------\n",
      "|Argentina|Capital Federal|Palermo|                 2885\n",
      "|Argentina|Capital Federal|Palermo|Palermo Soho|     394\n",
      "Name: place_with_parent_names, dtype: int64\n",
      "Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
      "3430234.0    3279\n",
      "Name: geonames_id, dtype: int64\n",
      "Resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id\n",
      "Vamos a dejar geonames_id_new en nulo para el caso de \"Palermo Soho\" que es mas abarcativa para sumarlo\n",
      "Al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
      "Cantidad original de casos para actualizar:\n",
      "3430234.0    394\n",
      "Name: geonames_id_new, dtype: int64\n",
      "Cantidad posterior de casos para actualizar:\n",
      "Series([], Name: geonames_id_new, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#..................................\n",
    "# geonames_id = 3430234, 3433359, 3435548\n",
    "    # mascara de id\n",
    "print ('geonames_id = 3430234')\n",
    "print ('----------------------')\n",
    "mask_geonames_id  = data_trabajo.geonames_id == 3430234\n",
    "# traemos la informacion de esos casos \n",
    "ver = data_trabajo.loc[mask_geonames_id,['place_with_parent_names']]\n",
    "print (ver.place_with_parent_names.value_counts())\n",
    "print ('Validamos que para esos place_with_parent_names no existan otros geonames_id')\n",
    "    # Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
    "valores = ['|Argentina|Capital Federal|Palermo|','|Argentina|Capital Federal|Palermo|Palermo Soho|']\n",
    "mask_place_with_parent_names  =  ([x in valores for x in data_trabajo.place_with_parent_names]) \n",
    "ver1 = data_trabajo.loc[mask_place_with_parent_names,['geonames_id']]\n",
    "print (ver1.geonames_id.value_counts())\n",
    "print ('Resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id')\n",
    "print ('Vamos a dejar geonames_id_new en nulo para el caso de \"Palermo Soho\" que es mas abarcativa para sumarlo') \n",
    "print ('Al tratamiente que vamos hacer despues con los nulos de geonames_id')\n",
    "    # resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id\n",
    "    # vamos a dejar geonames_id_new en nulo para el caso de 'Palermo Soho' que es mas abarcativa para sumarlo \n",
    "    # al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
    "# mascara\n",
    "mask_place_with_parent_names1 = data_trabajo.place_with_parent_names == '|Argentina|Capital Federal|Palermo|Palermo Soho|'\n",
    "data_antes =   data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']]\n",
    "print ('Cantidad original de casos para actualizar:')\n",
    "print(data_antes.geonames_id_new.value_counts())\n",
    "data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']] = None\n",
    "print ('Cantidad posterior de casos para actualizar:')\n",
    "data_despues =   data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']]\n",
    "print(data_despues.geonames_id_new.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geonames_id = 3433359\n",
      "---------------------\n",
      "|Argentina|Bs.As. G.B.A. Zona Oeste|ItuzaingÃ³|                  474\n",
      "|Argentina|Bs.As. G.B.A. Zona Oeste|ItuzaingÃ³|ItuzaingÃ³|        358\n",
      "|Argentina|Bs.As. G.B.A. Zona Oeste|ItuzaingÃ³|Villa Udaondo|     25\n",
      "Name: place_with_parent_names, dtype: int64\n",
      "Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
      "3433359.0    857\n",
      "Name: geonames_id, dtype: int64\n",
      "Resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id\n",
      "Vamos a dejar geonames_id en nulo para el caso de \"Villa Udaondo\" que es mas abarcativa para sumarlo\n",
      "Al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
      "Cantidad original de casos para actualizar:\n",
      "3433359.0    25\n",
      "Name: geonames_id_new, dtype: int64\n",
      "Cantidad posterior de casos para actualizar:\n",
      "Series([], Name: geonames_id_new, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#..................................\n",
    "# geonames_id =  3433359\n",
    "    # mascara de id\n",
    "mask_geonames_id  = data_trabajo.geonames_id == 3433359\n",
    "print ('geonames_id = 3433359')\n",
    "print ('---------------------')\n",
    "    # traemos la informacion de esos casos \n",
    "ver = data_trabajo.loc[mask_geonames_id,['place_with_parent_names'] ]\n",
    "print (ver.place_with_parent_names.value_counts())\n",
    "print ('Validamos que para esos place_with_parent_names no existan otros geonames_id')\n",
    "    # Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
    "valores = ['|Argentina|Bs.As. G.B.A. Zona Oeste|ItuzaingÃ³|','|Argentina|Bs.As. G.B.A. Zona Oeste|ItuzaingÃ³|ItuzaingÃ³|','|Argentina|Bs.As. G.B.A. Zona Oeste|ItuzaingÃ³|Villa Udaondo|']\n",
    "mask_place_with_parent_names  =  ([x in valores for x in data_trabajo.place_with_parent_names]) \n",
    "ver1 = data_trabajo.loc[mask_place_with_parent_names,['geonames_id']]\n",
    "print (ver1.geonames_id.value_counts())\n",
    "print ('Resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id')\n",
    "print ('Vamos a dejar geonames_id en nulo para el caso de \"Villa Udaondo\" que es mas abarcativa para sumarlo')\n",
    "print ('Al tratamiente que vamos hacer despues con los nulos de geonames_id')\n",
    "    # resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id\n",
    "    # vamos a dejar geonames_id en nulo para el caso de 'Villa Udaondo' que es mas abarcativa para sumarlo \n",
    "    # al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
    "# mascara\n",
    "mask_place_with_parent_names1 = data_trabajo.place_with_parent_names == '|Argentina|Bs.As. G.B.A. Zona Oeste|ItuzaingÃ³|Villa Udaondo|'\n",
    "data_antes =   data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']]\n",
    "print ('Cantidad original de casos para actualizar:')\n",
    "print(data_antes.geonames_id_new.value_counts())\n",
    "data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']] = None\n",
    "print ('Cantidad posterior de casos para actualizar:')\n",
    "data_despues =   data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']]\n",
    "print(data_despues.geonames_id_new.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geonames_id = 3435548\n",
      "---------------------\n",
      "|Argentina|Buenos Aires Costa AtlÃ¡ntica|Mar del Plata|Centro|    231\n",
      "|Argentina|Capital Federal|Centro / Microcentro|                 223\n",
      "Name: place_with_parent_names, dtype: int64\n",
      "Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
      "3435548.0    454\n",
      "Name: geonames_id, dtype: int64\n",
      "Resultado ... en este caso no corresponde a la mimsa zona, pero no existen mask_place_with_parent_names para otros geonames_id\n",
      "Vamos a dejar geonames_id en nulo para el caso de \"Mar del Plata\" solo para por simple elecciÃ³n y lo vamos a sumar\n",
      "Al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
      "Cantidad original de casos para actualizar:\n",
      "3435548.0    231\n",
      "Name: geonames_id_new, dtype: int64\n",
      "Cantidad posterior de casos para actualizar:\n",
      "Series([], Name: geonames_id_new, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#..................................\n",
    "# geonames_id = 3430234, 3433359, 3435548\n",
    "    # mascara de id\n",
    "print ('geonames_id = 3435548')\n",
    "print ('---------------------')\n",
    "mask_geonames_id  = data_trabajo.geonames_id == 3435548\n",
    "    # traemos la informacion de esos casos \n",
    "ver = data_trabajo.loc[mask_geonames_id,['place_with_parent_names'] ]\n",
    "print (ver.place_with_parent_names.value_counts())\n",
    "print ('Validamos que para esos place_with_parent_names no existan otros geonames_id')\n",
    "    # Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
    "valores = ['|Argentina|Buenos Aires Costa AtlÃ¡ntica|Mar del Plata|Centro|','|Argentina|Capital Federal|Centro / Microcentro|']\n",
    "mask_place_with_parent_names  =  ([x in valores for x in data_trabajo.place_with_parent_names]) \n",
    "ver1 = data_trabajo.loc[mask_place_with_parent_names,['geonames_id'] ]\n",
    "print (ver1.geonames_id.value_counts())\n",
    "print ('Resultado ... en este caso no corresponde a la mimsa zona, pero no existen mask_place_with_parent_names para otros geonames_id')\n",
    "print ('Vamos a dejar geonames_id en nulo para el caso de \"Mar del Plata\" solo para por simple elecciÃ³n y lo vamos a sumar')\n",
    "print ('Al tratamiente que vamos hacer despues con los nulos de geonames_id')\n",
    "    # resultado ... en este caso no corresponde a la mimsa zona, pero no existen mask_place_with_parent_names para otros geonames_id\n",
    "    # vamos a dejar geonames_id en nulo para el caso de 'Mar del Plata' solo para por simple elecciÃ³n y lo vamos a sumar\n",
    "    # al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
    "# mascara\n",
    "mask_place_with_parent_names1 = data_trabajo.place_with_parent_names == '|Argentina|Buenos Aires Costa AtlÃ¡ntica|Mar del Plata|Centro|'\n",
    "data_antes =   data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']]\n",
    "print ('Cantidad original de casos para actualizar:')\n",
    "print(data_antes.geonames_id_new.value_counts())\n",
    "data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']] = None\n",
    "print ('Cantidad posterior de casos para actualizar:')\n",
    "data_despues =   data_trabajo.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']]\n",
    "print(data_despues.geonames_id_new.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geonames_id = 3435907\n",
      "---------------------\n",
      "|Argentina|Bs.As. G.B.A. Zona Norte|        222\n",
      "|Argentina|Buenos Aires Interior|           106\n",
      "|Argentina|Bs.As. G.B.A. Zona Oeste|         65\n",
      "|Argentina|Buenos Aires Costa AtlÃ¡ntica|     27\n",
      "|Argentina|Bs.As. G.B.A. Zona Sur|           24\n",
      "Name: place_with_parent_names, dtype: int64\n",
      "Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
      "3435907.0    444\n",
      "Name: geonames_id, dtype: int64\n",
      "Resultado ... en este caso no corresponde a la mimsa zona, pero no existen mask_place_with_parent_names para otros geonames_id\n",
      "Vamos a dejar geonames_id en nulo para todos los casos y lo vamos a sumar\n",
      "Al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
      "Cantidad original de casos para actualizar:\n",
      "3435907.0    444\n",
      "Name: geonames_id_new, dtype: int64\n",
      "Cantidad posterior de casos para actualizar:\n",
      "Series([], Name: geonames_id_new, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#..................................\n",
    "# geonames_id = 3435907\n",
    "    # mascara de id\n",
    "print ('geonames_id = 3435907')\n",
    "print ('---------------------')\n",
    "valores_geonames_id = [3435907]\n",
    "mask_geonames_id  = ([x in valores_geonames_id for x in data_trabajo.geonames_id]) \n",
    "    # traemos la informacion de esos casos \n",
    "ver = data_trabajo.loc[mask_geonames_id,['place_with_parent_names'] ]\n",
    "print (ver.place_with_parent_names.value_counts())\n",
    "print ('Validamos que para esos place_with_parent_names no existan otros geonames_id')\n",
    "    # Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
    "valores = ['|Argentina|Bs.As. G.B.A. Zona Norte|','|Argentina|Bs.As. G.B.A. Zona Oeste|','|Argentina|Bs.As. G.B.A. Zona Sur|','|Argentina|Buenos Aires Costa AtlÃ¡ntica|','|Argentina|Buenos Aires Interior|']\n",
    "mask_place_with_parent_names  =  ([x in valores for x in data_trabajo.place_with_parent_names]) \n",
    "ver1 = data_trabajo.loc[mask_place_with_parent_names,['geonames_id'] ]\n",
    "print (ver1.geonames_id.value_counts())\n",
    "print ('Resultado ... en este caso no corresponde a la mimsa zona, pero no existen mask_place_with_parent_names para otros geonames_id')\n",
    "print ('Vamos a dejar geonames_id en nulo para todos los casos y lo vamos a sumar')\n",
    "print ('Al tratamiente que vamos hacer despues con los nulos de geonames_id')\n",
    "    # resultado ... en este caso no corresponde a la mimsa zona, pero no existen mask_place_with_parent_names para otros geonames_id\n",
    "    # vamos a dejar geonames_id en nulo para todos los casos y lo vamos a sumar\n",
    "    # al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
    "# mascara\n",
    "data_antes =   data_trabajo.loc[mask_geonames_id, ['geonames_id_new']]\n",
    "print ('Cantidad original de casos para actualizar:')\n",
    "print(data_antes.geonames_id_new.value_counts())\n",
    "data_trabajo.loc[mask_geonames_id, ['geonames_id_new']] = None\n",
    "print ('Cantidad posterior de casos para actualizar:')\n",
    "data_despues =   data_trabajo.loc[mask_geonames_id, ['geonames_id_new']]\n",
    "print(data_despues.geonames_id_new.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable geonames_id\n",
      "Vamos a analizar como podemos actualizar los valores nulos\n",
      "----------------------------------------------------------\n",
      "Cantidad de valores nulos: 19811\n",
      "Cantidad de valores distintos: 646\n",
      "Valor mÃ­nimo: 3427208.0\n",
      "Valor mÃ¡ximo: 6948895.0\n",
      "Cantidad de valores nulos final: 610\n",
      "Cantidad de valores distintos final: 1107\n",
      "Casos que un mismo geonames_id tiene asignado mÃ¡s de un place_name\n",
      "------------------------------------------------------------------\n",
      "Empty DataFrame\n",
      "Columns: [size]\n",
      "Index: []\n",
      "Casos con geonames_id nulo\n",
      "--------------------------\n",
      "|Argentina|Bs.As. G.B.A. Zona Norte|                                     222\n",
      "|Argentina|Buenos Aires Interior|                                        106\n",
      "|Argentina|TucumÃ¡n|                                                       77\n",
      "|Argentina|Bs.As. G.B.A. Zona Oeste|                                      65\n",
      "|Argentina|Buenos Aires Interior|ChascomÃºs|ChascomÃºs|                     54\n",
      "|Argentina|Buenos Aires Costa AtlÃ¡ntica|                                  27\n",
      "|Argentina|Bs.As. G.B.A. Zona Sur|                                        24\n",
      "|Argentina|Buenos Aires Interior|Berisso|Berisso|                         16\n",
      "|Argentina|Buenos Aires Interior|ZÃ¡rate|ZÃ¡rate|                            7\n",
      "|Argentina|Buenos Aires Interior|Campana|Campana|                          6\n",
      "|Argentina|Buenos Aires Interior|General Las Heras|General Las Heras|      3\n",
      "|Argentina|Buenos Aires Interior|Azul|Azul|                                2\n",
      "|Argentina|Buenos Aires Interior|JunÃ­n|JunÃ­n|                              1\n",
      "Name: place_with_parent_names, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print('Variable geonames_id')\n",
    "print('Vamos a analizar como podemos actualizar los valores nulos')\n",
    "print('----------------------------------------------------------')\n",
    "print('Cantidad de valores nulos: ' + str(data_trabajo.geonames_id_new.isnull().sum()))\n",
    "print('Cantidad de valores distintos: ' + str(len(data_trabajo.geonames_id_new.unique())))\n",
    "print('Valor mÃ­nimo: ' + str(data_trabajo.geonames_id_new.min()))\n",
    "print('Valor mÃ¡ximo: ' + str(data_trabajo.geonames_id_new.max()))\n",
    "# vamos a trabajar los nulos del campo geonames_id_new\\n# y lo hacemos por zonas:\n",
    "# definimos 3 zonas de acuerdo al analisis del dato faltante de los procesos sobre place_with_parent_names\n",
    "# valores_geo_grupo1  = \\'Bs.As. G.B.A. Zona Norte\\',\\'Bs.As. G.B.A. Zona Oeste\\',\\'Bs.As. G.B.A. Zona Sur\\',\\'Capital Federal\\'\\n# mas valores_geo_interior\\n    \n",
    "    # si no tiene sino tiene Partido_barrio informado lo dejamos nulo ya que no seria correcto asignar un valor ya que \\n    \n",
    "    # abarca demasiado territorio\\n    \n",
    "    # si tiene Partido_barrio asigamos un numero al azar que identificara el place_name\\n\n",
    "# valores_geo_grupo2 = \\'Buenos Aires Costa AtlÃ¡ntica\\', \\'Buenos Aires Interior\\'\\n    \n",
    "    # si no tiene sino tiene Partido_barrio informado lo dejamos nulo ya que no seria correcto asignar un valor ya que \\n    \n",
    "    # abarca demasiado territorio\\n    \n",
    "    # si tiene Partido_barrio y Localidad, y NO son iguales asigamos un numero al azar que identificara el place_name\\n    \n",
    "    # si tiene Partido_barrio y Localidad, y SI son iguales asigamos, buscamos el ID del Partido_barrio \\n    \n",
    "# que si estÃ¡ informado\\n\\n\n",
    "# creamos los grupos\\n\n",
    "valores_geo_grupo1 = ['Bs.As. G.B.A. Zona Norte','Bs.As. G.B.A. Zona Oeste','Bs.As. G.B.A. Zona Sur','Capital Federal']\n",
    "valores_geo_grupo2 = ['Buenos Aires Costa AtlÃ¡ntica', 'Buenos Aires Interior']\n",
    "valores_geo_interior_temp = data_trabajo.Zona.unique()\n",
    "valores_geo_interior_y_1 = list(set(valores_geo_interior_temp).difference(set(valores_geo_grupo2)))\n",
    "\n",
    "mask_geo_grupo2  =  ([x in valores_geo_grupo2 for x in data_trabajo.Zona])\n",
    "mask_geo_interior_y_1  =  ([x in valores_geo_interior_y_1 for x in data_trabajo.Zona])\n",
    "mask_geo_null = data_trabajo.geonames_id_new.isnull()\n",
    "#mask_Partido_barrio_notnull = data_trabajo.Partido_barrio.notnull()\n",
    "mask_Partido_barrio_null =  (data_trabajo.Partido_barrio.isnull()) | (data_trabajo.Partido_barrio == '')\n",
    "mask_Partido_barrio_notnull = mask_data_Partido_barrio_null == False\n",
    "mask_PB_dist_Localidad = data_trabajo.Partido_barrio != data_trabajo.Localidad\n",
    "\n",
    "# Creamos una serie con los distintos valores de place_name que no interesa aplicarle una numero al azar\n",
    "groupby_place_name_null = data_trabajo.loc[(mask_geo_interior_y_1 & mask_geo_null & mask_Partido_barrio_notnull)\\\n",
    "                                   | (mask_geo_grupo2&mask_geo_null&mask_Partido_barrio_notnull&mask_PB_dist_Localidad)\\\n",
    "                                   ].groupby(['place_name_new'])[\"Id_caso\"].count()\n",
    "# convertimos la seria en un df para trabajarlo\n",
    "groupby_place_name_null_df = groupby_place_name_null.to_frame()\n",
    "# asignamos a cada valor el nÃºmero aleatorio partiendo de un numero lo bastante grande para que\n",
    "# coincida con los existentes\n",
    "groupby_place_name_null_df[\"geonames_id_temp\"] = groupby_place_name_null_df.apply(lambda x: random.randint(10000000, 20000000), axis=1)\n",
    "\n",
    "# creamos un nuevo df sumando el campo nuevo \n",
    "datay = pd.merge(left=data_trabajo,right=groupby_place_name_null_df, how='left', left_on='place_name_new', \\\n",
    "                 right_on='place_name_new')\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "# actualizamos los casos que convertimos a nulo en el arreglo de geonames_id\n",
    "#mask_geo_temp = ['|Argentina|Capital Federal|Palermo|Palermo Soho|']\n",
    "#mask_geo_temp1  =  ([x in mask_geo_temp for x in datay.place_with_parent_names])\n",
    "#max_valor = datay.geonames_id_temp.max()\n",
    "#max_valor = max_valor + 1\n",
    "#print(max_valor)\n",
    "#datay.loc[mask_geo_temp1, 'geonames_id_temp'] = datay.loc[mask_geo_temp1, 'geonames_id_temp'].apply(lambda x: max_valor)\n",
    "#['|Argentina|Buenos Aires Costa AtlÃ¡ntica|Mar del Plata|Centro|']\n",
    "#['|Argentina|Bs.As. G.B.A. Zona Oeste|ItuzaingÃ³|Villa Udaondo|']\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "mask_geo_null = data_trabajo.geonames_id_new.isnull()\n",
    "datay.loc[mask_geo_null, 'geonames_id_new'] = datay.loc[mask_geo_null, 'geonames_id_temp']\n",
    "del datay['Id_caso_y']\n",
    "datay.rename(columns={'Id_caso_x': 'Id_caso'}, inplace=True)\n",
    "print('Cantidad de valores nulos final: ' + str(datay.geonames_id_new.isnull().sum()))\n",
    "print('Cantidad de valores distintos final: ' + str(len(datay.geonames_id_new.unique())))\n",
    "\n",
    "#Validamos que luego de la aplicacion de nulos no hayan quedado para un mismo \n",
    "# geonames_id a distintos valores de place_name_new\n",
    "\n",
    "# variable geonames_id,  corresponde al id asignado a cada place_name\n",
    "# volvemos a validar que No se asigne un mismo geonames_id a distintos valores de place_name_new\n",
    "mask_geonames_id_new_notnull = datay.geonames_id_new.notnull()\n",
    "df_geonames_id_place_name_ag2 = datay.loc[mask_geonames_id_new_notnull]\n",
    "\n",
    "grouped_0 = df_geonames_id_place_name_ag2.groupby(['geonames_id_new',  'place_name_new'])\n",
    "grouped_1 = grouped_0['Id_caso'].agg([np.size])\n",
    "\n",
    "df_agrupado_2 = grouped_1.groupby(['geonames_id_new']).filter(lambda grp: grp[\"size\"].count() > 1)\n",
    "print ('Casos que un mismo geonames_id tiene asignado mÃ¡s de un place_name')\n",
    "print ('------------------------------------------------------------------')\n",
    "print (df_agrupado_2)\n",
    "\n",
    "data_trabajo = datay\n",
    "data_trabajo.drop(\"geonames_id_temp\", axis = 1, inplace=True)\n",
    "\n",
    "print ('Casos con geonames_id nulo')\n",
    "print ('--------------------------')\n",
    "# actualizo la mascara de los nulos\n",
    "mask_geo_null = data_trabajo.geonames_id_new.isnull()\n",
    "print (data_trabajo.loc[mask_geo_null, 'place_with_parent_names'].value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso de validaciÃ³n de los campos Lat-Lon vs Lat / Lon\n",
      "--------------------------------------------------------\n",
      "lat-lon    69670\n",
      "lat        69670\n",
      "lon        69670\n",
      "dtype: int64\n",
      "Cantidad de casos iguales latitud: 69502\n",
      "Cantidad de casos iguales longitud: 69396\n"
     ]
    }
   ],
   "source": [
    "print ('Proceso de validaciÃ³n de los campos Lat-Lon vs Lat / Lon')\n",
    "print ('--------------------------------------------------------')\n",
    "# validamos que los campos Lat y Lon tengan la misma cantidad y valor de info que Lat-Lon\n",
    "# primero separamos el campo Lat-Lon\n",
    "df_lat_lon  = data_trabajo.loc[:,[\"Id_caso\",\"lat-lon\", \"lat\", \"lon\"]].join(data[\"lat-lon\"].str.split(',', expand=True).rename(columns={\n",
    "                                                                                                0:'lat_temp', \n",
    "                                                                                                1:'lon_temp'}))\n",
    "# los campos saparados los convierto en numÃ©ricos\n",
    "df_lat_lon.lat_temp = df_lat_lon.lat_temp.apply(pd.to_numeric)\n",
    "df_lat_lon.lon_temp = df_lat_lon.lon_temp.apply(pd.to_numeric)\n",
    "\n",
    "# Validmos que los campos tengan la misma cantidad de NO nulos\n",
    "print (df_lat_lon[[\"lat-lon\", \"lat\", \"lon\"]].notnull().sum())\n",
    "# mascara de no nulos\n",
    "mask_notnull = df_lat_lon[\"lat-lon\"].notnull()\n",
    "# mascara de valores iguales \n",
    "ver_lat = round(df_lat_lon.lat,6) == round(df_lat_lon.lat_temp,6)\n",
    "ver_lon = round(df_lat_lon.lon,6) == round(df_lat_lon.lon_temp,6)\n",
    "# validamos la cantidad de casos\n",
    "print ('Cantidad de casos iguales latitud: ' + str(ver_lat.sum()))\n",
    "print ('Cantidad de casos iguales longitud: ' + str(ver_lon.sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso de validaciÃ³n de tipo de cambio\n",
      "---------------------------------------\n",
      "Distintos tipos de moneda:\n",
      "USD    87587\n",
      "ARS    13219\n",
      "PEN        2\n",
      "UYU        1\n",
      "Name: currency, dtype: int64\n",
      "Los valores \"PEN\" y \"UYU\" los actualizamos a nulos para no descartarlos\n",
      "Distintos valores del tipo de cambio luego de actualizar la variable creada\n",
      "17.64    100806\n",
      "0.00      20414\n",
      "Name: Valor_dolar, dtype: int64\n",
      "Vemos que existe un solo valor ... Exc!\n",
      "Llegamos a la conclusion que es posible usar la variable price_aprox_usd como precio de la propiedad estÃ¡ndar\n"
     ]
    }
   ],
   "source": [
    "print ('Proceso de validaciÃ³n de tipo de cambio')\n",
    "print ('---------------------------------------')\n",
    "# proceso de validaciÃ³n del tipo de cambio para validar si es correcto tomar el \n",
    "# el campo price_aprox_usd para todos los casos\n",
    "\n",
    "# validamos que si currency (moneda) = \n",
    "# nulo  ----> nulo\n",
    "# 'USD'  ----> price_aprox_local_currency / price  ----> valor por dolar de precios en dolares\n",
    "# sino ---->price_aprox_local_currency / price_aprox_usd ----> valor por dolar de precios en pesos\n",
    "# agrupamos los valores por dolar ... redondeado a 2 dÃ­gitos\n",
    "\n",
    "#.................................................\n",
    "print ('Distintos tipos de moneda:')\n",
    "# Vemos los distintos valores de la variable moneda\n",
    "print(data_trabajo.currency.value_counts())\n",
    "# vemos que existen 3 registros con valores PEN (sol peruano) y UYU (peso Uruguayo)\n",
    "# vemos los casos\n",
    "print ('Los valores \"PEN\" y \"UYU\" los actualizamos a nulos para no descartarlos')\n",
    "valores_otras_monedas = ['PEN', 'UYU']\n",
    "mask_otras_monedas = [x in valores_otras_monedas for x in data_trabajo.currency]\n",
    "data_trabajo.loc[mask_otras_monedas, [\"currency\",\"price\"]] = None\n",
    "\n",
    "# sumamos la varible al Df Valor_dolar\n",
    "data_trabajo[\"Valor_dolar\"] = 0\n",
    "# trabajamos la moneda = 'USD'\n",
    "mask_dolar = data_trabajo.currency == 'USD'\n",
    "mask_price = (data_trabajo.price != 0) | (data_trabajo.price.notnull())\n",
    "data_trabajo.loc[mask_dolar & mask_price, \"Valor_dolar\"] = round(data_trabajo.price_aprox_local_currency / data_trabajo.price,2)\n",
    "# trabajamos la moneda = 'ARG'\n",
    "mask_peso = data_trabajo.currency == 'ARS'\n",
    "mask_price_aprox_usd = (data_trabajo.price_aprox_usd != 0) | (data_trabajo.price_aprox_usd.notnull())\n",
    "data_trabajo.loc[mask_peso & mask_price_aprox_usd, \"Valor_dolar\"] = round(data_trabajo.price_aprox_local_currency / data_trabajo.price_aprox_usd,2)\n",
    "print ('Distintos valores del tipo de cambio luego de actualizar la variable creada')\n",
    "# vemos los valores distintos para valor de dolar\n",
    "print(data_trabajo.Valor_dolar.value_counts())\n",
    "print ('Vemos que existe un solo valor ... Exc!')\n",
    "print ('Llegamos a la conclusion que es posible usar la variable price_aprox_usd como precio de la propiedad estÃ¡ndar')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso de anÃ¡lisis del precio por m2\n",
      "-------------------------------------\n",
      "Variables:\n",
      "- price_usd_per_m2\n",
      "- price_per_m2\n",
      "Al ver alguno ejemplos vamos a validar que:\n",
      "price_usd_per_m2 corresponde al precio en dÃ³lares sobre la superficie total en m2(price_aprox_usd / surface_total_in_m2)\n",
      "y que price_per_m2 corresponde al precio original sobre la superficie cubierta(price / surface_covered_in_m2)\n",
      "por lo que sobre esta Ãºltima, ademas vamos a estandarizarla a dÃ³lares sobre una nueva variable\n",
      "ValidaciÃ³n de price_usd_per_m2\n",
      "------------------------------\n",
      "Luego de \"imitar\" la variable agrupamos por la marca si coinciden o no con la variable original:\n",
      "False    68614\n",
      "True     52606\n",
      "dtype: int64\n",
      "Vemos que hay 52606 que no coinciden\n",
      "Validamos que todos los casos que correspondan a los valores nulos, mediante una mÃ¡scara\n",
      "True     52603\n",
      "False        3\n",
      "Name: price_usd_per_m2, dtype: int64\n",
      "ConclusiÃ³n: la variable price_usd_per_m2 corresponde a\n",
      "a price_aprox_usd / surface_total_in_m2\n",
      "ValidaciÃ³n de price_per_m2\n",
      "------------------------------\n",
      "Luego de \"imitar\" la variable agrupamos por la marca si coinciden o no con la variable original:\n",
      "False    87658\n",
      "True     33562\n",
      "dtype: int64\n",
      "Vemos que hay 33562 que no coinciden\n",
      "Validamos que todos los casos que correspondan a los valores nulos, mediante una mÃ¡scara\n",
      "True    33562\n",
      "Name: price_per_m2, dtype: int64\n",
      "ConclusiÃ³n: la variable price_per_m2 corresponde a\n",
      "price / surface_covered_in_m2\n"
     ]
    }
   ],
   "source": [
    "print ('Proceso de anÃ¡lisis del precio por m2')\n",
    "print ('-------------------------------------')\n",
    "print('Variables:')\n",
    "print('- price_usd_per_m2')\n",
    "print('- price_per_m2')\n",
    "    \n",
    "print ('Al ver alguno ejemplos vamos a validar que:')\n",
    "print ('price_usd_per_m2 corresponde al precio en dÃ³lares sobre la superficie total en m2(price_aprox_usd / surface_total_in_m2)')\n",
    "print ('y que price_per_m2 corresponde al precio original sobre la superficie cubierta(price / surface_covered_in_m2)')\n",
    "print ('por lo que sobre esta Ãºltima, ademas vamos a estandarizarla a dÃ³lares sobre una nueva variable')\n",
    "    \n",
    "\n",
    "# lo validamos\n",
    "print ('ValidaciÃ³n de price_usd_per_m2')\n",
    "print ('------------------------------')\n",
    "# ----------------------------------price_usd_per_m2\n",
    "# sumamos un nuevo campo \n",
    "data_trabajo[\"price_usd_per_m2_new\"] = -1\n",
    "# mascara de los NO nulos price_aprox_usd\n",
    "mask_price_aprox_usd_notnull = data_trabajo.price_aprox_usd.notnull()\n",
    "# mascara de los no nulos y mayores a cero de surface_total_in_m2\n",
    "mask_surface_total_in_m2_notnull_0 = ((data_trabajo.surface_total_in_m2.notnull()) & (data_trabajo.surface_total_in_m2 > 0))\n",
    "# actualizaciÃ³n de la variable nueva price_usd_per_m2_new\n",
    "data_trabajo.loc[mask_price_aprox_usd_notnull & mask_surface_total_in_m2_notnull_0, \"price_usd_per_m2_new\"] = round(data_trabajo.price_aprox_usd/data_trabajo.surface_total_in_m2,2)\n",
    "# validamos creando una mascara sobre los que NO coinciden variable original vs variable nueva\n",
    "mask_validacion_price_aprox_usd = data_trabajo.price_usd_per_m2_new != round(data_trabajo.price_usd_per_m2,2)\n",
    "print('Luego de \"imitar\" la variable agrupamos por la marca si coinciden o no con la variable original:')\n",
    "# agrupamos por la mascara y vemos que existen 52606 casos que son verdaderos .. NO coinciden\n",
    "print(mask_validacion_price_aprox_usd.value_counts())\n",
    "print('Vemos que hay 52606 que no coinciden')\n",
    "print('Validamos que todos los casos que correspondan a los valores nulos, mediante una mÃ¡scara')\n",
    "# contamos los nulos de esos no coincidentes y vemos que no coinciden porque la variable nueva se \n",
    "# le asigne como valor default -1 y en la variable original estan con nulo\n",
    "print(data_trabajo.loc[mask_validacion_price_aprox_usd, \"price_usd_per_m2\"].isnull().value_counts())\n",
    "print('ConclusiÃ³n: la variable price_usd_per_m2 corresponde a')\n",
    "print('a price_aprox_usd / surface_total_in_m2')\n",
    "\n",
    "# ----------------------------------price_per_m2\n",
    "print ('ValidaciÃ³n de price_per_m2')\n",
    "print ('------------------------------')\n",
    "# sumamos un nuevo campo \n",
    "data_trabajo[\"price_per_m2_new\"] = -1\n",
    "# mascara de los NO nulos price\n",
    "mask_price_notnull = data_trabajo.price.notnull()\n",
    "# mascara de los no nulos y mayores a cero de surface_covered_in_m2\n",
    "mask_surface_covered_in_m2_notnull_0 = ((data_trabajo.surface_covered_in_m2.notnull()) & (data_trabajo.surface_covered_in_m2 > 0))\n",
    "# actualizaciÃ³n de la variable nueva price_per_m2_new\n",
    "data_trabajo.loc[mask_price_notnull & mask_surface_covered_in_m2_notnull_0, \"price_per_m2_new\"] = round(data_trabajo.price/data_trabajo.surface_covered_in_m2,2)\n",
    "# validamos creando una mascara sobre los que NO coinciden variable original vs variable nueva\n",
    "mask_validacion_price_per_m2 = data_trabajo.price_per_m2_new != round(data_trabajo.price_per_m2,2)\n",
    "print('Luego de \"imitar\" la variable agrupamos por la marca si coinciden o no con la variable original:')\n",
    "# agrupamos por la mascara y vemos que existen 33562 casos que son verdaderos .. NO coinciden\n",
    "print(mask_validacion_price_per_m2.value_counts())\n",
    "print('Vemos que hay 33562 que no coinciden')\n",
    "print('Validamos que todos los casos que correspondan a los valores nulos, mediante una mÃ¡scara')\n",
    "# contamos los nulos de esos no coincidentes y vemos que no coinciden porque la variable nueva se \n",
    "# le asigne como valor default -1 y en la variable original estan con nulo\n",
    "print (data_trabajo.loc[mask_validacion_price_per_m2, \"price_per_m2\"].isnull().value_counts())\n",
    "print('ConclusiÃ³n: la variable price_per_m2 corresponde a')\n",
    "print('price / surface_covered_in_m2')\n",
    "# ahora vamos a actualizar la veriable que creamos price_per_m2 pero tomando para el caso de moneda ARG la \n",
    "# variable en dolares price_aprox_usd para que todo quede en la misma moneda\n",
    "# mascara moneda ARG\n",
    "mask_peso = data_trabajo.currency == 'ARS'\n",
    "data_trabajo.loc[mask_peso & mask_surface_covered_in_m2_notnull_0, \"price_per_m2_new\"] = round(data_trabajo.price_aprox_usd/data_trabajo.surface_covered_in_m2,2)\n",
    "# pasamos a nulo los que quedaron con valor -1\n",
    "data_trabajo['price_usd_per_m2_new'].replace(-1, np.nan, inplace=True)\n",
    "data_trabajo['price_per_m2_new'].replace(-1, np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### esto no se ejecuta!!!\n",
    "## de aca en adelante son pruebas\n",
    "\n",
    "\n",
    "BUSCAR DUPLICADOS EN UN DF\n",
    "artist_duplicated = data_artist.duplicated(subset=[\"Artist Display Name\", \"Artist Role\"])\n",
    "any(artist_duplicated) * me devuelve verdadero o falso\n",
    "artist_duplicated.sum()  * me devuelve la cantidad de duplicados\n",
    "BORRO LOS DUPLICADOS\n",
    "data_artist_unique = data_artist.drop_duplicates(subset=[\"Artist Display Name\", \"Artist Role\"], keep=\"first\")\n",
    "keep ... \n",
    "* first: devuelve False (no duplicado) el primer registro encontrado, y True (duplicados) todas las demÃ¡s apariciones\n",
    "* last: devuelve False (no duplicado) el Ãºltimo registro encontrado, y True (duplicados) todas las demÃ¡s apariciones\n",
    "* False: devuelve True (duplicado) todos los registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         False\n",
       "1          True\n",
       "2          True\n",
       "3          True\n",
       "4          True\n",
       "          ...  \n",
       "121215     True\n",
       "121216     True\n",
       "121217     True\n",
       "121218     True\n",
       "121219     True\n",
       "Length: 121220, dtype: bool"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver = data_trabajo.duplicated(subset=[\"currency\"])\n",
    "data_artist_unique = data_artist.drop_duplicates(subset=[\"Artist Display Name\", \"Artist Role\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na.to_csv('data_output/surveys_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_re\"></a> \n",
    "## Expresiones Regulares\n",
    "\n",
    " Segun la cantidad de registros completados sobre las Series `title` `description` del dataset decidimos realizar una analisis exploratorio sobre los patrones de texto que hacen referencia a los siguientes elementos:\n",
    " - Precios de inmuebles en dolares.\n",
    " - Metros cuadrados.\n",
    " - Ambientes.\n",
    " - Amenities: cochera, balcon, parrilla, pileta/piscina, baulera, lavadero, terraza y jardin.\n",
    " \n",
    "La busqueda de patrones de texto se realizo mediante el uso de expresiones regulares. En el armado de los patrones de busqueda se tuvo en consideracion el contexto donde se encontraba la cadena de caracteres a ser extraida para minimizar el numero de falsos positivos.\n",
    "\n",
    "Luego se aplico el uso de outliers para identificar casos extremos que pudieran indicar la existencia de valores falsos.\n",
    "\n",
    "[volver a TOC](#section_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_re_pg\"></a> \n",
    "### **Principios generales**\n",
    "\n",
    "[volver a TOC](#section_toc)\n",
    "\n",
    "### Patrones\n",
    "\n",
    "**Precios inmueble en dolares**\n",
    " - `(usd|u\\$d|u\\$s|us\\$|dolares) ?(\\d{2,}(\\,|\\.)?\\d{0,3}(\\,|\\.)?d{0,3}(\\,|\\.)?\\d{0,3})[^\\w] ?(dolares)?(?!(.*m2|.*mc|.*metros))`\n",
    " - Busqueda de precios con valores entre 10000 y 99999999999.\n",
    " - Separacion de decimas con punto (.) o coma(,).\n",
    " - Debe indicarse prefijo en dolares\n",
    " - No debe contener como sufijo una denominacion a metros cuadrados.\n",
    "\n",
    "**Metros inmueble**\n",
    " - `(\\d{1,4}\\,?\\.?\\d{0,4}) ?(m2|mc|metros|mts)`\n",
    " - VER SI AGREGAR.\n",
    "\n",
    "**Ambientes**\n",
    " - `(?<!\\-) ([1-2][0-9]?)(?= amb[^o])`\n",
    " - Entre 1 a 29 ambientes.\n",
    " - Debe tener como subfijo la cadena de caracteres \"amb\" o \"ambientes\" (no puede tener, por ejemplo \"ambos\") \n",
    " - No debe ser precedido por guiones, ejemplo: 100-80 amb.\n",
    "\n",
    "**Cochera**\n",
    " - `(?<!sin )(?<!no incluye )(?<!no posee )cochera(?! no incluye)(?! no incluida)`.\n",
    " - Busqueda de cadena de caracteres \"cochera\" o \"cocheras\".\n",
    " - La cadena de caracteres no puede estar precedida y sucedida por elementos que nieguen su existencia.\n",
    "\n",
    "**Piscina/Pileta**\n",
    " - `piscina|pileta(?! de baÃ±o)(?! de cocina)`\n",
    " - Busqueda de cadena de caracteres \"cochera\" o \"cocheras\".\n",
    " - Se realiza la aclaracion de que la pileta no debe ser de baÃ±o o de cocina.\n",
    "\n",
    "**Parilla**\n",
    " - `(?<!sin )(?<!no incluye )(?<!no posee )parrilla(?! no incluye)(?! no incluida)`\n",
    " - Busqueda de cadena de caracteres \"parrilla\" o \"parrillas\".\n",
    " - La cadena de caracteres no puede estar precedida y sucedida por elementos que nieguen su existencia.\n",
    "\n",
    "**Baulera**\n",
    " - `(?<!sin )(?<!no incluye )(?<!no posee )Baulera(?! no incluye)(?! no incluida)`\n",
    " - Busqueda de cadena de caracteres \"baulera\" o \"bauleras\".\n",
    " - La cadena de caracteres no puede estar precedida y sucedida por elementos que nieguen su existencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precios inmueble\n",
    "precios_inmueble_pat = '(usd|u\\$d|u\\$s|us\\$|dolares) ?(\\d{2,}(\\,|\\.)?\\d{0,3}(\\,|\\.)?d{0,3}(\\,|\\.)?\\d{0,3})[^\\w] ?(dolares)?(?!(.*m2|.*mc|.*metros))'\n",
    "precios_inmueble_reg = re.compile(precios_inmueble_pat, flags = re.IGNORECASE)\n",
    "\n",
    "# Metros inmueble\n",
    "metros_inmueble_pat = '(\\d{1,4}\\,?\\.?\\d{0,4}) ?(m2|mc|metros|mts)'\n",
    "metros_inmueble_reg = re.compile(metros_inmueble_pat, flags = re.IGNORECASE)\n",
    "\n",
    "# Ambientes - hay propiedaddes de 20 ambientes o mas?\n",
    "#amb_pat = '(\\d{1,2})(?= ambientes)'\n",
    "amb_pat = '(?<!\\-) ([1-2][0-9]?)(?= amb[^o])' # version mejorada\n",
    "amb_reg = re.compile(amb_pat, flags = re.IGNORECASE)\n",
    "\n",
    "# Cochera\n",
    "cochera_pat = '(?<!sin )(?<!no incluye )(?<!no posee )cochera(?! no incluye)(?! no incluida)'\n",
    "cochera_reg = re.compile(cochera_pat, flags = re.IGNORECASE)\n",
    "\n",
    "# Piscina/Pileta\n",
    "piscina_pat = 'piscina|pileta(?! de baÃ±o)(?! de cocina)'\n",
    "piscina_reg = re.compile(piscina_pat, flags = re.IGNORECASE)\n",
    "\n",
    "# Parilla\n",
    "parrilla_pat = '(?<!sin )(?<!no incluye )(?<!no posee )parrilla(?! no incluye)(?! no incluida)'\n",
    "parrilla_reg = re.compile(parrilla_pat, flags = re.IGNORECASE)\n",
    "\n",
    "# Baulera\n",
    "baulera_pat = '(?<!sin )(?<!no incluye )(?<!no posee )Baulera(?! no incluye)(?! no incluida)'\n",
    "baulera_reg = re.compile(baulera_pat, flags = re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex Precios\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    100810\n",
       "True      20410\n",
       "Name: price_aprox_usd, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati.price_aprox_usd.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Campo Titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati['precios_normal_regex_titulo'] = df_propierati.title.apply(lambda x: x if x is np.NaN else precios_inmueble_reg.search(x))\n",
    "df_propierati['precios_normal_regex_titulo'] = df_propierati.precios_normal_regex_titulo \\\n",
    "    .apply(lambda x: 0 if x is None else x.group(2) \\\n",
    "           .replace('.','') \\\n",
    "           .replace(',','')) \\\n",
    "    .astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    121220\n",
       "Name: precios_normal_regex_titulo, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati['precios_normal_regex_titulo'].notnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisis de outliers para identificar que eliminar\n",
    "precios_normal_regex_titulo = df_propierati.precios_normal_regex_titulo.apply(lambda x: x if x > 30000 and x < 35000000 else np.NaN)\n",
    "df_propierati['precios_normal_regex_titulo'] = df_propierati.precios_normal_regex_titulo.apply(lambda x: x if x > 30000 and x < 35000000 else np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    118601\n",
       "True       2619\n",
       "Name: precios_normal_regex_titulo, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati['precios_normal_regex_titulo'].notnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Campo Descripcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati['precios_normal_regex_desc'] = df_propierati.description.apply(lambda x: x if x is np.NaN else precios_inmueble_reg.search(x))\n",
    "df_propierati['precios_normal_regex_desc'] = df_propierati.precios_normal_regex_desc \\\n",
    "    .apply(lambda x: 0 if x is None or x is np.NaN else x.group(2) \\\n",
    "           .replace('.','') \\\n",
    "           .replace(',','')) \\\n",
    "    .astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    121220\n",
       "Name: precios_normal_regex_desc, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati['precios_normal_regex_desc'].notnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios_normal_regex_desc = df_propierati.precios_normal_regex_desc.apply(lambda x: x if x > 30000 and x < 20000000 else np.NaN)\n",
    "df_propierati['precios_normal_regex_desc'] = df_propierati.precios_normal_regex_desc.apply(lambda x: x if x > 30000 and x < 20000000 else np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    115327\n",
       "True       5893\n",
       "Name: precios_normal_regex_desc, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati['precios_normal_regex_desc'].notnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>    121220\n",
      "Name: precios_normal_regex_titulo, dtype: int64 \n",
      " float64\n"
     ]
    }
   ],
   "source": [
    "print(df_propierati['precios_normal_regex_titulo'].apply(lambda x: type(x)).value_counts(), '\\n', df_propierati['precios_normal_regex_titulo'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>    121220\n",
      "Name: precios_normal_regex_desc, dtype: int64 \n",
      " float64\n"
     ]
    }
   ],
   "source": [
    "print(df_propierati['precios_normal_regex_desc'].apply(lambda x: type(x)).value_counts(), '\\n', df_propierati['precios_normal_regex_desc'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121220, 121220)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati['precios_normal_regex_desc'].size, df_propierati['precios_normal_regex_titulo'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_aprox_usd_null_mask = df_propierati.price_aprox_usd.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati.loc[price_aprox_usd_null_mask, 'price_aprox_usd'] = df_propierati.loc[price_aprox_usd_null_mask, 'precios_normal_regex_titulo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    103188\n",
       "True      18032\n",
       "Name: price_aprox_usd, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati.price_aprox_usd.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_aprox_usd_null_mask = df_propierati.price_aprox_usd.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati.loc[price_aprox_usd_null_mask, 'price_aprox_usd'] = df_propierati.loc[price_aprox_usd_null_mask, 'precios_normal_regex_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    103310\n",
       "True      17910\n",
       "Name: price_aprox_usd, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati.price_aprox_usd.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex ambientes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'float'>    121220\n",
       "Name: rooms, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati.rooms.apply(lambda x: type(x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     73830\n",
       "False    47390\n",
       "Name: rooms, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati_rooms_null_mask = df_propierati.rooms.isnull()\n",
    "df_propierati.rooms.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati['rooms_regex_titl'] = df_propierati.title.apply(lambda x: x if x is np.NaN else amb_reg.search(x))\n",
    "df_propierati['rooms_regex_titl'] = df_propierati.rooms_regex_titl.apply(lambda x: x if x is None else x.group(1))\n",
    "df_propierati['rooms_regex_titl'] = df_propierati.rooms_regex_titl.apply(lambda x: np.NaN if x is None else float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     114860\n",
       "False      6360\n",
       "Name: rooms_regex_titl, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati.rooms_regex_titl.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0     5333\n",
       "1.0     1019\n",
       "11.0       3\n",
       "10.0       2\n",
       "15.0       1\n",
       "14.0       1\n",
       "12.0       1\n",
       "Name: rooms_regex_titl, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati.rooms_regex_titl.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati['rooms_regex_desc'] = df_propierati.description.apply(lambda x: x if x is np.NaN else amb_reg.search(x))\n",
    "df_propierati['rooms_regex_desc'] = df_propierati.rooms_regex_desc.apply(lambda x: x if x is np.NaN or x is None else x.group(1))\n",
    "df_propierati['rooms_regex_desc'] = df_propierati.rooms_regex_desc.apply(lambda x: np.NaN if x is None else float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     106492\n",
       "False     14728\n",
       "Name: rooms_regex_desc, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati.rooms_regex_desc.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0     12482\n",
       "1.0      2210\n",
       "10.0       13\n",
       "11.0       12\n",
       "18.0        3\n",
       "14.0        3\n",
       "12.0        2\n",
       "17.0        1\n",
       "25.0        1\n",
       "22.0        1\n",
       "Name: rooms_regex_desc, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati.rooms_regex_desc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     71455\n",
       "False    49765\n",
       "Name: rooms, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati.loc[df_propierati_rooms_null_mask, 'rooms'] = df_propierati.loc[df_propierati_rooms_null_mask, 'rooms_regex_titl']\n",
    "df_propierati.rooms.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati_rooms_null_mask = df_propierati.rooms.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     65802\n",
       "False    55418\n",
       "Name: rooms, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati.loc[df_propierati_rooms_null_mask, 'rooms'] = df_propierati.loc[df_propierati_rooms_null_mask, 'rooms_regex_desc']\n",
    "df_propierati.rooms.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex Metros\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'float'>    121220\n",
       "Name: surface_total_in_m2, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati.surface_total_in_m2.apply(lambda x: type(x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    81892\n",
       "True     39328\n",
       "Name: surface_total_in_m2, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati.surface_total_in_m2.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27520          1\n",
       "56822          1\n",
       "56828          1\n",
       "32984      1.000\n",
       "14561      1.000\n",
       "68526      1.000\n",
       "68497      1.000\n",
       "68477      1.000\n",
       "11124      1.013\n",
       "68583      1.100\n",
       "66342      1.100\n",
       "69007      1.133\n",
       "65183      1.144\n",
       "64804      1.200\n",
       "66425      1.200\n",
       "65122      1.230\n",
       "64808      1.255\n",
       "65791      1.270\n",
       "97448      1.300\n",
       "66298      1.340\n",
       "64901      1.400\n",
       "65270      1.500\n",
       "97611      1.500\n",
       "96283      1.500\n",
       "66012      1.622\n",
       "68727      1.707\n",
       "115251     1.720\n",
       "65845      1.750\n",
       "65532      1.800\n",
       "67016      1.890\n",
       "97524      1.892\n",
       "65095      1.950\n",
       "73961         10\n",
       "81026         10\n",
       "22474         10\n",
       "7592          10\n",
       "33510         10\n",
       "42575         10\n",
       "82953         10\n",
       "30576         10\n",
       "69115     10.960\n",
       "42665        100\n",
       "7873         100\n",
       "80921        100\n",
       "51234        100\n",
       "96776        100\n",
       "24622        100\n",
       "51527        100\n",
       "80777        100\n",
       "52324        100\n",
       "32090        100\n",
       "80538        100\n",
       "52338        100\n",
       "51147        100\n",
       "6501         100\n",
       "78009        100\n",
       "42532        100\n",
       "52820        100\n",
       "53344        100\n",
       "58483        100\n",
       "40937        100\n",
       "101982       100\n",
       "47340        100\n",
       "58551        100\n",
       "116270       100\n",
       "59116        100\n",
       "6210         100\n",
       "19074        100\n",
       "20810        100\n",
       "42716        100\n",
       "81075        100\n",
       "51146        100\n",
       "23421        100\n",
       "46838        100\n",
       "47933        100\n",
       "23193        100\n",
       "83337        100\n",
       "45692        100\n",
       "89021        100\n",
       "48682        100\n",
       "48683        100\n",
       "89767        100\n",
       "8664         100\n",
       "16272        100\n",
       "23001        100\n",
       "59424        100\n",
       "44918        100\n",
       "24045        100\n",
       "44225        100\n",
       "48898        100\n",
       "44096        100\n",
       "93169        100\n",
       "93458        100\n",
       "43774        100\n",
       "43773        100\n",
       "48899        100\n",
       "43772        100\n",
       "24276        100\n",
       "42742        100\n",
       "50958        100\n",
       "9691         100\n",
       "6144         100\n",
       "9278         100\n",
       "34791        100\n",
       "4692         100\n",
       "115035       100\n",
       "69426        100\n",
       "36150        100\n",
       "69415        100\n",
       "4746         100\n",
       "36149        100\n",
       "34910        100\n",
       "68977        100\n",
       "33911        100\n",
       "14292        100\n",
       "69082        100\n",
       "62702        100\n",
       "38265        100\n",
       "35372        100\n",
       "69209        100\n",
       "14291        100\n",
       "116442       100\n",
       "69196        100\n",
       "28981        100\n",
       "29514        100\n",
       "28200        100\n",
       "113266       100\n",
       "15028        100\n",
       "116959       100\n",
       "65819        100\n",
       "5762         100\n",
       "65705        100\n",
       "114833       100\n",
       "32892        100\n",
       "113269       100\n",
       "113268       100\n",
       "113267       100\n",
       "16205        100\n",
       "65771        100\n",
       "96440       1000\n",
       "64286       1000\n",
       "15058       1000\n",
       "95697       1000\n",
       "23866       1000\n",
       "1603        1000\n",
       "33364       1000\n",
       "49235       1000\n",
       "43929       1000\n",
       "23667       1000\n",
       "17176       1000\n",
       "26075       1000\n",
       "6566        1000\n",
       "101014      1000\n",
       "5748        1000\n",
       "13343       1000\n",
       "97795       1000\n",
       "41194       1000\n",
       "14478       1000\n",
       "60651        101\n",
       "73852        101\n",
       "74446        102\n",
       "41342        102\n",
       "46854        102\n",
       "100086      1020\n",
       "82064       1021\n",
       "110618      1025\n",
       "58523       1025\n",
       "60662        103\n",
       "48694        103\n",
       "74569        103\n",
       "77237        103\n",
       "63940        103\n",
       "64160       1035\n",
       "12649        104\n",
       "71440        104\n",
       "48575        104\n",
       "34432        104\n",
       "60650        105\n",
       "119682       105\n",
       "73839        105\n",
       "59922        105\n",
       "73728        105\n",
       "32334        105\n",
       "60661        105\n",
       "74559        105\n",
       "24513        105\n",
       "66721       1052\n",
       "58813        106\n",
       "58809        106\n",
       "33912        106\n",
       "79269       1060\n",
       "109713       107\n",
       "33126        107\n",
       "33130        107\n",
       "54825        107\n",
       "37426        107\n",
       "73985        107\n",
       "63574        107\n",
       "98804       1071\n",
       "22381       1074\n",
       "Name: totalm2_normal_regex_titulo, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analisis de outliers para identificar que eliminar\n",
    "\n",
    "df_propierati['totalm2_normal_regex_titulo'] = df_propierati.title.apply(lambda x: x if x is np.NaN else metros_inmueble_reg.search(x))\n",
    "df_propierati['totalm2_normal_regex_titulo'] = df_propierati.totalm2_normal_regex_titulo.apply(lambda x: x if x is None else x.group(1))\n",
    "\n",
    "#df_propierati['totalm2_normal_regex_titulo'] = df_propierati.totalm2_normal_regex_titulo.apply(lambda x: x if x is None else x.group(1).replace(',','.'))\n",
    "\n",
    "#df_propierati['totalm2_normal_regex_titulo'] = df_propierati.totalm2_normal_regex_titulo.apply(lambda x: 0 if x is np.NaN else x)\n",
    "#f_propierati['totalm2_normal_regex_titulo'] = df_propierati['totalm2_normal_regex_titulo'].astype(int)\n",
    "\n",
    "#df_propierati.loc[55106, 'totalm2_normal_regex_titulo']\n",
    "#df_propierati.loc[17768, ['totalm2_normal_regex_titulo', 'title']]\n",
    "\n",
    "\n",
    "df_propierati.surface_total_in_m2.value_counts()\n",
    "#pepe = df_propierati.totalm2_normal_regex_titulo.apply(lambda x: np.NaN if x is None else float(x))\n",
    "#df_propierati.totalm2_normal_regex_titulo.value_counts()\n",
    "#pepe.sort_values(ascending=True).head(100)\n",
    "#df_propierati['totalm2_normal_regex_titulo'].apply(lambda x: type(x)).value_counts()\n",
    "#df_propierati['totalm2_normal_regex_titulo'].isnull().value_counts()\n",
    "df_propierati['totalm2_normal_regex_titulo'].sort_values(ascending=True).head(200)\n",
    "#df_propierati['totalm2_normal_regex_titulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    98.50\n",
       "1    49.00\n",
       "2    85.74\n",
       "3      NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['98.5', '49.00', '85.74', np.NaN])\n",
    "s = s.astype(float)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex amenities\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cocheras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati['cochera_regex_titulo'] = df_propierati.title.apply(lambda x: x if x is np.NaN else cochera_reg.search(x))\n",
    "df_propierati['cochera_regex_titulo'] = df_propierati.cochera_regex_titulo.apply(lambda x: x if x is None else x.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     115235\n",
       "False      5985\n",
       "Name: cochera_regex_titulo, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cochera_regex_titulo_notnull_mask = df_propierati['cochera_regex_titulo'].notnull()\n",
    "df_propierati.loc[cochera_regex_titulo_notnull_mask, 'cochera_regex_titulo'] = 1\n",
    "cochera_regex_titulo_null_mask = df_propierati['cochera_regex_titulo'].isnull()\n",
    "df_propierati.loc[cochera_regex_titulo_null_mask, 'cochera_regex_titulo'] = np.NaN\n",
    "\n",
    "df_propierati['cochera_regex_titulo'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati['cochera_regex_desc'] = df_propierati.description.apply(lambda x: x if x is np.NaN else cochera_reg.search(x))\n",
    "df_propierati['cochera_regex_desc'] = df_propierati.cochera_regex_desc.apply(lambda x: x if x is None or x is np.NaN else x.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     79062\n",
       "False    42158\n",
       "Name: cochera_regex_desc, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cochera_regex_desc_notnull_mask = df_propierati['cochera_regex_desc'].notnull()\n",
    "df_propierati.loc[cochera_regex_desc_notnull_mask, 'cochera_regex_desc'] = 1\n",
    "cochera_regex_desc_null_mask = df_propierati['cochera_regex_desc'].isnull()\n",
    "df_propierati.loc[cochera_regex_desc_null_mask, 'cochera_regex_desc'] = np.NaN\n",
    "\n",
    "df_propierati['cochera_regex_desc'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     78075\n",
       "False    43145\n",
       "Name: cochera, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati['cochera'] = df_propierati['cochera_regex_titulo']\n",
    "df_propierati.loc[df_propierati['cochera_regex_titulo'].isnull(), 'cochera'] = df_propierati.loc[df_propierati['cochera_regex_titulo'].isnull(), 'cochera_regex_desc']\n",
    "df_propierati['cochera'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piscinas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati['piscina_regex_titulo'] = df_propierati.title.apply(lambda x: x if x is np.NaN else piscina_reg.search(x))\n",
    "df_propierati['piscina_regex_titulo'] = df_propierati.piscina_regex_titulo.apply(lambda x: x if x is None else x.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     119616\n",
       "False      1604\n",
       "Name: piscina_regex_titulo, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piscina_regex_titulo_notnull_mask = df_propierati['piscina_regex_titulo'].notnull()\n",
    "df_propierati.loc[piscina_regex_titulo_notnull_mask, 'piscina_regex_titulo'] = 1\n",
    "piscina_regex_titulo_null_mask = df_propierati['piscina_regex_titulo'].isnull()\n",
    "df_propierati.loc[piscina_regex_titulo_null_mask, 'piscina_regex_titulo'] = np.NaN\n",
    "\n",
    "df_propierati['piscina_regex_titulo'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati['piscina_regex_desc'] = df_propierati.description.apply(lambda x: x if x is np.NaN else piscina_reg.search(x))\n",
    "df_propierati['piscina_regex_desc'] = df_propierati.piscina_regex_desc.apply(lambda x: x if x is None or x is np.NaN else x.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     88487\n",
       "False    32733\n",
       "Name: piscina_regex_desc, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piscina_regex_desc_notnull_mask = df_propierati['piscina_regex_desc'].notnull()\n",
    "df_propierati.loc[piscina_regex_desc_notnull_mask, 'piscina_regex_desc'] = 1\n",
    "piscina_regex_desc_null_mask = df_propierati['piscina_regex_desc'].isnull()\n",
    "df_propierati.loc[piscina_regex_desc_null_mask, 'piscina_regex_desc'] = np.NaN\n",
    "\n",
    "df_propierati['piscina_regex_desc'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     78075\n",
       "False    43145\n",
       "Name: cochera, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati['piscina'] = df_propierati['piscina_regex_titulo']\n",
    "df_propierati.loc[df_propierati['piscina_regex_titulo'].isnull(), 'piscina'] = df_propierati.loc[df_propierati['piscina_regex_titulo'].isnull(), 'piscina_regex_desc']\n",
    "df_propierati['cochera'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati['parrilla_regex_titulo'] = df_propierati.title.apply(lambda x: x if x is np.NaN else parrilla_reg.search(x))\n",
    "df_propierati['parrilla_regex_titulo'] = df_propierati.parrilla_regex_titulo.apply(lambda x: x if x is None else x.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     120548\n",
       "False       672\n",
       "Name: parrilla_regex_titulo, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parrilla_regex_titulo_notnull_mask = df_propierati['parrilla_regex_titulo'].notnull()\n",
    "df_propierati.loc[parrilla_regex_titulo_notnull_mask, 'parrilla_regex_titulo'] = 1\n",
    "parrilla_regex_titulo_null_mask = df_propierati['parrilla_regex_titulo'].isnull()\n",
    "df_propierati.loc[parrilla_regex_titulo_null_mask, 'parrilla_regex_titulo'] = np.NaN\n",
    "\n",
    "df_propierati['parrilla_regex_titulo'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati['parrilla_regex_desc'] = df_propierati.description.apply(lambda x: x if x is np.NaN else parrilla_reg.search(x))\n",
    "df_propierati['parrilla_regex_desc'] = df_propierati.parrilla_regex_desc.apply(lambda x: x if x is None or x is np.NaN else x.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     87187\n",
       "False    34033\n",
       "Name: parrilla_regex_desc, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parrilla_regex_desc_notnull_mask = df_propierati['parrilla_regex_desc'].notnull()\n",
    "df_propierati.loc[parrilla_regex_desc_notnull_mask, 'parrilla_regex_desc'] = 1\n",
    "parrilla_regex_desc_null_mask = df_propierati['parrilla_regex_desc'].isnull()\n",
    "df_propierati.loc[parrilla_regex_desc_null_mask, 'parrilla_regex_desc'] = np.NaN\n",
    "\n",
    "df_propierati['parrilla_regex_desc'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     87129\n",
       "False    34091\n",
       "Name: parrilla, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati['parrilla'] = df_propierati['parrilla_regex_titulo']\n",
    "df_propierati.loc[df_propierati['parrilla_regex_titulo'].isnull(), 'parrilla'] = df_propierati.loc[df_propierati['parrilla_regex_titulo'].isnull(), 'parrilla_regex_desc']\n",
    "df_propierati['parrilla'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baulera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati['baulera_regex_titulo'] = df_propierati.title.apply(lambda x: x if x is np.NaN else baulera_reg.search(x))\n",
    "df_propierati['baulera_regex_titulo'] = df_propierati.baulera_regex_titulo.apply(lambda x: x if x is None else x.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     120693\n",
       "False       527\n",
       "Name: baulera_regex_titulo, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baulera_regex_titulo_notnull_mask = df_propierati['baulera_regex_titulo'].notnull()\n",
    "df_propierati.loc[baulera_regex_titulo_notnull_mask, 'baulera_regex_titulo'] = 1\n",
    "baulera_regex_titulo_null_mask = df_propierati['baulera_regex_titulo'].isnull()\n",
    "df_propierati.loc[baulera_regex_titulo_null_mask, 'baulera_regex_titulo'] = np.NaN\n",
    "\n",
    "df_propierati['baulera_regex_titulo'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propierati['baulera_regex_desc'] = df_propierati.description.apply(lambda x: x if x is np.NaN else baulera_reg.search(x))\n",
    "df_propierati['baulera_regex_desc'] = df_propierati.baulera_regex_desc.apply(lambda x: x if x is None or x is np.NaN else x.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     110435\n",
       "False     10785\n",
       "Name: baulera_regex_desc, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baulera_regex_desc_notnull_mask = df_propierati['baulera_regex_desc'].notnull()\n",
    "df_propierati.loc[baulera_regex_desc_notnull_mask, 'baulera_regex_desc'] = 1\n",
    "baulera_regex_desc_null_mask = df_propierati['baulera_regex_desc'].isnull()\n",
    "df_propierati.loc[baulera_regex_desc_null_mask, 'baulera_regex_desc'] = np.NaN\n",
    "\n",
    "df_propierati['baulera_regex_desc'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     110378\n",
       "False     10842\n",
       "Name: baulera, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati['baulera'] = df_propierati['baulera_regex_titulo']\n",
    "df_propierati.loc[df_propierati['baulera_regex_titulo'].isnull(), 'baulera'] = df_propierati.loc[df_propierati['baulera_regex_titulo'].isnull(), 'baulera_regex_desc']\n",
    "df_propierati['baulera'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>operation</th>\n",
       "      <th>property_type</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_with_parent_names</th>\n",
       "      <th>country_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>geonames_id</th>\n",
       "      <th>lat-lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>cochera</th>\n",
       "      <th>piscina_regex_titulo</th>\n",
       "      <th>piscina_regex_desc</th>\n",
       "      <th>piscina</th>\n",
       "      <th>parrilla_regex_titulo</th>\n",
       "      <th>parrilla_regex_desc</th>\n",
       "      <th>parrilla</th>\n",
       "      <th>baulera_regex_titulo</th>\n",
       "      <th>baulera_regex_desc</th>\n",
       "      <th>baulera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sell</td>\n",
       "      <td>PH</td>\n",
       "      <td>Mataderos</td>\n",
       "      <td>|Argentina|Capital Federal|Mataderos|</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>3430787.0</td>\n",
       "      <td>-34.6618237,-58.5088387</td>\n",
       "      <td>-34.661824</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sell</td>\n",
       "      <td>apartment</td>\n",
       "      <td>La Plata</td>\n",
       "      <td>|Argentina|Bs.As. G.B.A. Zona Sur|La Plata|</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Bs.As. G.B.A. Zona Sur</td>\n",
       "      <td>3432039.0</td>\n",
       "      <td>-34.9038831,-57.9643295</td>\n",
       "      <td>-34.903883</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sell</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Mataderos</td>\n",
       "      <td>|Argentina|Capital Federal|Mataderos|</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>3430787.0</td>\n",
       "      <td>-34.6522615,-58.5229825</td>\n",
       "      <td>-34.652262</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>sell</td>\n",
       "      <td>PH</td>\n",
       "      <td>Liniers</td>\n",
       "      <td>|Argentina|Capital Federal|Liniers|</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>3431333.0</td>\n",
       "      <td>-34.6477969,-58.5164244</td>\n",
       "      <td>-34.647797</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sell</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Centro</td>\n",
       "      <td>|Argentina|Buenos Aires Costa AtlÃ¡ntica|Mar del Plata|Centro|</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Buenos Aires Costa AtlÃ¡ntica</td>\n",
       "      <td>3435548.0</td>\n",
       "      <td>-38.0026256,-57.5494468</td>\n",
       "      <td>-38.002626</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>sell</td>\n",
       "      <td>house</td>\n",
       "      <td>GualeguaychÃº</td>\n",
       "      <td>|Argentina|Entre RÃ­os|GualeguaychÃº|</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Entre RÃ­os</td>\n",
       "      <td>3433657.0</td>\n",
       "      <td>-33.0140714,-58.519828</td>\n",
       "      <td>-33.014071</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>sell</td>\n",
       "      <td>PH</td>\n",
       "      <td>Munro</td>\n",
       "      <td>|Argentina|Bs.As. G.B.A. Zona Norte|Vicente LÃ³pez|Munro|</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Bs.As. G.B.A. Zona Norte</td>\n",
       "      <td>3430511.0</td>\n",
       "      <td>-34.5329567,-58.5217825</td>\n",
       "      <td>-34.532957</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>sell</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Belgrano</td>\n",
       "      <td>|Argentina|Capital Federal|Belgrano|</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>3436077.0</td>\n",
       "      <td>-34.5598729,-58.443362</td>\n",
       "      <td>-34.559873</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>sell</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Belgrano</td>\n",
       "      <td>|Argentina|Capital Federal|Belgrano|</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>3436077.0</td>\n",
       "      <td>-34.5598729,-58.443362</td>\n",
       "      <td>-34.559873</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>sell</td>\n",
       "      <td>house</td>\n",
       "      <td>Rosario</td>\n",
       "      <td>|Argentina|Santa Fe|Rosario|</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Santa Fe</td>\n",
       "      <td>3838574.0</td>\n",
       "      <td>-32.942031,-60.7259192</td>\n",
       "      <td>-32.942031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 operation property_type    place_name  \\\n",
       "0           0      sell            PH     Mataderos   \n",
       "1           1      sell     apartment      La Plata   \n",
       "2           2      sell     apartment     Mataderos   \n",
       "3           3      sell            PH       Liniers   \n",
       "4           4      sell     apartment        Centro   \n",
       "5           5      sell         house  GualeguaychÃº   \n",
       "6           6      sell            PH         Munro   \n",
       "7           7      sell     apartment      Belgrano   \n",
       "8           8      sell     apartment      Belgrano   \n",
       "9           9      sell         house       Rosario   \n",
       "\n",
       "                                         place_with_parent_names country_name  \\\n",
       "0                          |Argentina|Capital Federal|Mataderos|    Argentina   \n",
       "1                    |Argentina|Bs.As. G.B.A. Zona Sur|La Plata|    Argentina   \n",
       "2                          |Argentina|Capital Federal|Mataderos|    Argentina   \n",
       "3                            |Argentina|Capital Federal|Liniers|    Argentina   \n",
       "4  |Argentina|Buenos Aires Costa AtlÃ¡ntica|Mar del Plata|Centro|    Argentina   \n",
       "5                            |Argentina|Entre RÃ­os|GualeguaychÃº|    Argentina   \n",
       "6       |Argentina|Bs.As. G.B.A. Zona Norte|Vicente LÃ³pez|Munro|    Argentina   \n",
       "7                           |Argentina|Capital Federal|Belgrano|    Argentina   \n",
       "8                           |Argentina|Capital Federal|Belgrano|    Argentina   \n",
       "9                                   |Argentina|Santa Fe|Rosario|    Argentina   \n",
       "\n",
       "                     state_name  geonames_id                  lat-lon  \\\n",
       "0               Capital Federal    3430787.0  -34.6618237,-58.5088387   \n",
       "1        Bs.As. G.B.A. Zona Sur    3432039.0  -34.9038831,-57.9643295   \n",
       "2               Capital Federal    3430787.0  -34.6522615,-58.5229825   \n",
       "3               Capital Federal    3431333.0  -34.6477969,-58.5164244   \n",
       "4  Buenos Aires Costa AtlÃ¡ntica    3435548.0  -38.0026256,-57.5494468   \n",
       "5                    Entre RÃ­os    3433657.0   -33.0140714,-58.519828   \n",
       "6      Bs.As. G.B.A. Zona Norte    3430511.0  -34.5329567,-58.5217825   \n",
       "7               Capital Federal    3436077.0   -34.5598729,-58.443362   \n",
       "8               Capital Federal    3436077.0   -34.5598729,-58.443362   \n",
       "9                      Santa Fe    3838574.0   -32.942031,-60.7259192   \n",
       "\n",
       "         lat  ...  cochera  piscina_regex_titulo piscina_regex_desc  piscina  \\\n",
       "0 -34.661824  ...      NaN                   NaN                NaN      NaN   \n",
       "1 -34.903883  ...        1                   NaN                NaN      NaN   \n",
       "2 -34.652262  ...      NaN                   NaN                NaN      NaN   \n",
       "3 -34.647797  ...      NaN                   NaN                NaN      NaN   \n",
       "4 -38.002626  ...      NaN                   NaN                NaN      NaN   \n",
       "5 -33.014071  ...      NaN                   NaN                NaN      NaN   \n",
       "6 -34.532957  ...      NaN                   NaN                NaN      NaN   \n",
       "7 -34.559873  ...      NaN                   NaN                  1        1   \n",
       "8 -34.559873  ...      NaN                   NaN                  1        1   \n",
       "9 -32.942031  ...      NaN                   NaN                NaN      NaN   \n",
       "\n",
       "   parrilla_regex_titulo  parrilla_regex_desc  parrilla  baulera_regex_titulo  \\\n",
       "0                    NaN                  NaN       NaN                   NaN   \n",
       "1                    NaN                  NaN       NaN                   NaN   \n",
       "2                    NaN                  NaN       NaN                   NaN   \n",
       "3                    NaN                  NaN       NaN                   NaN   \n",
       "4                    NaN                  NaN       NaN                   NaN   \n",
       "5                    NaN                  NaN       NaN                   NaN   \n",
       "6                    NaN                  NaN       NaN                   NaN   \n",
       "7                    NaN                  NaN       NaN                   NaN   \n",
       "8                    NaN                  NaN       NaN                   NaN   \n",
       "9                    NaN                  NaN       NaN                   NaN   \n",
       "\n",
       "   baulera_regex_desc  baulera  \n",
       "0                 NaN      NaN  \n",
       "1                 NaN      NaN  \n",
       "2                 NaN      NaN  \n",
       "3                 NaN      NaN  \n",
       "4                 NaN      NaN  \n",
       "5                   1        1  \n",
       "6                 NaN      NaN  \n",
       "7                 NaN      NaN  \n",
       "8                 NaN      NaN  \n",
       "9                 NaN      NaN  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propierati.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
