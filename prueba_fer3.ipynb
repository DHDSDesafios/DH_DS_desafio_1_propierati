{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Archivo Properati.  \n",
    "## Primera exploración sobre los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables y tipos de datos\n",
      "--------------------------\n",
      "Id_caso                         int64\n",
      "operation                      object\n",
      "property_type                  object\n",
      "place_name                     object\n",
      "place_with_parent_names        object\n",
      "country_name                   object\n",
      "state_name                     object\n",
      "geonames_id                   float64\n",
      "lat-lon                        object\n",
      "lat                           float64\n",
      "lon                           float64\n",
      "price                         float64\n",
      "currency                       object\n",
      "price_aprox_local_currency    float64\n",
      "price_aprox_usd               float64\n",
      "surface_total_in_m2           float64\n",
      "surface_covered_in_m2         float64\n",
      "price_usd_per_m2              float64\n",
      "price_per_m2                  float64\n",
      "floor                         float64\n",
      "rooms                         float64\n",
      "expenses                      float64\n",
      "properati_url                  object\n",
      "description                    object\n",
      "title                          object\n",
      "image_thumbnail                object\n",
      "dtype: object\n",
      "Abrimos y vemos los datos\n",
      "-------------------------\n",
      "   Id_caso operation property_type place_name  \\\n",
      "0        0      sell            PH  Mataderos   \n",
      "\n",
      "                 place_with_parent_names country_name       state_name  \\\n",
      "0  |Argentina|Capital Federal|Mataderos|    Argentina  Capital Federal   \n",
      "\n",
      "   geonames_id                  lat-lon        lat  ...  \\\n",
      "0    3430787.0  -34.6618237,-58.5088387 -34.661824  ...   \n",
      "\n",
      "   surface_covered_in_m2  price_usd_per_m2 price_per_m2  floor  rooms  \\\n",
      "0                   40.0       1127.272727       1550.0    NaN    NaN   \n",
      "\n",
      "   expenses                                      properati_url  \\\n",
      "0       NaN  http://www.properati.com.ar/15bo8_venta_ph_mat...   \n",
      "\n",
      "                                         description  \\\n",
      "0  2 AMBIENTES TIPO CASA PLANTA BAJA POR PASILLO,...   \n",
      "\n",
      "                                title  \\\n",
      "0  2 AMB TIPO CASA SIN EXPENSAS EN PB   \n",
      "\n",
      "                                     image_thumbnail  \n",
      "0  https://thumbs4.properati.com/8/BluUYiHJLhgIIK...  \n",
      "\n",
      "[1 rows x 26 columns]\n",
      "Porcentaje de nulos por variable\n",
      "--------------------------------\n",
      "Id_caso                        0.0\n",
      "operation                      0.0\n",
      "property_type                  0.0\n",
      "place_name                     0.0\n",
      "place_with_parent_names        0.0\n",
      "country_name                   0.0\n",
      "state_name                     0.0\n",
      "geonames_id                   15.4\n",
      "lat-lon                       42.5\n",
      "lat                           42.5\n",
      "lon                           42.5\n",
      "price                         16.8\n",
      "currency                      16.8\n",
      "price_aprox_local_currency    16.8\n",
      "price_aprox_usd               16.8\n",
      "surface_total_in_m2           32.4\n",
      "surface_covered_in_m2         16.4\n",
      "price_usd_per_m2              43.4\n",
      "price_per_m2                  27.7\n",
      "floor                         93.5\n",
      "rooms                         60.9\n",
      "expenses                      88.2\n",
      "properati_url                  0.0\n",
      "description                    0.0\n",
      "title                          0.0\n",
      "image_thumbnail                2.6\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# importamos el archivo\n",
    "data_location = \"C:/Users/Fernando/Documents/DIGITAL_HOUSE/CONTENIDO/DESAFIO_I/properati.csv\"\n",
    "data_original = pd.read_csv(data_location, sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "# renombro la columna que no tiene nombre\n",
    "data_original = data_original.rename({           \n",
    "    'Unnamed: 0': 'Id_caso'\n",
    "}, axis=1)\n",
    "\n",
    "print('Variables y tipos de datos')\n",
    "print('--------------------------')\n",
    "# tipo de datos de cada columna\n",
    "print (data_original.dtypes)\n",
    "\n",
    "print('Abrimos y vemos los datos')\n",
    "print('-------------------------')\n",
    "# abrimos el archivo\n",
    "print(data_original.head(1))\n",
    "\n",
    "print ('Porcentaje de nulos por variable')\n",
    "print ('--------------------------------')\n",
    "# % de nulos por columna\n",
    "print (round(data_original.isnull().sum() / data_original.shape[0]*100,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Trabajo sobre variables\n",
    "\n",
    "Las tareas sobre las variables las organizamos de la siguiente manera:\n",
    "* Agrupamos cada una de acuerdo a criterios comunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grupo           Variable                  \n",
      "Característica  Tipo                          1\n",
      "                amenities                     1\n",
      "                expenses                      1\n",
      "                floor                         1\n",
      "                operation                     1\n",
      "                rooms                         1\n",
      "Dimensión       surface_covered_in_m2         1\n",
      "                surface_total_in_m2           1\n",
      "Localización    country_name                  1\n",
      "                geonames_id                   1\n",
      "                lat                           1\n",
      "                lat-lon                       1\n",
      "                lon                           1\n",
      "                place_name                    1\n",
      "                place_with_parent_names       1\n",
      "                state_name                    1\n",
      "Otras           description                   1\n",
      "                image_thumbnail               1\n",
      "                properati_url                 1\n",
      "                title                         1\n",
      "Valor           currency                      1\n",
      "                price                         1\n",
      "                price_aprox_local_currency    1\n",
      "                price_aprox_usd               1\n",
      "                price_per_m2                  1\n",
      "                price_usd_per_m2              1\n",
      "Name: Grupo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "var = pd.DataFrame({'Grupo': [\\\n",
    "                              'Característica', 'Característica', 'Característica','Característica', 'Característica', 'Característica',\\\n",
    "                              'Localización','Localización','Localización','Localización','Localización','Localización','Localización','Localización',\\\n",
    "                              'Dimensión','Dimensión',\\\n",
    "                              'Valor','Valor','Valor','Valor','Valor','Valor',\\\n",
    "                              'Otras','Otras','Otras','Otras'\\\n",
    "                             ],\n",
    "                    'Variable': ['operation', 'Tipo', 'floor','rooms', 'expenses', 'amenities',\\\n",
    "                                 'place_name','place_with_parent_names','country_name','state_name','geonames_id','lat-lon','lat','lon',\\\n",
    "                                 'surface_total_in_m2','surface_covered_in_m2',\\\n",
    "                                 'price','currency','price_aprox_local_currency','price_aprox_usd','price_usd_per_m2','price_per_m2',\\\n",
    "                                 'description','title','properati_url','image_thumbnail'\\\n",
    "                                ]})\n",
    "\n",
    "print(var.groupby([\"Grupo\",\"Variable\"])[\"Grupo\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* De acuerdo a cada grupo, nos separamos su análisis pero definiendo objetivos generales:\n",
    "    * Analisis de distribución.\n",
    "    * Definición si la variable era necesaria o no.\n",
    "    * Si alguna dependía o tenía su origen en otra.\n",
    "    * Búsqueda de errores y tareas de corrección.\n",
    "    * Política de llenado de valores nulos, si era posible.\n",
    "    * Identificación y política de valores outliers.\n",
    "* Trabajo de expresiones regulares para:\n",
    "    * Identificar valores faltantes sobre variables existentes\n",
    "    * Identificación de variables que sumen al objetivo.  Amenities.\n",
    "* Búsqueda y eliminación de registros duplicados.\n",
    "* Búsqueda y eliminación de registros únicos que finalmente no puedan ser utilizados para el cumplimiento del objetivo.\n",
    "* Finalmente genearación de un nuevo DF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1.  Variables del grupo de localización de propiedades\n",
    "\n",
    "\n",
    "Validación, limpieza y asignación de nulos; sobre las variables:\n",
    "\n",
    "- country_name \n",
    "- state_name\n",
    "- place_name\n",
    "- geonames_id\n",
    "- place_with_parent_names\n",
    "- lat-lon\n",
    "- lat\n",
    "- lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **country_name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Argentina    121220\n",
       "Name: country_name, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirmamos que la variable tiene un solo valor, por lo que es posible descartarla\n",
    "data_original.country_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **state_name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capital Federal                 32316\n",
      "Bs.As. G.B.A. Zona Norte        25560\n",
      "Bs.As. G.B.A. Zona Sur          13952\n",
      "Córdoba                         12069\n",
      "Santa Fe                        10172\n",
      "Buenos Aires Costa Atlántica    10006\n",
      "Bs.As. G.B.A. Zona Oeste         9322\n",
      "Buenos Aires Interior            2291\n",
      "Río Negro                         808\n",
      "Neuquén                           733\n",
      "Mendoza                           681\n",
      "Tucumán                           674\n",
      "Corrientes                        583\n",
      "Misiones                          464\n",
      "Entre Ríos                        369\n",
      "Salta                             278\n",
      "Chubut                            259\n",
      "San Luis                          252\n",
      "La Pampa                          157\n",
      "Formosa                            65\n",
      "Chaco                              57\n",
      "San Juan                           40\n",
      "Tierra Del Fuego                   31\n",
      "Catamarca                          27\n",
      "Jujuy                              26\n",
      "Santa Cruz                         20\n",
      "La Rioja                            4\n",
      "Santiago Del Estero                 4\n",
      "Name: state_name, dtype: int64\n",
      "--------------------------------------------------\n",
      "Vemos que no existen valores por fuera del listado\n"
     ]
    }
   ],
   "source": [
    "# Distribución de la variable\n",
    "print (data_original.state_name.value_counts())\n",
    "print (\"--------------------------------------------------\")\n",
    "print (\"Vemos que no existen valores por fuera del listado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **place_name**\n",
    "  \n",
    "  Validamos si los datos de la variable están completos y es un dato confiable, o si debemos realizar alguna terea sobre ellos.\n",
    "  * Luego del trabajo exploratorio, vamos a confirmar que place_name correponde a la última parte de la variable place_with_parent_names:\n",
    "      * Separamos place_with_parent_names en 5 variables nuevas:\n",
    "          * Pais\n",
    "          * Zona\n",
    "          * Partido_barrio\n",
    "          * Localidad\n",
    "          * Obs_localidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a determinadar si la variable 'place_name' tiene un dato 'confiable' o 'completo', \n",
    "# para eso separamos la variable 'place_with_parent_names' en partes, por el simbolo | (pipe) \n",
    "# separo la variable place_with_parent_names, sumando campos nuevos y ya trabajando sobre le nuevo dataframe\n",
    "data = data_original.join(data_original[\"place_with_parent_names\"].str.split('|', expand=True).rename(columns={\n",
    "                                                                                                1:'Pais', \n",
    "                                                                                                2:'Zona', \n",
    "                                                                                                3:'Partido_barrio', \n",
    "                                                                                                4:'Localidad', \n",
    "                                                                                                5:'Obs_localidad', \n",
    "                                                                                                6:'Descarte'}))\n",
    "data.drop(['Descarte'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se recorren las variables creadas desde la última hasta encontrar un NO nulo se graba el valor encontrado en place_name_new\n",
    "* Se compara la variable creada vs place_name original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualización de place_name_new\n",
      "--------------------------------\n",
      "Obs_localidad\n",
      "Cantidad de casos con Obs_localidad informada: 548\n",
      "Cantidad de casos con place_name_new original :121220\n",
      "Cantidad de casos con place_name_new posterior para analizar: 120672\n",
      "--------------------------------\n",
      "Localidad\n",
      "Cantidad de casos con Localidad informada: 40417\n",
      "Cantidad de casos con place_name_new original: 120672\n",
      "Cantidad de casos con place_name_new posterior para analizar: 80803\n",
      "--------------------------------\n",
      "Partido_barrio\n",
      "Cantidad de casos con Partido_barrio informada: 116440\n",
      "Cantidad de casos con place_name_new original: 80803\n",
      "Cantidad de casos con place_name_new posterior para analizar: 4780\n",
      "--------------------------------\n",
      "Zona\n",
      "Cantidad de casos con Zona informada: 121220\n",
      "Cantidad de casos con place_name_new original: 4780\n",
      "Cantidad de casos con place_name_new posterior para analizar: 0\n",
      "--------------------------------\n",
      "Cantidad casos que coinciden entre place_name_new y place_name\n",
      "True     121197\n",
      "False        23\n",
      "dtype: int64\n",
      "Vemos que casuiticas encontramos sobre los casos que no encontramos:\n",
      "place_with_parent_names\n",
      "|Argentina|Bs.As. G.B.A. Zona Norte|Tigre||    23\n",
      "Name: Id_caso, dtype: int64\n",
      "Vemos que son todos del mismo place_with_parent_names de Tigre\n",
      "Los normalizamos sobre la variable place_name_new\n",
      "Validamos la actualización:\n",
      "place_name_new\n",
      "Tigre    23\n",
      "Name: Id_caso, dtype: int64\n",
      "----------------------------------------------------------------------------\n",
      "Confirmamos que la variable creada - place_name_new - es igual a  place_name\n"
     ]
    }
   ],
   "source": [
    "# validamos que la variable place_name sea igual a el ultimo valor informado sobre place_with_parent_names\n",
    "# ya separado por el proceso anterior\n",
    "# lo recorro desde la ultima variable hasta encontrar un NO nulo y grabo el valor\n",
    "# 1 - Obs_localidad\n",
    "# 2 - Localidad\n",
    "# 3 - Partido_barrio\n",
    "# 4 - Zona\n",
    "# creo una nueva variable que voy a ir completando a medida que valido que cada \n",
    "# variable tenga valor empezando desde la última\n",
    "data[\"place_name_new\"] = 'validar'\n",
    "\n",
    "#para cada variable nuevo valido null o ''\n",
    "#---------------------------------------------------------------------------\n",
    "# creo mascara de los casos donde la varible 'x' tenga null o ''\n",
    "mask_data_Obs_localidad_null =  (data.Obs_localidad.isnull()) | (data.Obs_localidad == '')\n",
    "# creo otra mascara con origen en la mascara enterior para quedarme con los \n",
    "# que tienen valor en la variable 'x'\n",
    "mask_data_Obs_localidad_notnull = mask_data_Obs_localidad_null == False\n",
    "print ('Actualización de place_name_new')\n",
    "print ('--------------------------------')\n",
    "\n",
    "print ('Obs_localidad')\n",
    "print ('Cantidad de casos con Obs_localidad informada: ' + str(mask_data_Obs_localidad_notnull.sum()))\n",
    "# creo una mascara sobre la variable que voy a ir completando con el valor obtenido\n",
    "mask_data_place_name_new_validar = data.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new original :' + str(mask_data_place_name_new_validar.sum()))\n",
    "# actualizo los valores sobre mi nueva variable con los que encontré en la variable 'x'\n",
    "data.loc[mask_data_Obs_localidad_notnull&mask_data_place_name_new_validar, \"place_name_new\"] = data.Obs_localidad\n",
    "# actualizo la mascara sobre mi nueva variable para contar y ver si todo resultó ok!\n",
    "mask_data_place_name_new_validar = data.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new posterior para analizar: ' + str(mask_data_place_name_new_validar.sum()))\n",
    "# la cantidad de casos sobre la variable nueva con valor 'validar' era de 121197\n",
    "# La cantidad de casos sobre la misma variable con valor 'validar' despues de actualizar fue de 120649\n",
    "# El delta corresponde a los valores con origen en el primer campo Obs_localidad ... 548\n",
    "\n",
    "#---------------------------------------\n",
    "print ('--------------------------------')\n",
    "# 2 - Localidad\n",
    "mask_data_Localidad_null =  (data.Localidad.isnull()) | (data.Localidad == '')\n",
    "mask_data_Localidad_notnull = mask_data_Localidad_null == False\n",
    "print ('Localidad')\n",
    "print ('Cantidad de casos con Localidad informada: ' + str(mask_data_Localidad_notnull.sum()))\n",
    "mask_data_place_name_new_validar = data.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new original: ' +  str(mask_data_place_name_new_validar.sum()))\n",
    "data.loc[mask_data_Localidad_notnull&mask_data_place_name_new_validar, \"place_name_new\"] = data.Localidad\n",
    "mask_data_place_name_new_validar = data.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new posterior para analizar: ' + str(mask_data_place_name_new_validar.sum()))\n",
    "#---------------------------------------\n",
    "print ('--------------------------------')\n",
    "# 3 - Partido_barrio\n",
    "mask_data_Partido_barrio_null =  (data.Partido_barrio.isnull()) | (data.Partido_barrio == '')\n",
    "mask_data_Partido_barrio_notnull = mask_data_Partido_barrio_null == False\n",
    "print ('Partido_barrio')\n",
    "print ('Cantidad de casos con Partido_barrio informada: ' + str(mask_data_Partido_barrio_notnull.sum()))\n",
    "mask_data_place_name_new_validar = data.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new original: ' + str(mask_data_place_name_new_validar.sum()))\n",
    "data.loc[mask_data_Partido_barrio_notnull&mask_data_place_name_new_validar, \"place_name_new\"] = data.Partido_barrio\n",
    "mask_data_place_name_new_validar = data.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new posterior para analizar: ' + str(mask_data_place_name_new_validar.sum()))\n",
    "#---------------------------------------\n",
    "print ('--------------------------------')\n",
    "# 4 - Zona\n",
    "mask_data_Zona_null =  (data.Zona.isnull()) | (data.Zona == '')\n",
    "mask_data_Zona_notnull = mask_data_Zona_null == False\n",
    "print ('Zona')\n",
    "print ('Cantidad de casos con Zona informada: ' + str(mask_data_Zona_notnull.sum()))\n",
    "mask_data_place_name_new_validar = data.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new original: ' + str(mask_data_place_name_new_validar.sum()))\n",
    "data.loc[mask_data_Zona_notnull&mask_data_place_name_new_validar, \"place_name_new\"] = data.Zona\n",
    "mask_data_place_name_new_validar = data.place_name_new == 'validar'\n",
    "print ('Cantidad de casos con place_name_new posterior para analizar: ' + str(mask_data_place_name_new_validar.sum()))\n",
    "#----------------------------------------------------\n",
    "print ('--------------------------------')\n",
    "print ('Cantidad casos que coinciden entre place_name_new y place_name')\n",
    "# valido si place_name_new da igual que place_name, si contamos lo mismo es que da igual\n",
    "mask_place_name_validacion =  data.place_name_new == data.place_name\n",
    "print(mask_place_name_validacion.value_counts())  \n",
    "mask_place_name_validacion_falso = mask_place_name_validacion == False\n",
    "print ('Vemos que casuiticas encontramos sobre los casos que no encontramos:')\n",
    "print(data.loc[mask_place_name_validacion_falso, [\"Id_caso\",\"place_with_parent_names\",\"place_name\", \"place_name_new\"]].\\\n",
    "     groupby([\"place_with_parent_names\"])[\"Id_caso\"].count())\n",
    "print('Vemos que son todos del mismo place_with_parent_names de Tigre')\n",
    "# lo normalizamos\n",
    "print ('Los normalizamos sobre la variable place_name_new')\n",
    "data.loc[mask_place_name_validacion_falso, \"place_name_new\"] = 'Tigre'\n",
    "data.loc[mask_place_name_validacion_falso, \"Localidad\"] = 'Tigre'\n",
    "print ('Validamos la actualización:')\n",
    "print(data.loc[mask_place_name_validacion_falso, [\"Id_caso\", \"place_name_new\"]]\\\n",
    "     .groupby([\"place_name_new\"])[\"Id_caso\"].count())\n",
    "print('----------------------------------------------------------------------------')\n",
    "print('Confirmamos que la variable creada - place_name_new - es igual a  place_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creamos una nueva variable para identificar los casos sobre los que nos falta información de localización y luego analizar si corresponde descartar esos casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de casos a los que le falta información de localización:\n",
      "-----------------------------------------------------------------\n",
      "False    107421\n",
      "True      13799\n",
      "Name: calidad_dato, dtype: int64\n",
      "Agrupación de los casos a los que le falta información de localización:\n",
      "-----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pais       Zona                          Partido_barrio     \n",
       "Argentina  Bs.As. G.B.A. Zona Norte      Tigre                  2359\n",
       "                                         Pilar                  1857\n",
       "           Capital Federal                                      1297\n",
       "           Bs.As. G.B.A. Zona Norte      Escobar                1037\n",
       "           Bs.As. G.B.A. Zona Sur        La Plata                767\n",
       "           Bs.As. G.B.A. Zona Norte      San Isidro              641\n",
       "           Bs.As. G.B.A. Zona Oeste      Morón                   582\n",
       "                                         Ituzaingó               474\n",
       "           Bs.As. G.B.A. Zona Norte      San Fernando            437\n",
       "           Bs.As. G.B.A. Zona Oeste      Moreno                  434\n",
       "           Bs.As. G.B.A. Zona Norte      San Miguel              417\n",
       "                                         General San Martín      382\n",
       "           Bs.As. G.B.A. Zona Sur        Lomas de Zamora         276\n",
       "           Bs.As. G.B.A. Zona Oeste      Merlo                   271\n",
       "           Bs.As. G.B.A. Zona Sur        Avellaneda              238\n",
       "           Bs.As. G.B.A. Zona Norte      Vicente López           232\n",
       "                                                                 222\n",
       "           Bs.As. G.B.A. Zona Sur        Quilmes                 216\n",
       "                                         Ezeiza                  211\n",
       "                                         Esteban Echeverría      209\n",
       "           Bs.As. G.B.A. Zona Oeste      La Matanza              149\n",
       "           Bs.As. G.B.A. Zona Sur        Berazategui             115\n",
       "           Buenos Aires Interior                                 106\n",
       "           Bs.As. G.B.A. Zona Norte      Malvinas Argentinas     106\n",
       "                                         José C Paz              101\n",
       "           Bs.As. G.B.A. Zona Oeste      Hurlingham              100\n",
       "                                         Tres de Febrero          96\n",
       "           Bs.As. G.B.A. Zona Sur        San Vicente              95\n",
       "           Bs.As. G.B.A. Zona Oeste      General Rodríguez        83\n",
       "           Bs.As. G.B.A. Zona Sur        Lanús                    77\n",
       "           Bs.As. G.B.A. Zona Oeste                               65\n",
       "           Bs.As. G.B.A. Zona Sur        Almirante Brown          42\n",
       "           Buenos Aires Costa Atlántica                           27\n",
       "           Bs.As. G.B.A. Zona Sur                                 24\n",
       "                                         Presidente Perón         19\n",
       "                                         Florencio Varela         16\n",
       "           Bs.As. G.B.A. Zona Oeste      Marcos Paz               10\n",
       "           Bs.As. G.B.A. Zona Sur        Cañuelas                  9\n",
       "Name: Id_caso, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nueva variable para validar la calidad del dato place_with_parent_names luego de separarlo \n",
    "data[\"calidad_dato\"] = False\n",
    "# dependiendo de la zona que estamos analizando entendemos que la cantidad de info que necesitamos\n",
    "# para ['Bs.As. G.B.A. Zona Norte','Bs.As. G.B.A. Zona Oeste','Bs.As. G.B.A. Zona Sur'] el mínimo tendria que ser Localidad\n",
    "# para  ['Buenos Aires Costa Atlántica'] y en especial MDQ el mínimo tendria que ser Localidad\n",
    "# para el resto_zonas Partido_barrio\n",
    "# se va actualizando la variable creada (calidad_dato) a True que identifica los casos sobre los que necesitamos mayor informacion\n",
    "\n",
    "# para ['Bs.As. G.B.A. Zona Norte','Bs.As. G.B.A. Zona Oeste','Bs.As. G.B.A. Zona Sur']\n",
    "# zonas a traves de una lista de valores\n",
    "valores_zona = ['Bs.As. G.B.A. Zona Norte','Bs.As. G.B.A. Zona Oeste','Bs.As. G.B.A. Zona Sur']\n",
    "# mascara sobre la lista de valores y que localidad este nulo o ''\n",
    "mask_Localidad = ([x in valores_zona for x in data.Zona]) & ((data.Localidad.isnull())|(data.Localidad == ''))\n",
    "# actualizo la variable creada sobre los True por la mascara\n",
    "data.loc[mask_Localidad, \"calidad_dato\"] = True\n",
    "# ----------------------------------------------------------------------\n",
    "# caso especial de MDQ\n",
    "valores_zona_mdq = ['Buenos Aires Costa Atlántica']\n",
    "mask_Localidad_mdq = ([x in valores_zona_mdq for x in data.Zona])\\\n",
    "& (data.Partido_barrio == 'Mar del Plata') & ((data.Localidad.isnull()) | (data.Localidad == ''))\n",
    "data.loc[mask_Localidad, \"calidad_dato\"] = True\n",
    "# ----------------------------------------------------------------------\n",
    "#resto_zonas\n",
    "valores_zona_resto = ['Buenos Aires Costa Atlántica','Buenos Aires Interior','Capital Federal','Resto de provincias']\n",
    "mask_Partido_barrio = ([x in valores_zona_resto for x in data.Zona]) & ((data.Partido_barrio.isnull())|\\\n",
    "                                                                                (data.Partido_barrio == ''))\n",
    "mask_calidad_dato_false = data.calidad_dato == False\n",
    "data.loc[mask_Partido_barrio & mask_calidad_dato_false, \"calidad_dato\"] = True\n",
    "# ----------------------------------------------------------------------\n",
    "# todos los casos con True corresponden a los registros sobre los que nos falta informacion referida a \n",
    "# la geolocalización de la propiedad\n",
    "print ('Cantidad de casos a los que le falta información de localización:')\n",
    "print ('-----------------------------------------------------------------')\n",
    "print(data.calidad_dato.value_counts())\n",
    "# mascara sobre casos que nos faltaria info\n",
    "mask_faltante = (data.calidad_dato == True)\n",
    "data_faltante = data.loc[mask_faltante]\n",
    "#print (data_faltante)\n",
    "# agrupo por Pais, Zona, Partido_barrio los casos que no tenemos otra info\n",
    "groupby_df_faltante = data_faltante.groupby(['Pais',  'Zona', 'Partido_barrio'])[\"Id_caso\"].count().\\\n",
    "sort_values(ascending=False)\n",
    "print ('Agrupación de los casos a los que le falta información de localización:')\n",
    "print ('-----------------------------------------------------------------------')\n",
    "groupby_df_faltante\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **geonames_id**\n",
    "  \n",
    "  Del proceso exploratorio vemos que se corresponde a un Id sobre la variable place_name.  Vamos a:\n",
    "  * Validar que No se asigne un mismo geonames_id a distintos valores de place_name_new\n",
    "  * En caso que exista, vamos a definir la tarea de normalización sobre cada uno\n",
    "  * Por último vamos a completar los valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Validacion geonames_id*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casos que un mismo geonames_id tiene asignado más de un place_name\n",
      "------------------------------------------------------------------\n",
      "                                          size\n",
      "geonames_id place_name_new                    \n",
      "3428927.0   San Jose                         5\n",
      "            San José                        11\n",
      "3430234.0   Palermo                       2885\n",
      "            Palermo Soho                   394\n",
      "3433359.0   Ituzaingó                      832\n",
      "            Villa Udaondo                   25\n",
      "3435548.0   Centro                         231\n",
      "            Centro / Microcentro           223\n",
      "3435907.0   Bs.As. G.B.A. Zona Norte       222\n",
      "            Bs.As. G.B.A. Zona Oeste        65\n",
      "            Bs.As. G.B.A. Zona Sur          24\n",
      "            Buenos Aires Costa Atlántica    27\n",
      "            Buenos Aires Interior          106\n"
     ]
    }
   ],
   "source": [
    "# variable geonames_id,  corresponde al id asignado a cada place_name\n",
    "# primero vamos a validar que No se asigne un mismo geonames_id a distintos valores de place_name_new\n",
    "mask_geonames_id_nonull = data.geonames_id.notnull()\n",
    "df_geonames_id_place_name_ag = data.loc[mask_geonames_id_nonull]\n",
    "\n",
    "grouped = df_geonames_id_place_name_ag.groupby(['geonames_id',  'place_name_new'])\n",
    "grouped1 = grouped['Id_caso'].agg([np.size])\n",
    "\n",
    "df_agrupado2 = grouped1.groupby(['geonames_id']).filter(lambda grp: grp[\"size\"].count() > 1)\n",
    "print ('Casos que un mismo geonames_id tiene asignado más de un place_name')\n",
    "print ('------------------------------------------------------------------')\n",
    "print (df_agrupado2)\n",
    "\n",
    "# vemos que existen 5 valores de geonames_id que tiene mas de un valor de place_name\n",
    "# por lo que nos vemos en la necesidad de analizar un poco mas, para ver si corresponden a la misma zona\n",
    "# y ver que trabajo hacemos sobre ellos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Normalización y actualizacion de casos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzamos con el proceso de análisis y actualización de los los casos:\n",
      "-----------------------------------------------------------------------\n",
      "geonames_id = 3428927\n",
      "----------------------\n",
      "|Argentina|Bs.As. G.B.A. Zona Sur|Lomas de Zamora|San José|    11\n",
      "|Argentina|Bs.As. G.B.A. Zona Sur|Almirante Brown|San Jose|     5\n",
      "Name: place_with_parent_names, dtype: int64\n",
      "Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
      "3428927.0    16\n",
      "Name: geonames_id, dtype: int64\n",
      "Resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id\n",
      "Validamos en google que la localidad de \"San Jose\" corresponde al partido de \"Almirante Brown\"\n",
      "Para esos registros mask_place_with_parent_names = |Argentina|Bs.As. G.B.A. Zona Sur|Lomas de Zamora|San José|\n",
      "Actualizamos la variable Partido_barrio = \"Almirante Brown\"\n",
      "Actualizamos la variable Localidad = \"San Jose\"\n",
      "Actualizamos la variable place_name_new = \"San Jose\"\n",
      "Cantidad de casos para actualizar:\n",
      "Lomas de Zamora    11\n",
      "Name: Partido_barrio, dtype: int64\n",
      "Cantidad de casos actualizados:\n",
      "Almirante Brown    11\n",
      "Name: Partido_barrio, dtype: int64\n",
      "Cantidad de casos para actualizar:\n",
      "San José    11\n",
      "Name: Localidad, dtype: int64\n",
      "Cantidad de casos actualizados:\n",
      "San Jose    11\n",
      "Name: Localidad, dtype: int64\n",
      "Cantidad de casos para actualizar:\n",
      "San José    11\n",
      "Name: place_name_new, dtype: int64\n",
      "Cantidad de casos actualizados:\n",
      "San Jose    11\n",
      "Name: place_name_new, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print ('Comenzamos con el proceso de análisis y actualización de los los casos:')\n",
    "print ('-----------------------------------------------------------------------')\n",
    "print ('geonames_id = 3428927')\n",
    "print ('----------------------')\n",
    "# geonames_id = 3428927\n",
    "    # mascara de id\n",
    "mask_geonames_id  = data.geonames_id == 3428927\n",
    "    # traemos la informacion de esos casos \n",
    "ver = data.loc[mask_geonames_id,['place_with_parent_names']]\n",
    "print (ver.place_with_parent_names.value_counts())\n",
    "print ('Validamos que para esos place_with_parent_names no existan otros geonames_id')\n",
    "    # Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
    "valores = ['|Argentina|Bs.As. G.B.A. Zona Sur|Lomas de Zamora|San José|','|Argentina|Bs.As. G.B.A. Zona Sur|\\\n",
    "Almirante Brown|San Jose|']\n",
    "mask_place_with_parent_names  =  ([x in valores for x in data.place_with_parent_names]) \n",
    "ver1 = data.loc[mask_place_with_parent_names,['geonames_id'] ]\n",
    "print (ver1.geonames_id.value_counts())\n",
    "print ('Resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id')\n",
    "print ('Validamos en google que la localidad de \"San Jose\" corresponde al partido de \"Almirante Brown\"')\n",
    "print ('Para esos registros mask_place_with_parent_names = |Argentina|Bs.As. G.B.A. Zona Sur|Lomas de Zamora|San José|')\n",
    "print ('Actualizamos la variable Partido_barrio = \"Almirante Brown\"')\n",
    "print ('Actualizamos la variable Localidad = \"San Jose\"')\n",
    "print ('Actualizamos la variable place_name_new = \"San Jose\"')\n",
    "    \n",
    "    # resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id\n",
    "    # validamos en google que la localidad de 'San Jose' corresponde al partido de 'Almirante Brown'\n",
    "    # para esos registros mask_place_with_parent_names = |Argentina|Bs.As. G.B.A. Zona Sur|Lomas de Zamora|San José|\n",
    "    # actualizamos la variable Partido_barrio = 'Almirante Brown'\n",
    "    # actualizamos la variable Localidad = 'San Jose'\n",
    "    # actualizamos la variable place_name_new = 'San Jose'\n",
    "\n",
    "# creamos una veriable igual a geonames_id sobre le df para trabajar sobre esa\n",
    "data['geonames_id_new'] = data.geonames_id\n",
    "# mascara de geonames_id \n",
    "mask_geonames_id  = data.geonames_id == 3428927\n",
    "mask_place_with_parent_names = data.place_with_parent_names == '|Argentina|Bs.As. G.B.A. Zona Sur|\\\n",
    "Lomas de Zamora|San José|'\n",
    "# actualizamos el valor de Partido_barrio para los casos de la mascara\n",
    "print ('Cantidad de casos para actualizar:')\n",
    "data_antes = data.loc[mask_geonames_id & mask_place_with_parent_names,['Partido_barrio']]\n",
    "print (data_antes.Partido_barrio.value_counts())\n",
    "data.loc[mask_geonames_id & mask_place_with_parent_names,['Partido_barrio']] = 'Almirante Brown'\n",
    "print ('Cantidad de casos actualizados:')\n",
    "data_despues = data.loc[mask_geonames_id & mask_place_with_parent_names,['Partido_barrio']]\n",
    "print (data_despues.Partido_barrio.value_counts())\n",
    "# actualizamos el valor de Localidad para los casos de la mascara\n",
    "print ('Cantidad de casos para actualizar:')\n",
    "data_antes = data.loc[mask_geonames_id & mask_place_with_parent_names,['Localidad']]\n",
    "print (data_antes.Localidad.value_counts())\n",
    "data.loc[mask_geonames_id & mask_place_with_parent_names,['Localidad']] = 'San Jose'\n",
    "print ('Cantidad de casos actualizados:')\n",
    "data_despues = data.loc[mask_geonames_id & mask_place_with_parent_names,['Localidad']]\n",
    "print (data_despues.Localidad.value_counts())\n",
    "# actualizamos el valor de place_name_new para los casos de la mascara\n",
    "print ('Cantidad de casos para actualizar:')\n",
    "data_antes =  data.loc[mask_geonames_id & mask_place_with_parent_names,['place_name_new']]\n",
    "print (data_antes.place_name_new.value_counts())\n",
    "data.loc[mask_geonames_id & mask_place_with_parent_names,['place_name_new']] = 'San Jose'\n",
    "print ('Cantidad de casos actualizados:')\n",
    "data_despues = data.loc[mask_geonames_id & mask_place_with_parent_names,['place_name_new']]\n",
    "print (data_despues.place_name_new.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geonames_id = 3430234\n",
      "----------------------\n",
      "|Argentina|Capital Federal|Palermo|                 2885\n",
      "|Argentina|Capital Federal|Palermo|Palermo Soho|     394\n",
      "Name: place_with_parent_names, dtype: int64\n",
      "Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
      "3430234.0    3279\n",
      "Name: geonames_id, dtype: int64\n",
      "Resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id\n",
      "Vamos a dejar geonames_id_new en nulo para el caso de \"Palermo Soho\" que es mas abarcativa para sumarlo\n",
      "Al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
      "Cantidad original de casos para actualizar:\n",
      "3430234.0    394\n",
      "Name: geonames_id_new, dtype: int64\n",
      "Cantidad posterior de casos para actualizar:\n",
      "Series([], Name: geonames_id_new, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#..................................\n",
    "# geonames_id = 3430234, 3433359, 3435548\n",
    "    # mascara de id\n",
    "print ('geonames_id = 3430234')\n",
    "print ('----------------------')\n",
    "mask_geonames_id  = data.geonames_id == 3430234\n",
    "# traemos la informacion de esos casos \n",
    "ver = data.loc[mask_geonames_id,['place_with_parent_names']]\n",
    "print (ver.place_with_parent_names.value_counts())\n",
    "print ('Validamos que para esos place_with_parent_names no existan otros geonames_id')\n",
    "    # Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
    "valores = ['|Argentina|Capital Federal|Palermo|','|Argentina|Capital Federal|Palermo|Palermo Soho|']\n",
    "mask_place_with_parent_names  =  ([x in valores for x in data.place_with_parent_names]) \n",
    "ver1 = data.loc[mask_place_with_parent_names,['geonames_id']]\n",
    "print (ver1.geonames_id.value_counts())\n",
    "print ('Resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id')\n",
    "print ('Vamos a dejar geonames_id_new en nulo para el caso de \"Palermo Soho\" que es mas abarcativa para sumarlo') \n",
    "print ('Al tratamiente que vamos hacer despues con los nulos de geonames_id')\n",
    "    # resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id\n",
    "    # vamos a dejar geonames_id_new en nulo para el caso de 'Palermo Soho' que es mas abarcativa para sumarlo \n",
    "    # al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
    "# mascara\n",
    "mask_place_with_parent_names1 = data.place_with_parent_names == '|Argentina|Capital Federal|Palermo|Palermo Soho|'\n",
    "data_antes =   data.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']]\n",
    "print ('Cantidad original de casos para actualizar:')\n",
    "print(data_antes.geonames_id_new.value_counts())\n",
    "data.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']] = None\n",
    "print ('Cantidad posterior de casos para actualizar:')\n",
    "data_despues =   data.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']]\n",
    "print(data_despues.geonames_id_new.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geonames_id = 3433359\n",
      "---------------------\n",
      "|Argentina|Bs.As. G.B.A. Zona Oeste|Ituzaingó|                  474\n",
      "|Argentina|Bs.As. G.B.A. Zona Oeste|Ituzaingó|Ituzaingó|        358\n",
      "|Argentina|Bs.As. G.B.A. Zona Oeste|Ituzaingó|Villa Udaondo|     25\n",
      "Name: place_with_parent_names, dtype: int64\n",
      "Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
      "3433359.0    857\n",
      "Name: geonames_id, dtype: int64\n",
      "Resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id\n",
      "Vamos a dejar geonames_id en nulo para el caso de \"Villa Udaondo\" que es mas abarcativa para sumarlo\n",
      "Al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
      "Cantidad original de casos para actualizar:\n",
      "3433359.0    25\n",
      "Name: geonames_id_new, dtype: int64\n",
      "Cantidad posterior de casos para actualizar:\n",
      "Series([], Name: geonames_id_new, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#..................................\n",
    "# geonames_id =  3433359\n",
    "    # mascara de id\n",
    "mask_geonames_id  = data.geonames_id == 3433359\n",
    "print ('geonames_id = 3433359')\n",
    "print ('---------------------')\n",
    "    # traemos la informacion de esos casos \n",
    "ver = data.loc[mask_geonames_id,['place_with_parent_names']]\n",
    "print (ver.place_with_parent_names.value_counts())\n",
    "print ('Validamos que para esos place_with_parent_names no existan otros geonames_id')\n",
    "    # Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
    "valores = ['|Argentina|Bs.As. G.B.A. Zona Oeste|Ituzaingó|','|Argentina|Bs.As. G.B.A. Zona Oeste|Ituzaingó|Ituzaingó|','|Argentina|Bs.As. G.B.A. Zona Oeste|Ituzaingó|Villa Udaondo|']\n",
    "mask_place_with_parent_names  =  ([x in valores for x in data.place_with_parent_names]) \n",
    "ver1 = data.loc[mask_place_with_parent_names,['geonames_id']]\n",
    "print (ver1.geonames_id.value_counts())\n",
    "print ('Resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id')\n",
    "print ('Vamos a dejar geonames_id en nulo para el caso de \"Villa Udaondo\" que es mas abarcativa para sumarlo')\n",
    "print ('Al tratamiente que vamos hacer despues con los nulos de geonames_id')\n",
    "    # resultado ... como son de la misma zona y no existen mask_place_with_parent_names para otros geonames_id\n",
    "    # vamos a dejar geonames_id en nulo para el caso de 'Villa Udaondo' que es mas abarcativa para sumarlo \n",
    "    # al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
    "# mascara\n",
    "mask_place_with_parent_names1 = data.place_with_parent_names == '|Argentina|Bs.As. G.B.A. Zona Oeste|Ituzaingó|Villa Udaondo|'\n",
    "data_antes =   data.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']]\n",
    "print ('Cantidad original de casos para actualizar:')\n",
    "print(data_antes.geonames_id_new.value_counts())\n",
    "data.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']] = None\n",
    "print ('Cantidad posterior de casos para actualizar:')\n",
    "data_despues =   data.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']]\n",
    "print(data_despues.geonames_id_new.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geonames_id = 3435548\n",
      "---------------------\n",
      "|Argentina|Buenos Aires Costa Atlántica|Mar del Plata|Centro|    231\n",
      "|Argentina|Capital Federal|Centro / Microcentro|                 223\n",
      "Name: place_with_parent_names, dtype: int64\n",
      "Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
      "3435548.0    454\n",
      "Name: geonames_id, dtype: int64\n",
      "Resultado ... en este caso no corresponde a la mimsa zona, pero no existen mask_place_with_parent_names para otros geonames_id\n",
      "Vamos a dejar geonames_id en nulo para el caso de \"Mar del Plata\" solo para por simple elección y lo vamos a sumar\n",
      "Al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
      "Cantidad original de casos para actualizar:\n",
      "3435548.0    231\n",
      "Name: geonames_id_new, dtype: int64\n",
      "Cantidad posterior de casos para actualizar:\n",
      "Series([], Name: geonames_id_new, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#..................................\n",
    "# geonames_id = 3430234, 3433359, 3435548\n",
    "    # mascara de id\n",
    "print ('geonames_id = 3435548')\n",
    "print ('---------------------')\n",
    "mask_geonames_id  = data.geonames_id == 3435548\n",
    "    # traemos la informacion de esos casos \n",
    "ver = data.loc[mask_geonames_id,['place_with_parent_names'] ]\n",
    "print (ver.place_with_parent_names.value_counts())\n",
    "print ('Validamos que para esos place_with_parent_names no existan otros geonames_id')\n",
    "    # Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
    "valores = ['|Argentina|Buenos Aires Costa Atlántica|Mar del Plata|Centro|','|Argentina|Capital Federal|Centro / Microcentro|']\n",
    "mask_place_with_parent_names  =  ([x in valores for x in data.place_with_parent_names]) \n",
    "ver1 = data.loc[mask_place_with_parent_names,['geonames_id'] ]\n",
    "print (ver1.geonames_id.value_counts())\n",
    "print ('Resultado ... en este caso no corresponde a la mimsa zona, pero no existen mask_place_with_parent_names para otros geonames_id')\n",
    "print ('Vamos a dejar geonames_id en nulo para el caso de \"Mar del Plata\" solo para por simple elección y lo vamos a sumar')\n",
    "print ('Al tratamiente que vamos hacer despues con los nulos de geonames_id')\n",
    "    # resultado ... en este caso no corresponde a la mimsa zona, pero no existen mask_place_with_parent_names para otros geonames_id\n",
    "    # vamos a dejar geonames_id en nulo para el caso de 'Mar del Plata' solo para por simple elección y lo vamos a sumar\n",
    "    # al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
    "# mascara\n",
    "mask_place_with_parent_names1 = data.place_with_parent_names == '|Argentina|Buenos Aires Costa Atlántica|Mar del Plata|Centro|'\n",
    "data_antes =   data.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']]\n",
    "print ('Cantidad original de casos para actualizar:')\n",
    "print(data_antes.geonames_id_new.value_counts())\n",
    "data.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']] = None\n",
    "print ('Cantidad posterior de casos para actualizar:')\n",
    "data_despues =   data.loc[mask_geonames_id & mask_place_with_parent_names1, ['geonames_id_new']]\n",
    "print(data_despues.geonames_id_new.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geonames_id = 3435907\n",
      "---------------------\n",
      "|Argentina|Bs.As. G.B.A. Zona Norte|        222\n",
      "|Argentina|Buenos Aires Interior|           106\n",
      "|Argentina|Bs.As. G.B.A. Zona Oeste|         65\n",
      "|Argentina|Buenos Aires Costa Atlántica|     27\n",
      "|Argentina|Bs.As. G.B.A. Zona Sur|           24\n",
      "Name: place_with_parent_names, dtype: int64\n",
      "Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
      "3435907.0    444\n",
      "Name: geonames_id, dtype: int64\n",
      "Resultado ... en este caso no corresponde a la mimsa zona, pero no existen mask_place_with_parent_names para otros geonames_id\n",
      "Vamos a dejar geonames_id en nulo para todos los casos y lo vamos a sumar\n",
      "Al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
      "Cantidad original de casos para actualizar:\n",
      "3435907.0    444\n",
      "Name: geonames_id_new, dtype: int64\n",
      "Cantidad posterior de casos para actualizar:\n",
      "Series([], Name: geonames_id_new, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#..................................\n",
    "# geonames_id = 3435907\n",
    "    # mascara de id\n",
    "print ('geonames_id = 3435907')\n",
    "print ('---------------------')\n",
    "valores_geonames_id = [3435907]\n",
    "mask_geonames_id  = ([x in valores_geonames_id for x in data.geonames_id]) \n",
    "    # traemos la informacion de esos casos \n",
    "ver = data.loc[mask_geonames_id,['place_with_parent_names'] ]\n",
    "print (ver.place_with_parent_names.value_counts())\n",
    "print ('Validamos que para esos place_with_parent_names no existan otros geonames_id')\n",
    "    # Validamos que para esos place_with_parent_names no existan otros geonames_id\n",
    "valores = ['|Argentina|Bs.As. G.B.A. Zona Norte|','|Argentina|Bs.As. G.B.A. Zona Oeste|','|Argentina|Bs.As. G.B.A. Zona Sur|','|Argentina|Buenos Aires Costa Atlántica|','|Argentina|Buenos Aires Interior|']\n",
    "mask_place_with_parent_names  =  ([x in valores for x in data.place_with_parent_names]) \n",
    "ver1 = data.loc[mask_place_with_parent_names,['geonames_id'] ]\n",
    "print (ver1.geonames_id.value_counts())\n",
    "print ('Resultado ... en este caso no corresponde a la mimsa zona, pero no existen mask_place_with_parent_names para otros geonames_id')\n",
    "print ('Vamos a dejar geonames_id en nulo para todos los casos y lo vamos a sumar')\n",
    "print ('Al tratamiente que vamos hacer despues con los nulos de geonames_id')\n",
    "    # resultado ... en este caso no corresponde a la mimsa zona, pero no existen mask_place_with_parent_names para otros geonames_id\n",
    "    # vamos a dejar geonames_id en nulo para todos los casos y lo vamos a sumar\n",
    "    # al tratamiente que vamos hacer despues con los nulos de geonames_id\n",
    "# mascara\n",
    "data_antes =   data.loc[mask_geonames_id, ['geonames_id_new']]\n",
    "print ('Cantidad original de casos para actualizar:')\n",
    "print(data_antes.geonames_id_new.value_counts())\n",
    "data.loc[mask_geonames_id, ['geonames_id_new']] = None\n",
    "print ('Cantidad posterior de casos para actualizar:')\n",
    "data_despues =   data.loc[mask_geonames_id, ['geonames_id_new']]\n",
    "print(data_despues.geonames_id_new.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Asignación de valores sobre casos nulos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable geonames_id\n",
      "Vamos a analizar como podemos actualizar los valores nulos\n",
      "----------------------------------------------------------\n",
      "Cantidad de valores nulos: 19811\n",
      "Cantidad de valores distintos: 646\n",
      "Valor mínimo: 3427208.0\n",
      "Valor máximo: 6948895.0\n",
      "Cantidad de valores nulos final: 610\n",
      "Cantidad de valores distintos final: 1107\n",
      "Casos que un mismo geonames_id tiene asignado más de un place_name\n",
      "------------------------------------------------------------------\n",
      "Empty DataFrame\n",
      "Columns: [size]\n",
      "Index: []\n",
      "Casos con geonames_id nulo\n",
      "--------------------------\n",
      "|Argentina|Bs.As. G.B.A. Zona Norte|                                     222\n",
      "|Argentina|Buenos Aires Interior|                                        106\n",
      "|Argentina|Tucumán|                                                       77\n",
      "|Argentina|Bs.As. G.B.A. Zona Oeste|                                      65\n",
      "|Argentina|Buenos Aires Interior|Chascomús|Chascomús|                     54\n",
      "|Argentina|Buenos Aires Costa Atlántica|                                  27\n",
      "|Argentina|Bs.As. G.B.A. Zona Sur|                                        24\n",
      "|Argentina|Buenos Aires Interior|Berisso|Berisso|                         16\n",
      "|Argentina|Buenos Aires Interior|Zárate|Zárate|                            7\n",
      "|Argentina|Buenos Aires Interior|Campana|Campana|                          6\n",
      "|Argentina|Buenos Aires Interior|General Las Heras|General Las Heras|      3\n",
      "|Argentina|Buenos Aires Interior|Azul|Azul|                                2\n",
      "|Argentina|Buenos Aires Interior|Junín|Junín|                              1\n",
      "Name: place_with_parent_names, dtype: int64\n",
      "-----------------------------------------------------------------------------------\n",
      "Conclusión:\n",
      "Se terminó asignado un valor al azar mayor al máximo valor de la variable original\n",
      "solo quedando 610 casos nulos, que junto con la variable creada de calidad de dato,\n",
      "nos ayuda para definir o no su eliminación\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print('Variable geonames_id')\n",
    "print('Vamos a analizar como podemos actualizar los valores nulos')\n",
    "print('----------------------------------------------------------')\n",
    "print('Cantidad de valores nulos: ' + str(data.geonames_id_new.isnull().sum()))\n",
    "print('Cantidad de valores distintos: ' + str(len(data.geonames_id_new.unique())))\n",
    "print('Valor mínimo: ' + str(data.geonames_id_new.min()))\n",
    "print('Valor máximo: ' + str(data.geonames_id_new.max()))\n",
    "# vamos a trabajar los nulos del campo geonames_id_new\\n# y lo hacemos por zonas:\n",
    "# definimos 3 zonas de acuerdo al analisis del dato faltante de los procesos sobre place_with_parent_names\n",
    "# valores_geo_grupo1  = \\'Bs.As. G.B.A. Zona Norte\\',\\'Bs.As. G.B.A. Zona Oeste\\',\\'Bs.As. G.B.A. Zona Sur\\',\\'Capital Federal\\'\\n# mas valores_geo_interior\\n    \n",
    "    # si no tiene sino tiene Partido_barrio informado lo dejamos nulo ya que no seria correcto asignar un valor ya que \\n    \n",
    "    # abarca demasiado territorio\\n    \n",
    "    # si tiene Partido_barrio asigamos un numero al azar que identificara el place_name\\n\n",
    "# valores_geo_grupo2 = \\'Buenos Aires Costa Atlántica\\', \\'Buenos Aires Interior\\'\\n    \n",
    "    # si no tiene sino tiene Partido_barrio informado lo dejamos nulo ya que no seria correcto asignar un valor ya que \\n    \n",
    "    # abarca demasiado territorio\\n    \n",
    "    # si tiene Partido_barrio y Localidad, y NO son iguales asigamos un numero al azar que identificara el place_name\\n    \n",
    "    # si tiene Partido_barrio y Localidad, y SI son iguales asigamos, buscamos el ID del Partido_barrio \\n    \n",
    "# que si está informado\\n\\n\n",
    "# creamos los grupos\\n\n",
    "valores_geo_grupo1 = ['Bs.As. G.B.A. Zona Norte','Bs.As. G.B.A. Zona Oeste','Bs.As. G.B.A. Zona Sur','Capital Federal']\n",
    "valores_geo_grupo2 = ['Buenos Aires Costa Atlántica', 'Buenos Aires Interior']\n",
    "valores_geo_interior_temp = data.Zona.unique()\n",
    "valores_geo_interior_y_1 = list(set(valores_geo_interior_temp).difference(set(valores_geo_grupo2)))\n",
    "\n",
    "mask_geo_grupo2  =  ([x in valores_geo_grupo2 for x in data.Zona])\n",
    "mask_geo_interior_y_1  =  ([x in valores_geo_interior_y_1 for x in data.Zona])\n",
    "mask_geo_null = data.geonames_id_new.isnull()\n",
    "#mask_Partido_barrio_notnull = data.Partido_barrio.notnull()\n",
    "mask_Partido_barrio_null =  (data.Partido_barrio.isnull()) | (data.Partido_barrio == '')\n",
    "mask_Partido_barrio_notnull = mask_data_Partido_barrio_null == False\n",
    "mask_PB_dist_Localidad = data.Partido_barrio != data.Localidad\n",
    "\n",
    "# Creamos una serie con los distintos valores de place_name que no interesa aplicarle una numero al azar\n",
    "groupby_place_name_null = data.loc[(mask_geo_interior_y_1 & mask_geo_null & mask_Partido_barrio_notnull)\\\n",
    "                                   | (mask_geo_grupo2&mask_geo_null&mask_Partido_barrio_notnull&mask_PB_dist_Localidad)\\\n",
    "                                   ].groupby(['place_name_new'])[\"Id_caso\"].count()\n",
    "# convertimos la seria en un df para trabajarlo\n",
    "groupby_place_name_null_df = groupby_place_name_null.to_frame()\n",
    "# asignamos a cada valor el número aleatorio partiendo de un numero lo bastante grande para que\n",
    "# coincida con los existentes\n",
    "groupby_place_name_null_df[\"geonames_id_temp\"] = groupby_place_name_null_df.apply(lambda x: random.randint(10000000, 20000000), axis=1)\n",
    "\n",
    "# creamos un nuevo df sumando el campo nuevo \n",
    "datay = pd.merge(left=data,right=groupby_place_name_null_df, how='left', left_on='place_name_new', \\\n",
    "                 right_on='place_name_new')\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "# actualizamos los casos que convertimos a nulo en el arreglo de geonames_id\n",
    "#mask_geo_temp = ['|Argentina|Capital Federal|Palermo|Palermo Soho|']\n",
    "#mask_geo_temp1  =  ([x in mask_geo_temp for x in datay.place_with_parent_names])\n",
    "#max_valor = datay.geonames_id_temp.max()\n",
    "#max_valor = max_valor + 1\n",
    "#print(max_valor)\n",
    "#datay.loc[mask_geo_temp1, 'geonames_id_temp'] = datay.loc[mask_geo_temp1, 'geonames_id_temp'].apply(lambda x: max_valor)\n",
    "#['|Argentina|Buenos Aires Costa Atlántica|Mar del Plata|Centro|']\n",
    "#['|Argentina|Bs.As. G.B.A. Zona Oeste|Ituzaingó|Villa Udaondo|']\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "mask_geo_null = data.geonames_id_new.isnull()\n",
    "datay.loc[mask_geo_null, 'geonames_id_new'] = datay.loc[mask_geo_null, 'geonames_id_temp']\n",
    "del datay['Id_caso_y']\n",
    "datay.rename(columns={'Id_caso_x': 'Id_caso'}, inplace=True)\n",
    "print('Cantidad de valores nulos final: ' + str(datay.geonames_id_new.isnull().sum()))\n",
    "print('Cantidad de valores distintos final: ' + str(len(datay.geonames_id_new.unique())))\n",
    "\n",
    "#Validamos que luego de la aplicacion de nulos no hayan quedado para un mismo \n",
    "# geonames_id a distintos valores de place_name_new\n",
    "\n",
    "# variable geonames_id,  corresponde al id asignado a cada place_name\n",
    "# volvemos a validar que No se asigne un mismo geonames_id a distintos valores de place_name_new\n",
    "mask_geonames_id_new_notnull = datay.geonames_id_new.notnull()\n",
    "df_geonames_id_place_name_ag2 = datay.loc[mask_geonames_id_new_notnull]\n",
    "\n",
    "grouped_0 = df_geonames_id_place_name_ag2.groupby(['geonames_id_new',  'place_name_new'])\n",
    "grouped_1 = grouped_0['Id_caso'].agg([np.size])\n",
    "\n",
    "df_agrupado_2 = grouped_1.groupby(['geonames_id_new']).filter(lambda grp: grp[\"size\"].count() > 1)\n",
    "print ('Casos que un mismo geonames_id tiene asignado más de un place_name')\n",
    "print ('------------------------------------------------------------------')\n",
    "print (df_agrupado_2)\n",
    "\n",
    "data = datay\n",
    "data.drop(\"geonames_id_temp\", axis = 1, inplace=True)\n",
    "\n",
    "print ('Casos con geonames_id nulo')\n",
    "print ('--------------------------')\n",
    "# actualizo la mascara de los nulos\n",
    "mask_geo_null = data.geonames_id_new.isnull()\n",
    "print (data.loc[mask_geo_null, 'place_with_parent_names'].value_counts())\n",
    "print ('-----------------------------------------------------------------------------------')\n",
    "print ('Conclusión:')\n",
    "print ('Se terminó asignado un valor al azar mayor al máximo valor de la variable original')\n",
    "print ('solo quedando 610 casos nulos, que junto con la variable creada de calidad de dato,')\n",
    "print ('nos ayuda para definir o no su eliminación')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **Lat-Lon /** \n",
    "  **Lat /**\n",
    "  **Lon /**\n",
    "  \n",
    "  Vamos a validar que Lat-Lon corresponde a la concatenación de las variables Lat y Lon, con el objetivo de descartar las variables repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso de validación de los campos Lat-Lon vs Lat / Lon\n",
      "--------------------------------------------------------\n",
      "lat-lon    69670\n",
      "lat        69670\n",
      "lon        69670\n",
      "dtype: int64\n",
      "Cantidad de casos iguales latitud: 69502\n",
      "Cantidad de casos iguales longitud: 69396\n",
      "----------------------------------------------------------\n",
      "Se validó que la variable lat-lon corresponde a la concatenación\n",
      "de las variables individuales\n"
     ]
    }
   ],
   "source": [
    "print ('Proceso de validación de los campos Lat-Lon vs Lat / Lon')\n",
    "print ('--------------------------------------------------------')\n",
    "# validamos que los campos Lat y Lon tengan la misma cantidad y valor de info que Lat-Lon\n",
    "# primero separamos el campo Lat-Lon\n",
    "df_lat_lon  = data.loc[:,[\"Id_caso\",\"lat-lon\", \"lat\", \"lon\"]].join(data[\"lat-lon\"].str.split(',', expand=True).rename(columns={\n",
    "                                                                                                0:'lat_temp', \n",
    "                                                                                                1:'lon_temp'}))\n",
    "# los campos saparados los convierto en numéricos\n",
    "df_lat_lon.lat_temp = df_lat_lon.lat_temp.apply(pd.to_numeric)\n",
    "df_lat_lon.lon_temp = df_lat_lon.lon_temp.apply(pd.to_numeric)\n",
    "\n",
    "# Validmos que los campos tengan la misma cantidad de NO nulos\n",
    "print (df_lat_lon[[\"lat-lon\", \"lat\", \"lon\"]].notnull().sum())\n",
    "# mascara de no nulos\n",
    "mask_notnull = df_lat_lon[\"lat-lon\"].notnull()\n",
    "# mascara de valores iguales \n",
    "ver_lat = round(df_lat_lon.lat,6) == round(df_lat_lon.lat_temp,6)\n",
    "ver_lon = round(df_lat_lon.lon,6) == round(df_lat_lon.lon_temp,6)\n",
    "# validamos la cantidad de casos\n",
    "print ('Cantidad de casos iguales latitud: ' + str(ver_lat.sum()))\n",
    "print ('Cantidad de casos iguales longitud: ' + str(ver_lon.sum()))\n",
    "print ('----------------------------------------------------------')\n",
    "print ('Se validó que la variable lat-lon corresponde a la concatenación')\n",
    "print ('de las variables individuales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2.  Variables del grupo sobre el valor de propiedades\n",
    "\n",
    "Validación, limpieza y asignación de nulos; sobre las variables:\n",
    "\n",
    "- price\n",
    "- currency\n",
    "- price_aprox_local_currency\n",
    "- price_aprox_usd\n",
    "- price_usd_per_m2\n",
    "- price_per_m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**price /**\n",
    "**currency /**\n",
    "**price_aprox_local_currency /**\n",
    "**price_aprox_usd**\n",
    "\n",
    "Validamos si la variable price_aprox_usd es la podemos utilizar como precio estandar de una propiedad:\n",
    "* Analizamos si para todos los casos está asignado el mismo tipo de cambio por dolar, independientemente de la moneda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso de validación de tipo de cambio\n",
      "---------------------------------------\n",
      "Distintos tipos de moneda:\n",
      "USD    87587\n",
      "ARS    13219\n",
      "PEN        2\n",
      "UYU        1\n",
      "Name: currency, dtype: int64\n",
      "Los valores \"PEN\" y \"UYU\" los actualizamos a nulos para no descartarlos\n",
      "Distintos valores del tipo de cambio luego de actualizar la variable creada\n",
      "17.64    100806\n",
      "0.00      20414\n",
      "Name: Valor_dolar, dtype: int64\n",
      "Vemos que existe un solo valor ... Exc!\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "Llegamos a la conclusion que es posible usar la variable price_aprox_usd como precio de la propiedad estándar\n"
     ]
    }
   ],
   "source": [
    "print ('Proceso de validación de tipo de cambio')\n",
    "print ('---------------------------------------')\n",
    "# proceso de validación del tipo de cambio para validar si es correcto tomar el \n",
    "# el campo price_aprox_usd para todos los casos\n",
    "\n",
    "# validamos que si currency (moneda) = \n",
    "# nulo  ----> nulo\n",
    "# 'USD'  ----> price_aprox_local_currency / price  ----> valor por dolar de precios en dolares\n",
    "# sino ---->price_aprox_local_currency / price_aprox_usd ----> valor por dolar de precios en pesos\n",
    "# agrupamos los valores por dolar ... redondeado a 2 dígitos\n",
    "\n",
    "#.................................................\n",
    "print ('Distintos tipos de moneda:')\n",
    "# Vemos los distintos valores de la variable moneda\n",
    "print(data.currency.value_counts())\n",
    "# vemos que existen 3 registros con valores PEN (sol peruano) y UYU (peso Uruguayo)\n",
    "# vemos los casos\n",
    "print ('Los valores \"PEN\" y \"UYU\" los actualizamos a nulos para no descartarlos')\n",
    "valores_otras_monedas = ['PEN', 'UYU']\n",
    "mask_otras_monedas = [x in valores_otras_monedas for x in data.currency]\n",
    "data.loc[mask_otras_monedas, [\"currency\",\"price\"]] = None\n",
    "\n",
    "# sumamos la varible al Df Valor_dolar\n",
    "data[\"Valor_dolar\"] = 0\n",
    "# trabajamos la moneda = 'USD'\n",
    "mask_dolar = data.currency == 'USD'\n",
    "mask_price = (data.price != 0) | (data.price.notnull())\n",
    "data.loc[mask_dolar & mask_price, \"Valor_dolar\"] = round(data.price_aprox_local_currency / data.price,2)\n",
    "# trabajamos la moneda = 'ARG'\n",
    "mask_peso = data.currency == 'ARS'\n",
    "mask_price_aprox_usd = (data.price_aprox_usd != 0) | (data.price_aprox_usd.notnull())\n",
    "data.loc[mask_peso & mask_price_aprox_usd, \"Valor_dolar\"] = round(data.price_aprox_local_currency / data.price_aprox_usd,2)\n",
    "print ('Distintos valores del tipo de cambio luego de actualizar la variable creada')\n",
    "# vemos los valores distintos para valor de dolar\n",
    "print(data.Valor_dolar.value_counts())\n",
    "print ('Vemos que existe un solo valor ... Exc!')\n",
    "print ('-------------------------------------------------------------------------------------------------------------')\n",
    "print ('Llegamos a la conclusion que es posible usar la variable price_aprox_usd como precio de la propiedad estándar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**price_usd_per_m2 /**\n",
    "**price_per_m2**\n",
    "\n",
    "\n",
    "* Análisis sobre las variables\n",
    "* Estandarización sobre price_per_m2 a precio u$s\n",
    "* Lógica sobre valores nulos de price_per_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso de análisis del precio por m2\n",
      "-------------------------------------\n",
      "Variables:\n",
      "- price_usd_per_m2\n",
      "- price_per_m2\n",
      "Al ver alguno ejemplos vamos a validar que:\n",
      "price_usd_per_m2 corresponde al precio en dólares sobre la superficie total en m2(price_aprox_usd / surface_total_in_m2)\n",
      "y que price_per_m2 corresponde al precio original sobre la superficie cubierta(price / surface_covered_in_m2)\n",
      "por lo que sobre esta última, ademas vamos a estandarizarla a dólares sobre una nueva variable\n",
      "Validación de price_usd_per_m2\n",
      "------------------------------\n",
      "Luego de \"imitar\" la variable agrupamos por la marca si coinciden o no con la variable original:\n",
      "False    68614\n",
      "True     52606\n",
      "dtype: int64\n",
      "Vemos que hay 52606 que no coinciden\n",
      "Validamos que todos los casos que correspondan a los valores nulos, mediante una máscara\n",
      "True     52603\n",
      "False        3\n",
      "Name: price_usd_per_m2, dtype: int64\n",
      "Conclusión: la variable price_usd_per_m2 corresponde a\n",
      "a price_aprox_usd / surface_total_in_m2\n",
      "Validación de price_per_m2\n",
      "------------------------------\n",
      "Luego de \"imitar\" la variable agrupamos por la marca si coinciden o no con la variable original:\n",
      "False    87658\n",
      "True     33562\n",
      "dtype: int64\n",
      "Vemos que hay 33562 que no coinciden\n",
      "Validamos que todos los casos que correspondan a los valores nulos, mediante una máscara\n",
      "True    33562\n",
      "Name: price_per_m2, dtype: int64\n",
      "Conclusión: la variable price_per_m2 corresponde a\n",
      "price / surface_covered_in_m2\n"
     ]
    }
   ],
   "source": [
    "print ('Proceso de análisis del precio por m2')\n",
    "print ('-------------------------------------')\n",
    "print('Variables:')\n",
    "print('- price_usd_per_m2')\n",
    "print('- price_per_m2')\n",
    "    \n",
    "print ('Al ver alguno ejemplos vamos a validar que:')\n",
    "print ('price_usd_per_m2 corresponde al precio en dólares sobre la superficie total en m2(price_aprox_usd / surface_total_in_m2)')\n",
    "print ('y que price_per_m2 corresponde al precio original sobre la superficie cubierta(price / surface_covered_in_m2)')\n",
    "print ('por lo que sobre esta última, ademas vamos a estandarizarla a dólares sobre una nueva variable')\n",
    "    \n",
    "\n",
    "# lo validamos\n",
    "print ('Validación de price_usd_per_m2')\n",
    "print ('------------------------------')\n",
    "# ----------------------------------price_usd_per_m2\n",
    "# sumamos un nuevo campo \n",
    "data[\"price_usd_per_m2_new\"] = -1\n",
    "# mascara de los NO nulos price_aprox_usd\n",
    "mask_price_aprox_usd_notnull = data.price_aprox_usd.notnull()\n",
    "# mascara de los no nulos y mayores a cero de surface_total_in_m2\n",
    "mask_surface_total_in_m2_notnull_0 = ((data.surface_total_in_m2.notnull()) & (data.surface_total_in_m2 > 0))\n",
    "# actualización de la variable nueva price_usd_per_m2_new\n",
    "data.loc[mask_price_aprox_usd_notnull & mask_surface_total_in_m2_notnull_0, \"price_usd_per_m2_new\"] = round(data.price_aprox_usd/data.surface_total_in_m2,2)\n",
    "# validamos creando una mascara sobre los que NO coinciden variable original vs variable nueva\n",
    "mask_validacion_price_aprox_usd = data.price_usd_per_m2_new != round(data.price_usd_per_m2,2)\n",
    "print('Luego de \"imitar\" la variable agrupamos por la marca si coinciden o no con la variable original:')\n",
    "# agrupamos por la mascara y vemos que existen 52606 casos que son verdaderos .. NO coinciden\n",
    "print(mask_validacion_price_aprox_usd.value_counts())\n",
    "print('Vemos que hay 52606 que no coinciden')\n",
    "print('Validamos que todos los casos que correspondan a los valores nulos, mediante una máscara')\n",
    "# contamos los nulos de esos no coincidentes y vemos que no coinciden porque la variable nueva se \n",
    "# le asigne como valor default -1 y en la variable original estan con nulo\n",
    "print(data.loc[mask_validacion_price_aprox_usd, \"price_usd_per_m2\"].isnull().value_counts())\n",
    "print('Conclusión: la variable price_usd_per_m2 corresponde a')\n",
    "print('a price_aprox_usd / surface_total_in_m2')\n",
    "\n",
    "# ----------------------------------price_per_m2\n",
    "print ('Validación de price_per_m2')\n",
    "print ('------------------------------')\n",
    "# sumamos un nuevo campo \n",
    "data[\"price_per_m2_new\"] = -1\n",
    "# mascara de los NO nulos price\n",
    "mask_price_notnull = data.price.notnull()\n",
    "# mascara de los no nulos y mayores a cero de surface_covered_in_m2\n",
    "mask_surface_covered_in_m2_notnull_0 = ((data.surface_covered_in_m2.notnull()) & (data.surface_covered_in_m2 > 0))\n",
    "# actualización de la variable nueva price_per_m2_new\n",
    "data.loc[mask_price_notnull & mask_surface_covered_in_m2_notnull_0, \"price_per_m2_new\"] = round(data.price/data.surface_covered_in_m2,2)\n",
    "# validamos creando una mascara sobre los que NO coinciden variable original vs variable nueva\n",
    "mask_validacion_price_per_m2 = data.price_per_m2_new != round(data.price_per_m2,2)\n",
    "print('Luego de \"imitar\" la variable agrupamos por la marca si coinciden o no con la variable original:')\n",
    "# agrupamos por la mascara y vemos que existen 33562 casos que son verdaderos .. NO coinciden\n",
    "print(mask_validacion_price_per_m2.value_counts())\n",
    "print('Vemos que hay 33562 que no coinciden')\n",
    "print('Validamos que todos los casos que correspondan a los valores nulos, mediante una máscara')\n",
    "# contamos los nulos de esos no coincidentes y vemos que no coinciden porque la variable nueva se \n",
    "# le asigne como valor default -1 y en la variable original estan con nulo\n",
    "print (data.loc[mask_validacion_price_per_m2, \"price_per_m2\"].isnull().value_counts())\n",
    "print('Conclusión: la variable price_per_m2 corresponde a')\n",
    "print('price / surface_covered_in_m2')\n",
    "# ahora vamos a actualizar la veriable que creamos price_per_m2 pero tomando para el caso de moneda ARG la \n",
    "# variable en dolares price_aprox_usd para que todo quede en la misma moneda\n",
    "# mascara moneda ARG\n",
    "mask_peso = data.currency == 'ARS'\n",
    "data.loc[mask_peso & mask_surface_covered_in_m2_notnull_0, \"price_per_m2_new\"] = round(data.price_aprox_usd/data.surface_covered_in_m2,2)\n",
    "# pasamos a nulo los que quedaron con valor -1\n",
    "data['price_usd_per_m2_new'].replace(-1, np.nan, inplace=True)\n",
    "data['price_per_m2_new'].replace(-1, np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso para llenar nulos sobre price_per_m2_new\n",
      "------------------------------------------------\n",
      "Cantidad de casos nulos: 33562\n",
      "Tomamos la decision de reemplazar los nulos por:\n",
      "data.price_aprox_usd / data.surface_total_in_m2\n",
      "Pero para los casos que:\n",
      "property_type == \"apartment\"\n",
      "price_aprox_usd no sea nulo\n",
      "surface_total_in_m2 no sea nulo y mayor a cero\n",
      "Cantidad de casos actualizados: 3309\n",
      "------------------------------------------------\n",
      "Cantidad de casos nulos despues del proceso: 30253\n"
     ]
    }
   ],
   "source": [
    "print ('Proceso para llenar nulos sobre price_per_m2_new')\n",
    "print ('------------------------------------------------')\n",
    "\n",
    "print ('Cantidad de casos nulos: ' + str(data.price_per_m2_new.isnull().sum()))\n",
    "\n",
    "print ('Tomamos la decision de reemplazar los nulos por:')\n",
    "print ('data.price_aprox_usd / data.surface_total_in_m2')\n",
    "print ('Pero para los casos que:')\n",
    "print ('property_type == \"apartment\"')\n",
    "print ('price_aprox_usd no sea nulo')\n",
    "print ('surface_total_in_m2 no sea nulo y mayor a cero')\n",
    "\n",
    "# mascaras necesarias\n",
    "mask_property_type = data.property_type == 'apartment'\n",
    "mask_price_aprox_usd = data.price_aprox_usd.notnull()\n",
    "mask_surface_total_in_m2 = data.surface_total_in_m2.notnull()&data.surface_total_in_m2 > 0\n",
    "mask_surface_covered_in_m2 = data.surface_covered_in_m2.isnull()\n",
    "mask_price_per_m2_new = data.price_per_m2_new.isnull()\n",
    "\n",
    "data.loc[mask_property_type&mask_price_aprox_usd&\\\n",
    "                 mask_surface_total_in_m2&mask_surface_covered_in_m2&mask_price_per_m2_new, \"price_per_m2_new\"] =\\\n",
    "data.price_aprox_usd /  data.surface_total_in_m2 \n",
    "\n",
    "print ('Cantidad de casos actualizados: ' + str(len(data.loc[mask_property_type&mask_price_aprox_usd&\\\n",
    "                 mask_surface_total_in_m2&mask_surface_covered_in_m2, \"price_per_m2_new\"] )))\n",
    "print ('------------------------------------------------')\n",
    "print ('Cantidad de casos nulos despues del proceso: ' + str(data.price_per_m2_new.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3.  Proceso de borrado de registros duplicados\n",
    "\n",
    "Luego del analisis de cada uno de los datos, llegamos a la conclusion de ejecutar el borrado de los datos duplicados sobre las variables:\n",
    "* property_type\n",
    "* geonames_id_new\n",
    "* lat-lon\n",
    "* price_aprox_usd\n",
    "* price_per_m2_new\n",
    "* description\n",
    "* title\n",
    "\n",
    "Teniendo en cuenta como afecta al proceso la cantidad de nulos de cada variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso de borrado de duplicados\n",
      "--------------------------------\n",
      "Cantidad de registros con duplicados: 121220\n",
      "Cantidad de registros duplicados: 6169\n",
      "Cantidad de registros sin duplicados: 115051\n"
     ]
    }
   ],
   "source": [
    "print ('Proceso de borrado de duplicados')\n",
    "print ('--------------------------------')\n",
    "\n",
    "print('Cantidad de registros con duplicados: ' + str(len(data)))\n",
    "\n",
    "# analizando las varibles disponibles decidimos validar la existencia de duplicados por:\n",
    "# property_type:    no existen nulos\n",
    "# geonames_id_new:  no existen nulos\n",
    "# lat-lon:          existen nulos\n",
    "# price_aprox_usd:  existen nulos\n",
    "# price_per_m2_new: existen nulos\n",
    "# description:      no existen nulos\n",
    "# title:            no existen nulos\n",
    "\n",
    "print ('Cantidad de registros duplicados: ' + str(data.duplicated(subset=[\\\n",
    "                                                                                  \"property_type\",\\\n",
    "                                                                                  \"geonames_id_new\",\\\n",
    "                                                                                  \"lat-lon\",\\\n",
    "                                                                                  \"price_aprox_usd\",\\\n",
    "                                                                                  \"price_per_m2_new\",\\\n",
    "                                                                                  \"description\",\\\n",
    "                                                                                  \"title\"\\\n",
    "                                                                                 ], keep=\"last\").sum())\\\n",
    "      )\n",
    "\n",
    "data.drop_duplicates(subset=[\\\n",
    "                                     \"property_type\",\\\n",
    "                                     \"geonames_id_new\",\\\n",
    "                                     \"lat-lon\",\\\n",
    "                                     \"price_aprox_usd\",\\\n",
    "                                     \"price_per_m2_new\",\\\n",
    "                                     \"description\",\\\n",
    "                                     \"title\"\\\n",
    "                                    ], keep=\"last\", inplace=True)\n",
    "\n",
    "print('Cantidad de registros sin duplicados: ' + str(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4.  Proceso de borrado de registros sin información completa\n",
    "\n",
    "De acuerdo al trabajo de limpieza que generamos, vemos que existen casuísticas que debemos tener en cuenta y que debemos descartar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planteamos tres escenarios que nos permiten definifir los conjuntos de datos que pueden ser borrados:\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Cantidad de registros original: 115051\n",
      "1. price_aprox_usd es null & surface_covered_in_m2 es null & price_per_m2_new is null\n",
      "5689\n",
      "2. calidad_dato = True & lat-lon es null\n",
      "7041\n",
      "3. aquellas regiones con una cantidad de casos muy chica\n",
      "93\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Eliminamos los registros:\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Validamos el resultado:\n",
      "Cantidad de registros final: 102228\n"
     ]
    }
   ],
   "source": [
    "print ('Planteamos tres escenarios que nos permiten definifir los conjuntos de datos que pueden ser borrados:')\n",
    "print ('-----------------------------------------------------------------------------------------------------')\n",
    "print ('Cantidad de registros original: ' + str(len(data)))\n",
    "print ('1. price_aprox_usd es null & surface_covered_in_m2 es null & price_per_m2_new is null')\n",
    "maskf_price_aprox_usd = data.price_aprox_usd.isnull()\n",
    "maskf_surface_covered_in_m2 = data.surface_covered_in_m2.isnull()\n",
    "maskf_price_per_m2_new = data.price_per_m2_new.isnull()\n",
    "print (len(data.loc[maskf_price_aprox_usd&maskf_surface_covered_in_m2&maskf_price_per_m2_new]))\n",
    "data.drop(data[maskf_price_aprox_usd&maskf_surface_covered_in_m2&maskf_price_per_m2_new].index, inplace=True)\n",
    "\n",
    "print ('2. calidad_dato = True & lat-lon es null')\n",
    "maskf_calidad_dato = data.calidad_dato == True\n",
    "maskf_lat_lon = data[\"lat-lon\"].isnull()\n",
    "print (len(data.loc[maskf_calidad_dato&maskf_lat_lon]))\n",
    "data.drop(data[maskf_calidad_dato&maskf_lat_lon].index, inplace=True)\n",
    "\n",
    "print ('3. aquellas regiones con una cantidad de casos muy chica')\n",
    "list_state_name = ['Tierra Del Fuego','Catamarca','Jujuy','Santa Cruz','La Rioja','Santiago Del Estero']\n",
    "mask_state_name = [x in list_state_name for x in data.state_name]\n",
    "print (len(data.loc[mask_state_name]))\n",
    "data.drop(data[mask_state_name].index, inplace=True)\n",
    "print ('-----------------------------------------------------------------------------------------------------')\n",
    "print ('Eliminamos los registros:')\n",
    "#data.drop(data[maskf_price_aprox_usd&maskf_surface_covered_in_m2&maskf_price_per_m2_new].index, inplace=True)\n",
    "#data.drop(data[maskf_calidad_dato&maskf_lat_lon].index, inplace=True)\n",
    "#data.drop(data[mask_state_name].index, inplace=True)\n",
    "print ('-----------------------------------------------------------------------------------------------------')\n",
    "print ('Validamos el resultado:')\n",
    "print ('Cantidad de registros final: ' + str(len(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = data.loc[:, [\\\n",
    "                            'Id_caso','property_type','place_name_new',\\\n",
    "                            'state_name','geonames_id_new','lat-lon', 'calidad_dato',\\\n",
    "                            'price_aprox_usd',\\\n",
    "                            'surface_total_in_m2','surface_covered_in_m2',\\\n",
    "                            'price_usd_per_m2','price_per_m2_new',\\\n",
    "                            'rooms',\\\n",
    "                            'description','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id_caso                 -0.016277\n",
       "geonames_id_new          0.003905\n",
       "calidad_dato            -0.000373\n",
       "price_aprox_usd          0.099110\n",
       "surface_total_in_m2     -0.011256\n",
       "surface_covered_in_m2   -0.010896\n",
       "price_usd_per_m2         0.455498\n",
       "price_per_m2_new         1.000000\n",
       "rooms                   -0.021756\n",
       "Name: price_per_m2_new, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.corr().price_per_m2_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
